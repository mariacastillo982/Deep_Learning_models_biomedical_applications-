{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xngEyGvkJjRg",
        "outputId": "057b8caf-690c-4443-ef2d-7a3fc5bec1ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "MRS_path = \"/content/drive/My Drive/Lipid Peak/DB_F.mat\"\n",
        "MRS_C_path=\"/content/drive/My Drive/Lipid Peak/DB_FC.mat\"\n",
        "ppm_path=\"/content/drive/My Drive/Lipid Peak/ppm.mat\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3GBEI5ya17_",
        "outputId": "c6539d8a-6a2a-4be0-debe-33b92915da85"
      },
      "source": [
        "!pip install talos\n",
        "import talos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting talos\n",
            "  Downloading talos-1.0-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 20 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 30 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from talos) (2.6.0)\n",
            "Collecting astetik\n",
            "  Downloading astetik-1.11.1-py3-none-any.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from talos) (1.1.5)\n",
            "Collecting wrangle\n",
            "  Downloading wrangle-0.6.9-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 633 kB/s \n",
            "\u001b[?25hCollecting chances\n",
            "  Downloading chances-0.1.9.tar.gz (35 kB)\n",
            "Collecting kerasplotlib\n",
            "  Downloading kerasplotlib-0.1.6.tar.gz (3.5 kB)\n",
            "Collecting statsmodels>=0.11.0\n",
            "  Downloading statsmodels-0.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from talos) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from talos) (2.23.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from talos) (4.62.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.0->talos) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.0->talos) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->talos) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.2->statsmodels>=0.11.0->talos) (1.15.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.2.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.12)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.37.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.41.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.0.0->talos) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->talos) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->talos) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->talos) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->talos) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0.0->talos) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0.0->talos) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->talos) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0.0->talos) (3.1.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from astetik->talos) (0.11.2)\n",
            "Collecting geonamescache\n",
            "  Downloading geonamescache-1.3.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from astetik->talos) (5.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0.0->talos) (3.6.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (5.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->astetik->talos) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->astetik->talos) (0.7.0)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->astetik->talos) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->talos) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->talos) (1.0.1)\n",
            "Building wheels for collected packages: chances, kerasplotlib\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chances: filename=chances-0.1.9-py3-none-any.whl size=41609 sha256=683903396eaa12e65f7a6812e5f23d2f4b8c66d0513631034f1be4824dace5cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/2e/7e/316f7da11ccf2195ff05e4a0186a4b5975be9bd0b0004198b6\n",
            "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kerasplotlib: filename=kerasplotlib-0.1.6-py3-none-any.whl size=3603 sha256=24c7639a0e7b5dc484eac5b7b3030bada407f42add0fbfd052affcfca8bec3ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/b4/c8/d1533d85f7fc617e3201c3f41b79fe49ae9284c8fc4a5bd4b2\n",
            "Successfully built chances kerasplotlib\n",
            "Installing collected packages: statsmodels, wrangle, geonamescache, kerasplotlib, chances, astetik, talos\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed astetik-1.11.1 chances-0.1.9 geonamescache-1.3.0 kerasplotlib-0.1.6 statsmodels-0.13.0 talos-1.0 wrangle-0.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeCkjSiGJqX6"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import signal, io\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from scipy import signal\n",
        "from scipy.fft import fftshift\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
        "from keras.models import Sequential, Model\n",
        "import itertools\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "#import talos\n",
        "from talos.model.normalizers import lr_normalizer\n",
        "import copy\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "import math\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HEID6yrZ1YW"
      },
      "source": [
        "def read_DB(MRS_path,MRS_C_path, fs):\n",
        "  MRS_F=io.loadmat(MRS_path)\n",
        "  MRS_F=MRS_F['MRS']\n",
        "  MRS_FC=io.loadmat(MRS_C_path)\n",
        "  MRS_FC=MRS_FC['MRS_Clean']\n",
        "\n",
        "  Data = []\n",
        "  DataC = []\n",
        "  DataMRS = []\n",
        "  DataMRSC = []\n",
        "\n",
        "  for (MRS,MRSC) in zip(MRS_F,MRS_FC):\n",
        "      DataMRS.append(MRS)\n",
        "      DataMRSC.append(MRSC)\n",
        "\n",
        "  DATA=np.asarray(DataMRS)\n",
        "  DATAC=np.asarray(DataMRSC)\n",
        "  return DATAC, DATA\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qghWxthOUR4T",
        "outputId": "6b4fc961-9910-497f-9a28-4c71699e4783"
      },
      "source": [
        "# Model configuration\n",
        "batch_size = 5\n",
        "no_epochs = 20\n",
        "train_test_split = 0.3\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "max_norm_value = 2.0\n",
        "\n",
        "#Load and split data\n",
        "fs=2000\n",
        "DATAC, DATA=read_DB(MRS_path,MRS_C_path, fs)\n",
        "input_shape = (DATA.shape[1],1)\n",
        "noisy_input=DATA.reshape((DATA.shape[0], DATA.shape[1], 1))\n",
        "pure_input=DATAC.reshape((DATAC.shape[0], DATAC.shape[1], 1))\n",
        "print(noisy_input.shape)\n",
        "\n",
        "# Train/test split\n",
        "percentage_training = math.floor((1 - train_test_split) * len(noisy_input))\n",
        "noisy_input, noisy_input_test = noisy_input[:percentage_training], noisy_input[percentage_training:]\n",
        "pure_input, pure_input_test = pure_input[:percentage_training], pure_input[percentage_training:]\n",
        "print(noisy_input.shape)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(16, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(16, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(32, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(64, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1DTranspose(128, kernel_size=3, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(1, kernel_size=3, activation='sigmoid', padding='same'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile and fit data\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(noisy_input, pure_input,\n",
        "                epochs=no_epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_split=validation_split)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Generate reconstructions\n",
        "num_reconstructions = 2\n",
        "samples = noisy_input_test[:num_reconstructions]\n",
        "reconstructions = model.predict(samples)\n",
        "\n",
        "# Plot reconstructions\n",
        "for i in np.arange(0, num_reconstructions):\n",
        "  # Prediction index\n",
        "  prediction_index = i + percentage_training\n",
        "  # Get the sample and the reconstruction\n",
        "  original = DATA[prediction_index]\n",
        "  pure = DATAC[prediction_index]\n",
        "  reconstruction = np.array(reconstructions[i])\n",
        "  # Matplotlib preparations\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "  # Plot sample and reconstruciton\n",
        "  axes[0].plot(original)\n",
        "  axes[0].set_title('Noisy waveform')\n",
        "  axes[1].plot(pure)\n",
        "  axes[1].set_title('Pure waveform')\n",
        "  axes[2].plot(reconstruction)\n",
        "  axes[2].set_title('Conv Autoencoder Denoised waveform')\n",
        "  plt.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(63, 1024, 1)\n",
            "(44, 1024, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 1016, 16)          1552      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_3 (Conv1DTr (None, 1018, 16)          784       \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_4 (Conv1DTr (None, 1020, 32)          1568      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_5 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_6 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 66,529\n",
            "Trainable params: 66,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 2s 76ms/step - loss: 1.0585 - val_loss: 0.9146\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9060 - val_loss: 0.8455\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8455 - val_loss: 0.8124\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8230 - val_loss: 0.7906\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8077 - val_loss: 0.7808\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7983 - val_loss: 0.7745\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7910 - val_loss: 0.7676\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.7881 - val_loss: 0.7671\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7856 - val_loss: 0.7637\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7831 - val_loss: 0.7538\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7817 - val_loss: 0.7575\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7820 - val_loss: 0.7578\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7798 - val_loss: 0.7508\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7789 - val_loss: 0.7535\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7779 - val_loss: 0.7483\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7773 - val_loss: 0.7487\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.7761 - val_loss: 0.7509\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7756 - val_loss: 0.7492\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7748 - val_loss: 0.7505\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7756 - val_loss: 0.7533\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nriCrsCHv6Vz"
      },
      "source": [
        "def minimal(MRS_path,MRS_C_path, fs):\n",
        "\n",
        "    validation_split = 0.2\n",
        "    #Load and split data\n",
        "    DATAC, DATA=read_DB(MRS_path,MRS_C_path, fs)\n",
        "    input_shape = (DATA.shape[1],1)\n",
        "    noisy_input=DATA.reshape((DATA.shape[0], DATA.shape[1], 1))\n",
        "    pure_input=DATAC.reshape((DATAC.shape[0], DATAC.shape[1], 1))\n",
        "\n",
        "    # Train/test split\n",
        "    percentage_training = math.floor((1 - train_test_split) * len(noisy_input))\n",
        "    noisy_input, noisy_input_test = noisy_input[:percentage_training], noisy_input[percentage_training:]\n",
        "    pure_input, pure_input_test = pure_input[:percentage_training], pure_input[percentage_training:]\n",
        "\n",
        "    p = {'optimizer': [Adam],\n",
        "         'lr':[0.5, 0.1, 0.01, 1e-3],\n",
        "         'loss': ['mse'],\n",
        "         'activation': ['elu', 'relu', 'sigmoid', 'softmax', 'tanh'],\n",
        "         'Kernel_ini': ['glorot_normal', 'glorot_uniform', 'he_normal', 'he_normal'],\n",
        "         'metrics': ['mse'],\n",
        "         'batch_size':[5, 10, 15, 20, 30],\n",
        "         'epochs':[5, 10, 20, 30, 50]}\n",
        "\n",
        "    def autoencoder_model(noisy_input, pure_input, noisy_input_test, pure_input_test, params):\n",
        "\n",
        "        # Create the model\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(128, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini'], input_shape=input_shape))\n",
        "        model.add(Conv1D(64, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini']))\n",
        "        model.add(Conv1D(32, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini']))\n",
        "        model.add(Conv1DTranspose(32, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini']))\n",
        "        model.add(Conv1DTranspose(64, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini']))\n",
        "        model.add(Conv1DTranspose(128, kernel_size=3, activation=params['activation'], kernel_initializer=params['Kernel_ini']))\n",
        "        model.add(Conv1D(1, kernel_size=3, activation='sigmoid', padding='same'))\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(loss=params['loss'], optimizer=params['optimizer'](lr=lr_normalizer(params['lr'],params['optimizer'])), metrics=params['metrics'])\n",
        "\n",
        "        history = model.fit(noisy_input, pure_input, batch_size=params['batch_size'], epochs=params['epochs'], validation_data=(noisy_input_test, pure_input_test))\n",
        "\n",
        "        return history, model\n",
        "\n",
        "    scan_object = talos.Scan(x=noisy_input, y=pure_input, params=p, model=autoencoder_model, experiment_name='autoencoder', x_val=noisy_input_test, y_val=pure_input_test, val_split=validation_split,  fraction_limit=0.1)\n",
        "\n",
        "    return scan_object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "YfLa2FvwrW46",
        "outputId": "02b8a5de-2419-4eb9-9aec-be025aafb4b2"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUHL7EMfiNPI",
        "outputId": "00d6883d-0d04-4df6-ebb9-59885cc13b7b"
      },
      "source": [
        "scan_object= minimal(MRS_path,MRS_C_path, fs)\n",
        "    # accessing the results data frame\n",
        "scan_object.data.head()\n",
        "\n",
        "    # accessing epoch entropy values for each round\n",
        "scan_object.learning_entropy\n",
        "\n",
        "    # access the summary details\n",
        "scan_object.details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_3 (Conv1DTr (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_4 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_5 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 596ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2449 - val_mse: 1.2449\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 1.2449 - mse: 1.2449 - val_loss: 1.2449 - val_mse: 1.2449\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 1.2449 - mse: 1.2449 - val_loss: 1.2449 - val_mse: 1.2449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/200 [00:06<21:03,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 2s 216ms/step - loss: 1.3364 - mse: 1.3364 - val_loss: 1.2898 - val_mse: 1.2898\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2668 - mse: 1.2668 - val_loss: 1.2253 - val_mse: 1.2253\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2056 - mse: 1.2056 - val_loss: 1.1707 - val_mse: 1.1707\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.1548 - mse: 1.1548 - val_loss: 1.1273 - val_mse: 1.1273\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.1151 - mse: 1.1151 - val_loss: 1.0944 - val_mse: 1.0944\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0854 - mse: 1.0854 - val_loss: 1.0704 - val_mse: 1.0704\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0640 - mse: 1.0640 - val_loss: 1.0533 - val_mse: 1.0533\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.0488 - mse: 1.0488 - val_loss: 1.0413 - val_mse: 1.0413\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.0380 - mse: 1.0380 - val_loss: 1.0327 - val_mse: 1.0327\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.0303 - mse: 1.0303 - val_loss: 1.0265 - val_mse: 1.0265\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0248 - mse: 1.0248 - val_loss: 1.0220 - val_mse: 1.0220\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0207 - mse: 1.0207 - val_loss: 1.0186 - val_mse: 1.0186\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.0176 - mse: 1.0176 - val_loss: 1.0160 - val_mse: 1.0160\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 1.0139 - val_mse: 1.0139\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0133 - mse: 1.0133 - val_loss: 1.0123 - val_mse: 1.0123\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0117 - mse: 1.0117 - val_loss: 1.0109 - val_mse: 1.0109\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0105 - mse: 1.0105 - val_loss: 1.0098 - val_mse: 1.0098\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0094 - mse: 1.0094 - val_loss: 1.0089 - val_mse: 1.0089\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0085 - mse: 1.0085 - val_loss: 1.0080 - val_mse: 1.0080\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0077 - mse: 1.0077 - val_loss: 1.0074 - val_mse: 1.0074\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.0071 - mse: 1.0071 - val_loss: 1.0067 - val_mse: 1.0067\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 1.0062 - val_mse: 1.0062\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 1.0057 - val_mse: 1.0057\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.0055 - mse: 1.0055 - val_loss: 1.0053 - val_mse: 1.0053\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.0051 - mse: 1.0051 - val_loss: 1.0049 - val_mse: 1.0049\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0048 - mse: 1.0048 - val_loss: 1.0046 - val_mse: 1.0046\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.0044 - mse: 1.0044 - val_loss: 1.0043 - val_mse: 1.0043\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.0041 - mse: 1.0041 - val_loss: 1.0040 - val_mse: 1.0040\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0039 - mse: 1.0039 - val_loss: 1.0037 - val_mse: 1.0037\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 1.0035 - val_mse: 1.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/200 [00:32<58:32, 17.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 387ms/step - loss: 1.2517 - mse: 1.2517 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2512 - val_mse: 1.2512\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2512 - mse: 1.2512 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2499 - val_mse: 1.2499\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2500 - mse: 1.2500 - val_loss: 1.2497 - val_mse: 1.2497\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.2498 - mse: 1.2498 - val_loss: 1.2495 - val_mse: 1.2495\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2493 - val_mse: 1.2493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/200 [00:41<45:24, 13.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 226ms/step - loss: 1.2432 - mse: 1.2432 - val_loss: 1.2419 - val_mse: 1.2419\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2429 - mse: 1.2429 - val_loss: 1.2415 - val_mse: 1.2415\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2425 - mse: 1.2425 - val_loss: 1.2411 - val_mse: 1.2411\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2422 - mse: 1.2422 - val_loss: 1.2407 - val_mse: 1.2407\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2418 - mse: 1.2418 - val_loss: 1.2402 - val_mse: 1.2402\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2415 - mse: 1.2415 - val_loss: 1.2398 - val_mse: 1.2398\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2412 - mse: 1.2412 - val_loss: 1.2394 - val_mse: 1.2394\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.2408 - mse: 1.2408 - val_loss: 1.2390 - val_mse: 1.2390\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2405 - mse: 1.2405 - val_loss: 1.2386 - val_mse: 1.2386\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2401 - mse: 1.2401 - val_loss: 1.2382 - val_mse: 1.2382\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2398 - mse: 1.2398 - val_loss: 1.2378 - val_mse: 1.2378\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.2394 - mse: 1.2394 - val_loss: 1.2373 - val_mse: 1.2373\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2391 - mse: 1.2391 - val_loss: 1.2369 - val_mse: 1.2369\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2388 - mse: 1.2388 - val_loss: 1.2365 - val_mse: 1.2365\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2384 - mse: 1.2384 - val_loss: 1.2361 - val_mse: 1.2361\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2381 - mse: 1.2381 - val_loss: 1.2357 - val_mse: 1.2357\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2377 - mse: 1.2377 - val_loss: 1.2353 - val_mse: 1.2353\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.2374 - mse: 1.2374 - val_loss: 1.2349 - val_mse: 1.2349\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2370 - mse: 1.2370 - val_loss: 1.2344 - val_mse: 1.2344\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.2367 - mse: 1.2367 - val_loss: 1.2340 - val_mse: 1.2340\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2363 - mse: 1.2363 - val_loss: 1.2336 - val_mse: 1.2336\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2360 - mse: 1.2360 - val_loss: 1.2332 - val_mse: 1.2332\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.2356 - mse: 1.2356 - val_loss: 1.2327 - val_mse: 1.2327\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.2353 - mse: 1.2353 - val_loss: 1.2323 - val_mse: 1.2323\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2349 - mse: 1.2349 - val_loss: 1.2319 - val_mse: 1.2319\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2346 - mse: 1.2346 - val_loss: 1.2315 - val_mse: 1.2315\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.2342 - mse: 1.2342 - val_loss: 1.2310 - val_mse: 1.2310\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2339 - mse: 1.2339 - val_loss: 1.2306 - val_mse: 1.2306\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2335 - mse: 1.2335 - val_loss: 1.2302 - val_mse: 1.2302\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.2332 - mse: 1.2332 - val_loss: 1.2298 - val_mse: 1.2298\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2328 - mse: 1.2328 - val_loss: 1.2293 - val_mse: 1.2293\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2324 - mse: 1.2324 - val_loss: 1.2289 - val_mse: 1.2289\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2321 - mse: 1.2321 - val_loss: 1.2285 - val_mse: 1.2285\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2317 - mse: 1.2317 - val_loss: 1.2280 - val_mse: 1.2280\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2314 - mse: 1.2314 - val_loss: 1.2276 - val_mse: 1.2276\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2310 - mse: 1.2310 - val_loss: 1.2271 - val_mse: 1.2271\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2306 - mse: 1.2306 - val_loss: 1.2267 - val_mse: 1.2267\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2303 - mse: 1.2303 - val_loss: 1.2263 - val_mse: 1.2263\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.2299 - mse: 1.2299 - val_loss: 1.2258 - val_mse: 1.2258\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2295 - mse: 1.2295 - val_loss: 1.2254 - val_mse: 1.2254\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2292 - mse: 1.2292 - val_loss: 1.2249 - val_mse: 1.2249\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2288 - mse: 1.2288 - val_loss: 1.2245 - val_mse: 1.2245\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2284 - mse: 1.2284 - val_loss: 1.2240 - val_mse: 1.2240\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2280 - mse: 1.2280 - val_loss: 1.2236 - val_mse: 1.2236\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2277 - mse: 1.2277 - val_loss: 1.2231 - val_mse: 1.2231\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2273 - mse: 1.2273 - val_loss: 1.2227 - val_mse: 1.2227\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2269 - mse: 1.2269 - val_loss: 1.2222 - val_mse: 1.2222\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2265 - mse: 1.2265 - val_loss: 1.2217 - val_mse: 1.2217\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2261 - mse: 1.2261 - val_loss: 1.2213 - val_mse: 1.2213\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 1.2258 - mse: 1.2258 - val_loss: 1.2208 - val_mse: 1.2208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/200 [01:23<1:22:24, 25.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 389ms/step - loss: 1.2718 - mse: 1.2718 - val_loss: 1.2437 - val_mse: 1.2437\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2310 - mse: 1.2310 - val_loss: 1.2054 - val_mse: 1.2054\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.1939 - mse: 1.1939 - val_loss: 1.1712 - val_mse: 1.1712\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 1.1612 - mse: 1.1612 - val_loss: 1.1415 - val_mse: 1.1415\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.1329 - mse: 1.1329 - val_loss: 1.1162 - val_mse: 1.1162\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.1090 - mse: 1.1090 - val_loss: 1.0952 - val_mse: 1.0952\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.0893 - mse: 1.0893 - val_loss: 1.0779 - val_mse: 1.0779\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0732 - mse: 1.0732 - val_loss: 1.0640 - val_mse: 1.0640\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.0602 - mse: 1.0602 - val_loss: 1.0529 - val_mse: 1.0529\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.0498 - mse: 1.0498 - val_loss: 1.0440 - val_mse: 1.0440\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.0416 - mse: 1.0416 - val_loss: 1.0370 - val_mse: 1.0370\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.0351 - mse: 1.0351 - val_loss: 1.0314 - val_mse: 1.0314\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0298 - mse: 1.0298 - val_loss: 1.0269 - val_mse: 1.0269\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0257 - mse: 1.0257 - val_loss: 1.0233 - val_mse: 1.0233\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 1.0223 - mse: 1.0223 - val_loss: 1.0204 - val_mse: 1.0204\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.0196 - mse: 1.0196 - val_loss: 1.0180 - val_mse: 1.0180\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.0173 - mse: 1.0173 - val_loss: 1.0160 - val_mse: 1.0160\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 1.0144 - val_mse: 1.0144\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.0139 - mse: 1.0139 - val_loss: 1.0130 - val_mse: 1.0130\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.0126 - mse: 1.0126 - val_loss: 1.0118 - val_mse: 1.0118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 5/200 [01:41<1:12:49, 22.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 591ms/step - loss: 1.0888 - mse: 1.0888 - val_loss: 1.0887 - val_mse: 1.0887\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 1.0887 - mse: 1.0887 - val_loss: 1.0886 - val_mse: 1.0886\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.0885 - mse: 1.0885 - val_loss: 1.0884 - val_mse: 1.0884\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.0884 - mse: 1.0884 - val_loss: 1.0883 - val_mse: 1.0883\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.0883 - mse: 1.0883 - val_loss: 1.0882 - val_mse: 1.0882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 6/200 [01:47<54:48, 16.95s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 1.2379 - mse: 1.2379 - val_loss: 1.1582 - val_mse: 1.1582\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1425 - mse: 1.1425 - val_loss: 1.0725 - val_mse: 1.0725\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0588 - mse: 1.0588 - val_loss: 0.9888 - val_mse: 0.9888\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9867 - mse: 0.9867 - val_loss: 0.9236 - val_mse: 0.9236\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9359 - mse: 0.9359 - val_loss: 0.8828 - val_mse: 0.8828\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9038 - mse: 0.9038 - val_loss: 0.8570 - val_mse: 0.8570\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8821 - mse: 0.8821 - val_loss: 0.8378 - val_mse: 0.8378\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8662 - mse: 0.8662 - val_loss: 0.8226 - val_mse: 0.8226\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8548 - mse: 0.8548 - val_loss: 0.8129 - val_mse: 0.8129\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8454 - mse: 0.8454 - val_loss: 0.8039 - val_mse: 0.8039\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8382 - mse: 0.8382 - val_loss: 0.7949 - val_mse: 0.7949\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8324 - mse: 0.8324 - val_loss: 0.7957 - val_mse: 0.7957\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8276 - mse: 0.8276 - val_loss: 0.7852 - val_mse: 0.7852\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8236 - mse: 0.8236 - val_loss: 0.7852 - val_mse: 0.7852\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8196 - mse: 0.8196 - val_loss: 0.7785 - val_mse: 0.7785\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8159 - mse: 0.8159 - val_loss: 0.7772 - val_mse: 0.7772\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8123 - mse: 0.8123 - val_loss: 0.7707 - val_mse: 0.7707\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8087 - mse: 0.8087 - val_loss: 0.7772 - val_mse: 0.7772\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8074 - mse: 0.8074 - val_loss: 0.7648 - val_mse: 0.7648\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8033 - mse: 0.8033 - val_loss: 0.7620 - val_mse: 0.7620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 7/200 [02:09<59:32, 18.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 382ms/step - loss: 1.5035 - mse: 1.5035 - val_loss: 1.3289 - val_mse: 1.3289\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2864 - mse: 1.2864 - val_loss: 1.1506 - val_mse: 1.1506\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.1258 - mse: 1.1258 - val_loss: 1.0565 - val_mse: 1.0565\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0465 - mse: 1.0465 - val_loss: 1.0204 - val_mse: 1.0204\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0169 - mse: 1.0169 - val_loss: 1.0080 - val_mse: 1.0080\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.0067 - mse: 1.0067 - val_loss: 1.0035 - val_mse: 1.0035\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0029 - mse: 1.0029 - val_loss: 1.0016 - val_mse: 1.0016\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0013 - mse: 1.0013 - val_loss: 1.0007 - val_mse: 1.0007\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0006 - mse: 1.0006 - val_loss: 1.0003 - val_mse: 1.0003\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0002 - mse: 1.0002 - val_loss: 1.0000 - val_mse: 1.0000\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 0.9999 - val_mse: 0.9999\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 8/200 [02:27<58:33, 18.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 405ms/step - loss: 1.2454 - mse: 1.2454 - val_loss: 1.2441 - val_mse: 1.2441\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2438 - mse: 1.2438 - val_loss: 1.2425 - val_mse: 1.2425\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.2422 - mse: 1.2422 - val_loss: 1.2409 - val_mse: 1.2409\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2406 - mse: 1.2406 - val_loss: 1.2393 - val_mse: 1.2393\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2390 - mse: 1.2390 - val_loss: 1.2377 - val_mse: 1.2377\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.2374 - mse: 1.2374 - val_loss: 1.2361 - val_mse: 1.2361\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2358 - mse: 1.2358 - val_loss: 1.2345 - val_mse: 1.2345\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 1.2342 - mse: 1.2342 - val_loss: 1.2330 - val_mse: 1.2330\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 1.2314 - val_mse: 1.2314\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2311 - mse: 1.2311 - val_loss: 1.2298 - val_mse: 1.2298\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2295 - mse: 1.2295 - val_loss: 1.2283 - val_mse: 1.2283\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.2280 - mse: 1.2280 - val_loss: 1.2267 - val_mse: 1.2267\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.2264 - mse: 1.2264 - val_loss: 1.2252 - val_mse: 1.2252\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2249 - mse: 1.2249 - val_loss: 1.2237 - val_mse: 1.2237\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2233 - mse: 1.2233 - val_loss: 1.2222 - val_mse: 1.2222\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2218 - mse: 1.2218 - val_loss: 1.2206 - val_mse: 1.2206\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.2203 - mse: 1.2203 - val_loss: 1.2191 - val_mse: 1.2191\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2188 - mse: 1.2188 - val_loss: 1.2176 - val_mse: 1.2176\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.2173 - mse: 1.2173 - val_loss: 1.2161 - val_mse: 1.2161\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.2158 - mse: 1.2158 - val_loss: 1.2147 - val_mse: 1.2147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/200 [02:47<59:47, 18.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 375ms/step - loss: 1.2488 - mse: 1.2488 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.2488 - mse: 1.2488 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2491 - val_mse: 1.2491\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2491 - val_mse: 1.2491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 10/200 [02:53<47:20, 14.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 397ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 11/200 [03:35<1:13:24, 23.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 1.2741 - mse: 1.2741 - val_loss: 1.2611 - val_mse: 1.2611\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2648 - mse: 1.2648 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2552 - mse: 1.2552 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2294 - val_mse: 1.2294\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2346 - mse: 1.2346 - val_loss: 1.2191 - val_mse: 1.2191\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2243 - mse: 1.2243 - val_loss: 1.2095 - val_mse: 1.2095\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2142 - mse: 1.2142 - val_loss: 1.2006 - val_mse: 1.2006\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2046 - mse: 1.2046 - val_loss: 1.1915 - val_mse: 1.1915\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1953 - mse: 1.1953 - val_loss: 1.1818 - val_mse: 1.1818\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1860 - mse: 1.1860 - val_loss: 1.1712 - val_mse: 1.1712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 12/200 [03:46<1:00:51, 19.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 387ms/step - loss: 1.2671 - mse: 1.2671 - val_loss: 1.1468 - val_mse: 1.1468\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.1092 - mse: 1.1092 - val_loss: 1.0510 - val_mse: 1.0510\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.0372 - mse: 1.0372 - val_loss: 1.0171 - val_mse: 1.0171\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.0126 - mse: 1.0126 - val_loss: 1.0062 - val_mse: 1.0062\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 1.0025 - val_mse: 1.0025\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.0019 - mse: 1.0019 - val_loss: 1.0010 - val_mse: 1.0010\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 1.0004 - val_mse: 1.0004\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.0002 - mse: 1.0002 - val_loss: 1.0000 - val_mse: 1.0000\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 13/200 [04:28<1:21:55, 26.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 130ms/step - loss: 1.1772 - mse: 1.1772 - val_loss: 1.1403 - val_mse: 1.1403\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.1362 - mse: 1.1362 - val_loss: 1.0974 - val_mse: 1.0974\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.1022 - mse: 1.1022 - val_loss: 1.0627 - val_mse: 1.0627\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0751 - mse: 1.0751 - val_loss: 1.0351 - val_mse: 1.0351\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0537 - mse: 1.0537 - val_loss: 1.0136 - val_mse: 1.0136\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0370 - mse: 1.0370 - val_loss: 0.9966 - val_mse: 0.9966\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0237 - mse: 1.0237 - val_loss: 0.9831 - val_mse: 0.9831\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0131 - mse: 1.0131 - val_loss: 0.9722 - val_mse: 0.9722\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0046 - mse: 1.0046 - val_loss: 0.9633 - val_mse: 0.9633\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9976 - mse: 0.9976 - val_loss: 0.9559 - val_mse: 0.9559\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9917 - mse: 0.9917 - val_loss: 0.9497 - val_mse: 0.9497\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9868 - mse: 0.9868 - val_loss: 0.9444 - val_mse: 0.9444\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9825 - mse: 0.9825 - val_loss: 0.9398 - val_mse: 0.9398\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9789 - mse: 0.9789 - val_loss: 0.9358 - val_mse: 0.9358\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9757 - mse: 0.9757 - val_loss: 0.9323 - val_mse: 0.9323\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9729 - mse: 0.9729 - val_loss: 0.9292 - val_mse: 0.9292\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9704 - mse: 0.9704 - val_loss: 0.9265 - val_mse: 0.9265\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9681 - mse: 0.9681 - val_loss: 0.9240 - val_mse: 0.9240\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9661 - mse: 0.9661 - val_loss: 0.9217 - val_mse: 0.9217\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9642 - mse: 0.9642 - val_loss: 0.9196 - val_mse: 0.9196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 14/200 [04:49<1:17:06, 24.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 587ms/step - loss: 1.2145 - mse: 1.2145 - val_loss: 1.0698 - val_mse: 1.0698\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 1.0819 - mse: 1.0819 - val_loss: 0.9823 - val_mse: 0.9823\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 1.0145 - mse: 1.0145 - val_loss: 0.9443 - val_mse: 0.9443\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.9848 - mse: 0.9848 - val_loss: 0.9262 - val_mse: 0.9262\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.9700 - mse: 0.9700 - val_loss: 0.9159 - val_mse: 0.9159\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 0.9610 - mse: 0.9610 - val_loss: 0.9086 - val_mse: 0.9086\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 0.9539 - mse: 0.9539 - val_loss: 0.9024 - val_mse: 0.9024\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 0.9469 - mse: 0.9469 - val_loss: 0.8970 - val_mse: 0.8970\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9397 - mse: 0.9397 - val_loss: 0.8936 - val_mse: 0.8936\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 363ms/step - loss: 0.9341 - mse: 0.9341 - val_loss: 0.8921 - val_mse: 0.8921\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.9304 - mse: 0.9304 - val_loss: 0.8912 - val_mse: 0.8912\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.9275 - mse: 0.9275 - val_loss: 0.8903 - val_mse: 0.8903\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 0.9251 - mse: 0.9251 - val_loss: 0.8891 - val_mse: 0.8891\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.9227 - mse: 0.9227 - val_loss: 0.8876 - val_mse: 0.8876\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 0.9204 - mse: 0.9204 - val_loss: 0.8857 - val_mse: 0.8857\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.9180 - mse: 0.9180 - val_loss: 0.8836 - val_mse: 0.8836\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 383ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.8813 - val_mse: 0.8813\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 0.9131 - mse: 0.9131 - val_loss: 0.8789 - val_mse: 0.8789\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 0.9107 - mse: 0.9107 - val_loss: 0.8764 - val_mse: 0.8764\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.8739 - val_mse: 0.8739\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.9058 - mse: 0.9058 - val_loss: 0.8715 - val_mse: 0.8715\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.9033 - mse: 0.9033 - val_loss: 0.8690 - val_mse: 0.8690\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 0.9007 - mse: 0.9007 - val_loss: 0.8665 - val_mse: 0.8665\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 0.8980 - mse: 0.8980 - val_loss: 0.8640 - val_mse: 0.8640\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.8950 - mse: 0.8950 - val_loss: 0.8613 - val_mse: 0.8613\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.8920 - mse: 0.8920 - val_loss: 0.8585 - val_mse: 0.8585\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.8887 - mse: 0.8887 - val_loss: 0.8554 - val_mse: 0.8554\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 372ms/step - loss: 0.8853 - mse: 0.8853 - val_loss: 0.8520 - val_mse: 0.8520\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 0.8818 - mse: 0.8818 - val_loss: 0.8482 - val_mse: 0.8482\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.8784 - mse: 0.8784 - val_loss: 0.8445 - val_mse: 0.8445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 15/200 [05:32<1:32:41, 30.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 1.2392 - mse: 1.2392 - val_loss: 1.1904 - val_mse: 1.1904\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1862 - mse: 1.1862 - val_loss: 1.1367 - val_mse: 1.1367\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.1407 - mse: 1.1407 - val_loss: 1.0923 - val_mse: 1.0923\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1035 - mse: 1.1035 - val_loss: 1.0567 - val_mse: 1.0567\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0740 - mse: 1.0740 - val_loss: 1.0290 - val_mse: 1.0290\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0510 - mse: 1.0510 - val_loss: 1.0076 - val_mse: 1.0076\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0331 - mse: 1.0331 - val_loss: 0.9912 - val_mse: 0.9912\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0190 - mse: 1.0190 - val_loss: 0.9783 - val_mse: 0.9783\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.0075 - mse: 1.0075 - val_loss: 0.9679 - val_mse: 0.9679\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9979 - mse: 0.9979 - val_loss: 0.9594 - val_mse: 0.9594\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9895 - mse: 0.9895 - val_loss: 0.9523 - val_mse: 0.9523\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.9822 - mse: 0.9822 - val_loss: 0.9459 - val_mse: 0.9459\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9757 - mse: 0.9757 - val_loss: 0.9402 - val_mse: 0.9402\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9699 - mse: 0.9699 - val_loss: 0.9347 - val_mse: 0.9347\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9646 - mse: 0.9646 - val_loss: 0.9294 - val_mse: 0.9294\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9595 - mse: 0.9595 - val_loss: 0.9243 - val_mse: 0.9243\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9547 - mse: 0.9547 - val_loss: 0.9193 - val_mse: 0.9193\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9501 - mse: 0.9501 - val_loss: 0.9145 - val_mse: 0.9145\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.9099 - val_mse: 0.9099\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.9055 - val_mse: 0.9055\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9371 - mse: 0.9371 - val_loss: 0.9011 - val_mse: 0.9011\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9331 - mse: 0.9331 - val_loss: 0.8971 - val_mse: 0.8971\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9291 - mse: 0.9291 - val_loss: 0.8932 - val_mse: 0.8932\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9253 - mse: 0.9253 - val_loss: 0.8894 - val_mse: 0.8894\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9215 - mse: 0.9215 - val_loss: 0.8857 - val_mse: 0.8857\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.9179 - mse: 0.9179 - val_loss: 0.8821 - val_mse: 0.8821\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.9143 - mse: 0.9143 - val_loss: 0.8785 - val_mse: 0.8785\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.8750 - val_mse: 0.8750\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9074 - mse: 0.9074 - val_loss: 0.8719 - val_mse: 0.8719\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9040 - mse: 0.9040 - val_loss: 0.8686 - val_mse: 0.8686\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.9008 - mse: 0.9008 - val_loss: 0.8654 - val_mse: 0.8654\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8977 - mse: 0.8977 - val_loss: 0.8626 - val_mse: 0.8626\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8948 - mse: 0.8948 - val_loss: 0.8598 - val_mse: 0.8598\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8920 - mse: 0.8920 - val_loss: 0.8571 - val_mse: 0.8571\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8893 - mse: 0.8893 - val_loss: 0.8546 - val_mse: 0.8546\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8868 - mse: 0.8868 - val_loss: 0.8522 - val_mse: 0.8522\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8843 - mse: 0.8843 - val_loss: 0.8499 - val_mse: 0.8499\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.8820 - mse: 0.8820 - val_loss: 0.8480 - val_mse: 0.8480\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.8798 - mse: 0.8798 - val_loss: 0.8459 - val_mse: 0.8459\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.8777 - mse: 0.8777 - val_loss: 0.8439 - val_mse: 0.8439\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8757 - mse: 0.8757 - val_loss: 0.8420 - val_mse: 0.8420\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8738 - mse: 0.8738 - val_loss: 0.8402 - val_mse: 0.8402\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8719 - mse: 0.8719 - val_loss: 0.8385 - val_mse: 0.8385\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8701 - mse: 0.8701 - val_loss: 0.8369 - val_mse: 0.8369\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.8684 - mse: 0.8684 - val_loss: 0.8352 - val_mse: 0.8352\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8667 - mse: 0.8667 - val_loss: 0.8336 - val_mse: 0.8336\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8651 - mse: 0.8651 - val_loss: 0.8321 - val_mse: 0.8321\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8635 - mse: 0.8635 - val_loss: 0.8307 - val_mse: 0.8307\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8620 - mse: 0.8620 - val_loss: 0.8294 - val_mse: 0.8294\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8606 - mse: 0.8606 - val_loss: 0.8280 - val_mse: 0.8280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 16/200 [06:21<1:50:20, 35.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 362ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2425 - val_mse: 1.2425\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.2438 - mse: 1.2438 - val_loss: 1.2400 - val_mse: 1.2400\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.2418 - mse: 1.2418 - val_loss: 1.2374 - val_mse: 1.2374\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.2397 - mse: 1.2397 - val_loss: 1.2349 - val_mse: 1.2349\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.2376 - mse: 1.2376 - val_loss: 1.2324 - val_mse: 1.2324\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2355 - mse: 1.2355 - val_loss: 1.2299 - val_mse: 1.2299\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.2334 - mse: 1.2334 - val_loss: 1.2273 - val_mse: 1.2273\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2313 - mse: 1.2313 - val_loss: 1.2247 - val_mse: 1.2247\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.2292 - mse: 1.2292 - val_loss: 1.2221 - val_mse: 1.2221\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.2271 - mse: 1.2271 - val_loss: 1.2195 - val_mse: 1.2195\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.2249 - mse: 1.2249 - val_loss: 1.2168 - val_mse: 1.2168\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.2227 - mse: 1.2227 - val_loss: 1.2141 - val_mse: 1.2141\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 1.2204 - mse: 1.2204 - val_loss: 1.2113 - val_mse: 1.2113\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2181 - mse: 1.2181 - val_loss: 1.2085 - val_mse: 1.2085\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.2158 - mse: 1.2158 - val_loss: 1.2056 - val_mse: 1.2056\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.2134 - mse: 1.2134 - val_loss: 1.2027 - val_mse: 1.2027\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.2109 - mse: 1.2109 - val_loss: 1.1997 - val_mse: 1.1997\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.2084 - mse: 1.2084 - val_loss: 1.1966 - val_mse: 1.1966\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.2058 - mse: 1.2058 - val_loss: 1.1934 - val_mse: 1.1934\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2032 - mse: 1.2032 - val_loss: 1.1902 - val_mse: 1.1902\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.2005 - mse: 1.2005 - val_loss: 1.1869 - val_mse: 1.1869\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.1977 - mse: 1.1977 - val_loss: 1.1835 - val_mse: 1.1835\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.1948 - mse: 1.1948 - val_loss: 1.1800 - val_mse: 1.1800\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.1919 - mse: 1.1919 - val_loss: 1.1764 - val_mse: 1.1764\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.1889 - mse: 1.1889 - val_loss: 1.1727 - val_mse: 1.1727\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.1858 - mse: 1.1858 - val_loss: 1.1689 - val_mse: 1.1689\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.1826 - mse: 1.1826 - val_loss: 1.1651 - val_mse: 1.1651\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.1793 - mse: 1.1793 - val_loss: 1.1611 - val_mse: 1.1611\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.1759 - mse: 1.1759 - val_loss: 1.1571 - val_mse: 1.1571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 17/200 [07:03<1:55:20, 37.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 394ms/step - loss: 1.1230 - mse: 1.1230 - val_loss: 1.1228 - val_mse: 1.1228\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.1227 - mse: 1.1227 - val_loss: 1.1226 - val_mse: 1.1226\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.1225 - mse: 1.1225 - val_loss: 1.1223 - val_mse: 1.1223\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.1222 - mse: 1.1222 - val_loss: 1.1221 - val_mse: 1.1221\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.1220 - mse: 1.1220 - val_loss: 1.1218 - val_mse: 1.1218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 18/200 [07:10<1:25:56, 28.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 129ms/step - loss: 1.2901 - mse: 1.2901 - val_loss: 1.2814 - val_mse: 1.2814\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2887 - mse: 1.2887 - val_loss: 1.2801 - val_mse: 1.2801\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2873 - mse: 1.2873 - val_loss: 1.2788 - val_mse: 1.2788\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2859 - mse: 1.2859 - val_loss: 1.2775 - val_mse: 1.2775\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2845 - mse: 1.2845 - val_loss: 1.2762 - val_mse: 1.2762\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2831 - mse: 1.2831 - val_loss: 1.2748 - val_mse: 1.2748\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2817 - mse: 1.2817 - val_loss: 1.2735 - val_mse: 1.2735\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2803 - mse: 1.2803 - val_loss: 1.2722 - val_mse: 1.2722\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2788 - mse: 1.2788 - val_loss: 1.2708 - val_mse: 1.2708\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2774 - mse: 1.2774 - val_loss: 1.2694 - val_mse: 1.2694\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2760 - mse: 1.2760 - val_loss: 1.2680 - val_mse: 1.2680\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2745 - mse: 1.2745 - val_loss: 1.2666 - val_mse: 1.2666\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2731 - mse: 1.2731 - val_loss: 1.2652 - val_mse: 1.2652\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2716 - mse: 1.2716 - val_loss: 1.2638 - val_mse: 1.2638\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2702 - mse: 1.2702 - val_loss: 1.2624 - val_mse: 1.2624\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2687 - mse: 1.2687 - val_loss: 1.2610 - val_mse: 1.2610\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2673 - mse: 1.2673 - val_loss: 1.2596 - val_mse: 1.2596\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2658 - mse: 1.2658 - val_loss: 1.2582 - val_mse: 1.2582\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2644 - mse: 1.2644 - val_loss: 1.2568 - val_mse: 1.2568\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2630 - mse: 1.2630 - val_loss: 1.2554 - val_mse: 1.2554\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2615 - mse: 1.2615 - val_loss: 1.2541 - val_mse: 1.2541\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2601 - mse: 1.2601 - val_loss: 1.2527 - val_mse: 1.2527\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2587 - mse: 1.2587 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2573 - mse: 1.2573 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2559 - mse: 1.2559 - val_loss: 1.2488 - val_mse: 1.2488\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2532 - mse: 1.2532 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2518 - mse: 1.2518 - val_loss: 1.2448 - val_mse: 1.2448\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2435 - val_mse: 1.2435\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2491 - mse: 1.2491 - val_loss: 1.2421 - val_mse: 1.2421\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2408 - val_mse: 1.2408\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2395 - val_mse: 1.2395\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2451 - mse: 1.2451 - val_loss: 1.2381 - val_mse: 1.2381\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2437 - mse: 1.2437 - val_loss: 1.2368 - val_mse: 1.2368\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2424 - mse: 1.2424 - val_loss: 1.2354 - val_mse: 1.2354\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2410 - mse: 1.2410 - val_loss: 1.2340 - val_mse: 1.2340\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2397 - mse: 1.2397 - val_loss: 1.2327 - val_mse: 1.2327\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2383 - mse: 1.2383 - val_loss: 1.2313 - val_mse: 1.2313\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2369 - mse: 1.2369 - val_loss: 1.2299 - val_mse: 1.2299\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2356 - mse: 1.2356 - val_loss: 1.2285 - val_mse: 1.2285\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2342 - mse: 1.2342 - val_loss: 1.2270 - val_mse: 1.2270\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2328 - mse: 1.2328 - val_loss: 1.2256 - val_mse: 1.2256\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2314 - mse: 1.2314 - val_loss: 1.2241 - val_mse: 1.2241\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2300 - mse: 1.2300 - val_loss: 1.2225 - val_mse: 1.2225\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2285 - mse: 1.2285 - val_loss: 1.2209 - val_mse: 1.2209\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2271 - mse: 1.2271 - val_loss: 1.2193 - val_mse: 1.2193\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2256 - mse: 1.2256 - val_loss: 1.2176 - val_mse: 1.2176\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2242 - mse: 1.2242 - val_loss: 1.2159 - val_mse: 1.2159\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2227 - mse: 1.2227 - val_loss: 1.2141 - val_mse: 1.2141\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 1.2123 - val_mse: 1.2123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 19/200 [08:33<2:15:04, 44.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "9/9 [==============================] - 2s 143ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2495 - val_mse: 1.2495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 20/200 [08:44<1:44:19, 34.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 411ms/step - loss: 1.4763 - mse: 1.4763 - val_loss: 1.4460 - val_mse: 1.4460\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.4313 - mse: 1.4313 - val_loss: 1.4010 - val_mse: 1.4010\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.3864 - mse: 1.3864 - val_loss: 1.3566 - val_mse: 1.3566\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.3425 - mse: 1.3425 - val_loss: 1.3138 - val_mse: 1.3138\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.3003 - mse: 1.3003 - val_loss: 1.2732 - val_mse: 1.2732\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2607 - mse: 1.2607 - val_loss: 1.2356 - val_mse: 1.2356\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2242 - mse: 1.2242 - val_loss: 1.2015 - val_mse: 1.2015\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.1912 - mse: 1.1912 - val_loss: 1.1711 - val_mse: 1.1711\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.1622 - mse: 1.1622 - val_loss: 1.1448 - val_mse: 1.1448\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.1371 - mse: 1.1371 - val_loss: 1.1222 - val_mse: 1.1222\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.1157 - mse: 1.1157 - val_loss: 1.1032 - val_mse: 1.1032\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.0977 - mse: 1.0977 - val_loss: 1.0873 - val_mse: 1.0873\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.0828 - mse: 1.0828 - val_loss: 1.0743 - val_mse: 1.0743\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.0705 - mse: 1.0705 - val_loss: 1.0635 - val_mse: 1.0635\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.0604 - mse: 1.0604 - val_loss: 1.0547 - val_mse: 1.0547\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.0522 - mse: 1.0522 - val_loss: 1.0475 - val_mse: 1.0475\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.0454 - mse: 1.0454 - val_loss: 1.0415 - val_mse: 1.0415\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.0398 - mse: 1.0398 - val_loss: 1.0366 - val_mse: 1.0366\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.0352 - mse: 1.0352 - val_loss: 1.0325 - val_mse: 1.0325\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0313 - mse: 1.0313 - val_loss: 1.0291 - val_mse: 1.0291\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.0281 - mse: 1.0281 - val_loss: 1.0262 - val_mse: 1.0262\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.0253 - mse: 1.0253 - val_loss: 1.0238 - val_mse: 1.0238\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 1.0230 - mse: 1.0230 - val_loss: 1.0217 - val_mse: 1.0217\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.0210 - mse: 1.0210 - val_loss: 1.0199 - val_mse: 1.0199\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.0193 - mse: 1.0193 - val_loss: 1.0183 - val_mse: 1.0183\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.0178 - mse: 1.0178 - val_loss: 1.0170 - val_mse: 1.0170\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.0165 - mse: 1.0165 - val_loss: 1.0158 - val_mse: 1.0158\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 1.0147 - val_mse: 1.0147\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.0143 - mse: 1.0143 - val_loss: 1.0138 - val_mse: 1.0138\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.0134 - mse: 1.0134 - val_loss: 1.0129 - val_mse: 1.0129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 21/200 [09:26<1:50:26, 37.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "9/9 [==============================] - 2s 137ms/step - loss: 1.0720 - mse: 1.0720 - val_loss: 1.0086 - val_mse: 1.0086\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.0034 - mse: 1.0034 - val_loss: 1.0005 - val_mse: 1.0005\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 22/200 [09:33<1:22:32, 27.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 236ms/step - loss: 1.6504 - mse: 1.6504 - val_loss: 1.6461 - val_mse: 1.6461\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.6439 - mse: 1.6439 - val_loss: 1.6395 - val_mse: 1.6395\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.6372 - mse: 1.6372 - val_loss: 1.6328 - val_mse: 1.6328\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.6305 - mse: 1.6305 - val_loss: 1.6260 - val_mse: 1.6260\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.6237 - mse: 1.6237 - val_loss: 1.6192 - val_mse: 1.6192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 23/200 [09:39<1:03:06, 21.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 429ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2439 - val_mse: 1.2439\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.2391 - val_mse: 1.2391\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2383 - mse: 1.2383 - val_loss: 1.2344 - val_mse: 1.2344\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2337 - mse: 1.2337 - val_loss: 1.2295 - val_mse: 1.2295\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.2289 - mse: 1.2289 - val_loss: 1.2239 - val_mse: 1.2239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 24/200 [09:46<49:31, 16.89s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 136ms/step - loss: 1.2625 - mse: 1.2625 - val_loss: 1.0530 - val_mse: 1.0530\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.0209 - mse: 1.0209 - val_loss: 1.0039 - val_mse: 1.0039\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0018 - mse: 1.0018 - val_loss: 1.0005 - val_mse: 1.0005\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9999 - val_mse: 0.9999\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 25/200 [10:07<53:30, 18.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 2s 243ms/step - loss: 1.1291 - mse: 1.1291 - val_loss: 0.9938 - val_mse: 0.9938\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.0071 - mse: 1.0071 - val_loss: 0.9345 - val_mse: 0.9345\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.9708 - mse: 0.9708 - val_loss: 0.9146 - val_mse: 0.9146\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.9584 - mse: 0.9584 - val_loss: 0.9057 - val_mse: 0.9057\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.9523 - mse: 0.9523 - val_loss: 0.9005 - val_mse: 0.9005\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.9485 - mse: 0.9485 - val_loss: 0.8971 - val_mse: 0.8971\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8945 - val_mse: 0.8945\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.9434 - mse: 0.9434 - val_loss: 0.8924 - val_mse: 0.8924\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.9414 - mse: 0.9414 - val_loss: 0.8907 - val_mse: 0.8907\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.9397 - mse: 0.9397 - val_loss: 0.8892 - val_mse: 0.8892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 26/200 [10:18<46:09, 15.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 237ms/step - loss: 1.3073 - mse: 1.3073 - val_loss: 1.1174 - val_mse: 1.1174\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 1.0710 - mse: 1.0710 - val_loss: 1.0205 - val_mse: 1.0205\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0127 - mse: 1.0127 - val_loss: 1.0044 - val_mse: 1.0044\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0029 - mse: 1.0029 - val_loss: 1.0012 - val_mse: 1.0012\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 1.0002 - val_mse: 1.0002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 27/200 [10:23<37:09, 12.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 598ms/step - loss: 1.2416 - mse: 1.2416 - val_loss: 1.2232 - val_mse: 1.2232\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.2245 - mse: 1.2245 - val_loss: 1.2022 - val_mse: 1.2022\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.2072 - mse: 1.2072 - val_loss: 1.1804 - val_mse: 1.1804\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.1887 - mse: 1.1887 - val_loss: 1.1575 - val_mse: 1.1575\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.1692 - mse: 1.1692 - val_loss: 1.1333 - val_mse: 1.1333\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 1.1487 - mse: 1.1487 - val_loss: 1.1080 - val_mse: 1.1080\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 1.1268 - mse: 1.1268 - val_loss: 1.0819 - val_mse: 1.0819\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 1.1042 - mse: 1.1042 - val_loss: 1.0556 - val_mse: 1.0556\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 1.0814 - mse: 1.0814 - val_loss: 1.0297 - val_mse: 1.0297\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 1.0591 - mse: 1.0591 - val_loss: 1.0052 - val_mse: 1.0052\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 1.0377 - mse: 1.0377 - val_loss: 0.9827 - val_mse: 0.9827\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 1.0185 - mse: 1.0185 - val_loss: 0.9628 - val_mse: 0.9628\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 1.0013 - mse: 1.0013 - val_loss: 0.9459 - val_mse: 0.9459\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.9870 - mse: 0.9870 - val_loss: 0.9320 - val_mse: 0.9320\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.9209 - val_mse: 0.9209\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.9656 - mse: 0.9656 - val_loss: 0.9121 - val_mse: 0.9121\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.9583 - mse: 0.9583 - val_loss: 0.9054 - val_mse: 0.9054\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.9526 - mse: 0.9526 - val_loss: 0.9002 - val_mse: 0.9002\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 0.9483 - mse: 0.9483 - val_loss: 0.8962 - val_mse: 0.8962\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 0.9449 - mse: 0.9449 - val_loss: 0.8931 - val_mse: 0.8931\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.9424 - mse: 0.9424 - val_loss: 0.8907 - val_mse: 0.8907\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.9403 - mse: 0.9403 - val_loss: 0.8888 - val_mse: 0.8888\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.9387 - mse: 0.9387 - val_loss: 0.8872 - val_mse: 0.8872\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9373 - mse: 0.9373 - val_loss: 0.8858 - val_mse: 0.8858\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.9362 - mse: 0.9362 - val_loss: 0.8847 - val_mse: 0.8847\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.9352 - mse: 0.9352 - val_loss: 0.8837 - val_mse: 0.8837\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.8828 - val_mse: 0.8828\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8820 - val_mse: 0.8820\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.9328 - mse: 0.9328 - val_loss: 0.8812 - val_mse: 0.8812\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 333ms/step - loss: 0.9321 - mse: 0.9321 - val_loss: 0.8805 - val_mse: 0.8805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 28/200 [11:06<1:02:10, 21.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 463ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 29/200 [11:12<48:33, 17.04s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 140ms/step - loss: 1.0794 - mse: 1.0794 - val_loss: 0.8906 - val_mse: 0.8906\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9349 - mse: 0.9349 - val_loss: 0.8782 - val_mse: 0.8782\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9280 - mse: 0.9280 - val_loss: 0.8719 - val_mse: 0.8719\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9220 - mse: 0.9220 - val_loss: 0.8695 - val_mse: 0.8695\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9183 - mse: 0.9183 - val_loss: 0.8674 - val_mse: 0.8674\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9141 - mse: 0.9141 - val_loss: 0.8679 - val_mse: 0.8679\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8990 - mse: 0.8990 - val_loss: 0.8542 - val_mse: 0.8542\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8648 - mse: 0.8648 - val_loss: 0.8385 - val_mse: 0.8385\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8487 - mse: 0.8487 - val_loss: 0.8275 - val_mse: 0.8275\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8401 - mse: 0.8401 - val_loss: 0.8194 - val_mse: 0.8194\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8349 - mse: 0.8349 - val_loss: 0.8168 - val_mse: 0.8168\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8302 - mse: 0.8302 - val_loss: 0.8111 - val_mse: 0.8111\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8256 - mse: 0.8256 - val_loss: 0.8038 - val_mse: 0.8038\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8201 - mse: 0.8201 - val_loss: 0.7959 - val_mse: 0.7959\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.8145 - mse: 0.8145 - val_loss: 0.7918 - val_mse: 0.7918\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8088 - mse: 0.8088 - val_loss: 0.7832 - val_mse: 0.7832\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8021 - mse: 0.8021 - val_loss: 0.7739 - val_mse: 0.7739\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7952 - mse: 0.7952 - val_loss: 0.7644 - val_mse: 0.7644\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7891 - mse: 0.7891 - val_loss: 0.7534 - val_mse: 0.7534\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7828 - mse: 0.7828 - val_loss: 0.7510 - val_mse: 0.7510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 30/200 [11:33<51:30, 18.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 241ms/step - loss: 1.1199 - mse: 1.1199 - val_loss: 1.0938 - val_mse: 1.0938\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.1177 - mse: 1.1177 - val_loss: 1.0913 - val_mse: 1.0913\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.1155 - mse: 1.1155 - val_loss: 1.0888 - val_mse: 1.0888\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.1134 - mse: 1.1134 - val_loss: 1.0864 - val_mse: 1.0864\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.1112 - mse: 1.1112 - val_loss: 1.0839 - val_mse: 1.0839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 31/200 [11:39<41:14, 14.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 445ms/step - loss: 1.4955 - mse: 1.4955 - val_loss: 1.5204 - val_mse: 1.5204\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.4932 - mse: 1.4932 - val_loss: 1.5178 - val_mse: 1.5178\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.4908 - mse: 1.4908 - val_loss: 1.5152 - val_mse: 1.5152\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.4885 - mse: 1.4885 - val_loss: 1.5126 - val_mse: 1.5126\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.4862 - mse: 1.4862 - val_loss: 1.5100 - val_mse: 1.5100\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.4839 - mse: 1.4839 - val_loss: 1.5074 - val_mse: 1.5074\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.4815 - mse: 1.4815 - val_loss: 1.5048 - val_mse: 1.5048\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.4792 - mse: 1.4792 - val_loss: 1.5022 - val_mse: 1.5022\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.4769 - mse: 1.4769 - val_loss: 1.4996 - val_mse: 1.4996\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.4746 - mse: 1.4746 - val_loss: 1.4970 - val_mse: 1.4970\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.4722 - mse: 1.4722 - val_loss: 1.4944 - val_mse: 1.4944\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.4699 - mse: 1.4699 - val_loss: 1.4918 - val_mse: 1.4918\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.4675 - mse: 1.4675 - val_loss: 1.4892 - val_mse: 1.4892\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.4652 - mse: 1.4652 - val_loss: 1.4866 - val_mse: 1.4866\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.4629 - mse: 1.4629 - val_loss: 1.4840 - val_mse: 1.4840\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.4606 - mse: 1.4606 - val_loss: 1.4814 - val_mse: 1.4814\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.4582 - mse: 1.4582 - val_loss: 1.4788 - val_mse: 1.4788\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.4559 - mse: 1.4559 - val_loss: 1.4762 - val_mse: 1.4762\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.4536 - mse: 1.4536 - val_loss: 1.4736 - val_mse: 1.4736\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.4512 - mse: 1.4512 - val_loss: 1.4710 - val_mse: 1.4710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 32/200 [11:59<45:07, 16.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 381ms/step - loss: 1.0931 - mse: 1.0931 - val_loss: 1.0368 - val_mse: 1.0368\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.0294 - mse: 1.0294 - val_loss: 1.0112 - val_mse: 1.0112\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.0090 - mse: 1.0090 - val_loss: 1.0037 - val_mse: 1.0037\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0030 - mse: 1.0030 - val_loss: 1.0012 - val_mse: 1.0012\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0009 - mse: 1.0009 - val_loss: 1.0003 - val_mse: 1.0003\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 33/200 [13:22<1:40:53, 36.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 2s 247ms/step - loss: 1.3470 - mse: 1.3470 - val_loss: 1.2964 - val_mse: 1.2964\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2715 - mse: 1.2715 - val_loss: 1.2266 - val_mse: 1.2266\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2054 - mse: 1.2054 - val_loss: 1.1682 - val_mse: 1.1682\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.1514 - mse: 1.1514 - val_loss: 1.1227 - val_mse: 1.1227\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.1101 - mse: 1.1101 - val_loss: 1.0891 - val_mse: 1.0891\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.0801 - mse: 1.0801 - val_loss: 1.0653 - val_mse: 1.0653\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.0591 - mse: 1.0591 - val_loss: 1.0488 - val_mse: 1.0488\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0445 - mse: 1.0445 - val_loss: 1.0375 - val_mse: 1.0375\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.0345 - mse: 1.0345 - val_loss: 1.0296 - val_mse: 1.0296\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.0274 - mse: 1.0274 - val_loss: 1.0239 - val_mse: 1.0239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 34/200 [13:33<1:19:49, 28.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 607ms/step - loss: 1.1685 - mse: 1.1685 - val_loss: 1.0949 - val_mse: 1.0949\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.0856 - mse: 1.0856 - val_loss: 1.0450 - val_mse: 1.0450\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 1.0404 - mse: 1.0404 - val_loss: 1.0211 - val_mse: 1.0211\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 1.0190 - mse: 1.0190 - val_loss: 1.0102 - val_mse: 1.0102\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.0092 - mse: 1.0092 - val_loss: 1.0052 - val_mse: 1.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 35/200 [13:40<1:00:55, 22.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 414ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2473 - val_mse: 1.2473\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2473 - val_mse: 1.2473\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2473 - val_mse: 1.2473\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.2473 - mse: 1.2473 - val_loss: 1.2471 - val_mse: 1.2471\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2473 - mse: 1.2473 - val_loss: 1.2471 - val_mse: 1.2471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 36/200 [13:52<51:53, 18.98s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 420ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2484 - val_mse: 1.2484\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2484 - val_mse: 1.2484\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2483 - val_mse: 1.2483\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 1.2483 - val_mse: 1.2483\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 1.2483 - val_mse: 1.2483\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2479 - val_mse: 1.2479\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2479 - mse: 1.2479 - val_loss: 1.2479 - val_mse: 1.2479\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2479 - mse: 1.2479 - val_loss: 1.2479 - val_mse: 1.2479\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.2479 - mse: 1.2479 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 37/200 [14:34<1:10:38, 26.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2479 - val_mse: 1.2479\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 1.2479 - mse: 1.2479 - val_loss: 1.2479 - val_mse: 1.2479\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2479 - mse: 1.2479 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 204ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 202ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2473 - mse: 1.2473 - val_loss: 1.2473 - val_mse: 1.2473\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 1.2473 - mse: 1.2473 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2472 - mse: 1.2472 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 1.2472 - mse: 1.2472 - val_loss: 1.2471 - val_mse: 1.2471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 38/200 [14:56<1:06:50, 24.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 450ms/step - loss: 1.2215 - mse: 1.2215 - val_loss: 1.1247 - val_mse: 1.1247\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.1050 - mse: 1.1050 - val_loss: 0.9889 - val_mse: 0.9889\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.9979 - mse: 0.9979 - val_loss: 0.9064 - val_mse: 0.9064\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.9462 - mse: 0.9462 - val_loss: 0.8858 - val_mse: 0.8858\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 0.9356 - mse: 0.9356 - val_loss: 0.8817 - val_mse: 0.8817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 39/200 [15:02<51:41, 19.26s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 387ms/step - loss: 1.6533 - mse: 1.6533 - val_loss: 1.6503 - val_mse: 1.6503\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.6494 - mse: 1.6494 - val_loss: 1.6463 - val_mse: 1.6463\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.6455 - mse: 1.6455 - val_loss: 1.6424 - val_mse: 1.6424\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.6416 - mse: 1.6416 - val_loss: 1.6384 - val_mse: 1.6384\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.6376 - mse: 1.6376 - val_loss: 1.6344 - val_mse: 1.6344\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.6336 - mse: 1.6336 - val_loss: 1.6304 - val_mse: 1.6304\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.6296 - mse: 1.6296 - val_loss: 1.6264 - val_mse: 1.6264\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.6255 - mse: 1.6255 - val_loss: 1.6223 - val_mse: 1.6223\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.6214 - mse: 1.6214 - val_loss: 1.6181 - val_mse: 1.6181\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.6173 - mse: 1.6173 - val_loss: 1.6140 - val_mse: 1.6140\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.6131 - mse: 1.6131 - val_loss: 1.6098 - val_mse: 1.6098\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.6089 - mse: 1.6089 - val_loss: 1.6056 - val_mse: 1.6056\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.6047 - mse: 1.6047 - val_loss: 1.6013 - val_mse: 1.6013\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.6004 - mse: 1.6004 - val_loss: 1.5971 - val_mse: 1.5971\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 1.5962 - mse: 1.5962 - val_loss: 1.5927 - val_mse: 1.5927\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.5918 - mse: 1.5918 - val_loss: 1.5884 - val_mse: 1.5884\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.5875 - mse: 1.5875 - val_loss: 1.5840 - val_mse: 1.5840\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.5831 - mse: 1.5831 - val_loss: 1.5796 - val_mse: 1.5796\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.5787 - mse: 1.5787 - val_loss: 1.5752 - val_mse: 1.5752\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.5743 - mse: 1.5743 - val_loss: 1.5707 - val_mse: 1.5707\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.5698 - mse: 1.5698 - val_loss: 1.5662 - val_mse: 1.5662\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.5653 - mse: 1.5653 - val_loss: 1.5617 - val_mse: 1.5617\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.5608 - mse: 1.5608 - val_loss: 1.5572 - val_mse: 1.5572\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.5562 - mse: 1.5562 - val_loss: 1.5526 - val_mse: 1.5526\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.5516 - mse: 1.5516 - val_loss: 1.5480 - val_mse: 1.5480\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.5470 - mse: 1.5470 - val_loss: 1.5434 - val_mse: 1.5434\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.5424 - mse: 1.5424 - val_loss: 1.5388 - val_mse: 1.5388\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.5378 - mse: 1.5378 - val_loss: 1.5341 - val_mse: 1.5341\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.5331 - mse: 1.5331 - val_loss: 1.5294 - val_mse: 1.5294\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 1.5284 - mse: 1.5284 - val_loss: 1.5247 - val_mse: 1.5247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 40/200 [15:44<1:09:46, 26.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 2s 272ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 203ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 206ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 204ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 202ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 200ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 209ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 202ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 203ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 203ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 202ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 205ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 204ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 41/200 [16:16<1:13:49, 27.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 389ms/step - loss: 1.2419 - mse: 1.2419 - val_loss: 1.2377 - val_mse: 1.2377\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 1.2347 - val_mse: 1.2347\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2371 - mse: 1.2371 - val_loss: 1.2318 - val_mse: 1.2318\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2347 - mse: 1.2347 - val_loss: 1.2288 - val_mse: 1.2288\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2322 - mse: 1.2322 - val_loss: 1.2259 - val_mse: 1.2259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 42/200 [16:23<56:25, 21.43s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 266ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 205ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 205ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 43/200 [16:34<48:20, 18.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 440ms/step - loss: 1.0979 - mse: 1.0979 - val_loss: 1.0978 - val_mse: 1.0978\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 307ms/step - loss: 1.0977 - mse: 1.0977 - val_loss: 1.0976 - val_mse: 1.0976\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 308ms/step - loss: 1.0975 - mse: 1.0975 - val_loss: 1.0974 - val_mse: 1.0974\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.0973 - mse: 1.0973 - val_loss: 1.0972 - val_mse: 1.0972\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 1.0971 - mse: 1.0971 - val_loss: 1.0969 - val_mse: 1.0969\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 1.0969 - mse: 1.0969 - val_loss: 1.0967 - val_mse: 1.0967\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.0967 - mse: 1.0967 - val_loss: 1.0965 - val_mse: 1.0965\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.0965 - mse: 1.0965 - val_loss: 1.0963 - val_mse: 1.0963\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.0962 - mse: 1.0962 - val_loss: 1.0961 - val_mse: 1.0961\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.0960 - mse: 1.0960 - val_loss: 1.0959 - val_mse: 1.0959\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.0958 - mse: 1.0958 - val_loss: 1.0957 - val_mse: 1.0957\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.0956 - mse: 1.0956 - val_loss: 1.0955 - val_mse: 1.0955\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.0954 - mse: 1.0954 - val_loss: 1.0953 - val_mse: 1.0953\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.0952 - mse: 1.0952 - val_loss: 1.0951 - val_mse: 1.0951\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.0950 - mse: 1.0950 - val_loss: 1.0949 - val_mse: 1.0949\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.0948 - mse: 1.0948 - val_loss: 1.0947 - val_mse: 1.0947\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 1.0946 - mse: 1.0946 - val_loss: 1.0945 - val_mse: 1.0945\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.0944 - mse: 1.0944 - val_loss: 1.0943 - val_mse: 1.0943\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.0942 - mse: 1.0942 - val_loss: 1.0941 - val_mse: 1.0941\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.0940 - mse: 1.0940 - val_loss: 1.0939 - val_mse: 1.0939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 44/200 [16:56<50:36, 19.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 2s 241ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2437 - val_mse: 1.2437\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2426 - mse: 1.2426 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2384 - mse: 1.2384 - val_loss: 1.2346 - val_mse: 1.2346\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2325 - mse: 1.2325 - val_loss: 1.2270 - val_mse: 1.2270\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2242 - mse: 1.2242 - val_loss: 1.2166 - val_mse: 1.2166\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2131 - mse: 1.2131 - val_loss: 1.2026 - val_mse: 1.2026\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.1987 - mse: 1.1987 - val_loss: 1.1844 - val_mse: 1.1844\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1800 - mse: 1.1800 - val_loss: 1.1608 - val_mse: 1.1608\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.1564 - mse: 1.1564 - val_loss: 1.1313 - val_mse: 1.1313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▎       | 45/200 [17:06<43:14, 16.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 432ms/step - loss: 1.2622 - mse: 1.2622 - val_loss: 1.2629 - val_mse: 1.2629\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.2597 - mse: 1.2597 - val_loss: 1.2599 - val_mse: 1.2599\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.2572 - mse: 1.2572 - val_loss: 1.2569 - val_mse: 1.2569\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2540 - val_mse: 1.2540\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.2523 - mse: 1.2523 - val_loss: 1.2511 - val_mse: 1.2511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 46/200 [17:13<35:01, 13.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 148ms/step - loss: 1.0904 - mse: 1.0904 - val_loss: 0.8978 - val_mse: 0.8978\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.9405 - mse: 0.9405 - val_loss: 0.8839 - val_mse: 0.8839\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.9322 - mse: 0.9322 - val_loss: 0.8746 - val_mse: 0.8746\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.9236 - mse: 0.9236 - val_loss: 0.8693 - val_mse: 0.8693\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.9175 - mse: 0.9175 - val_loss: 0.8658 - val_mse: 0.8658\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.9132 - mse: 0.9132 - val_loss: 0.8647 - val_mse: 0.8647\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.8588 - val_mse: 0.8588\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.9008 - mse: 0.9008 - val_loss: 0.8568 - val_mse: 0.8568\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.8881 - mse: 0.8881 - val_loss: 0.8432 - val_mse: 0.8432\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.8606 - mse: 0.8606 - val_loss: 0.8263 - val_mse: 0.8263\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.8352 - mse: 0.8352 - val_loss: 0.8093 - val_mse: 0.8093\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.8220 - mse: 0.8220 - val_loss: 0.8006 - val_mse: 0.8006\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.8157 - mse: 0.8157 - val_loss: 0.7973 - val_mse: 0.7973\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.8100 - mse: 0.8100 - val_loss: 0.7802 - val_mse: 0.7802\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.8021 - mse: 0.8021 - val_loss: 0.7729 - val_mse: 0.7729\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.7976 - mse: 0.7976 - val_loss: 0.7737 - val_mse: 0.7737\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7922 - mse: 0.7922 - val_loss: 0.7564 - val_mse: 0.7564\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.7870 - mse: 0.7870 - val_loss: 0.7469 - val_mse: 0.7469\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.7818 - mse: 0.7818 - val_loss: 0.7473 - val_mse: 0.7473\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7786 - mse: 0.7786 - val_loss: 0.7432 - val_mse: 0.7432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 47/200 [17:55<56:40, 22.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 395ms/step - loss: 1.1351 - mse: 1.1351 - val_loss: 1.1156 - val_mse: 1.1156\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.1108 - mse: 1.1108 - val_loss: 1.0942 - val_mse: 1.0942\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.0902 - mse: 1.0902 - val_loss: 1.0764 - val_mse: 1.0764\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0731 - mse: 1.0731 - val_loss: 1.0618 - val_mse: 1.0618\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0591 - mse: 1.0591 - val_loss: 1.0500 - val_mse: 1.0500\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0479 - mse: 1.0479 - val_loss: 1.0407 - val_mse: 1.0407\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0390 - mse: 1.0390 - val_loss: 1.0334 - val_mse: 1.0334\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.0321 - mse: 1.0321 - val_loss: 1.0276 - val_mse: 1.0276\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.0266 - mse: 1.0266 - val_loss: 1.0231 - val_mse: 1.0231\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0222 - mse: 1.0222 - val_loss: 1.0195 - val_mse: 1.0195\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0188 - mse: 1.0188 - val_loss: 1.0167 - val_mse: 1.0167\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 1.0144 - val_mse: 1.0144\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0139 - mse: 1.0139 - val_loss: 1.0126 - val_mse: 1.0126\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0122 - mse: 1.0122 - val_loss: 1.0111 - val_mse: 1.0111\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0108 - mse: 1.0108 - val_loss: 1.0098 - val_mse: 1.0098\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.0096 - mse: 1.0096 - val_loss: 1.0088 - val_mse: 1.0088\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0086 - mse: 1.0086 - val_loss: 1.0080 - val_mse: 1.0080\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.0078 - mse: 1.0078 - val_loss: 1.0072 - val_mse: 1.0072\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.0071 - mse: 1.0071 - val_loss: 1.0066 - val_mse: 1.0066\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 1.0061 - val_mse: 1.0061\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0059 - mse: 1.0059 - val_loss: 1.0056 - val_mse: 1.0056\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0055 - mse: 1.0055 - val_loss: 1.0052 - val_mse: 1.0052\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0051 - mse: 1.0051 - val_loss: 1.0048 - val_mse: 1.0048\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 1.0045 - val_mse: 1.0045\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0044 - mse: 1.0044 - val_loss: 1.0042 - val_mse: 1.0042\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0041 - mse: 1.0041 - val_loss: 1.0039 - val_mse: 1.0039\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0038 - mse: 1.0038 - val_loss: 1.0037 - val_mse: 1.0037\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 1.0036 - mse: 1.0036 - val_loss: 1.0034 - val_mse: 1.0034\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0034 - mse: 1.0034 - val_loss: 1.0032 - val_mse: 1.0032\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0032 - mse: 1.0032 - val_loss: 1.0030 - val_mse: 1.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 48/200 [18:22<59:41, 23.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 142ms/step - loss: 1.0570 - mse: 1.0570 - val_loss: 1.0568 - val_mse: 1.0568\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0566 - mse: 1.0566 - val_loss: 1.0564 - val_mse: 1.0564\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0562 - mse: 1.0562 - val_loss: 1.0560 - val_mse: 1.0560\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0558 - mse: 1.0558 - val_loss: 1.0556 - val_mse: 1.0556\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.0554 - mse: 1.0554 - val_loss: 1.0552 - val_mse: 1.0552\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0550 - mse: 1.0550 - val_loss: 1.0548 - val_mse: 1.0548\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.0547 - mse: 1.0547 - val_loss: 1.0545 - val_mse: 1.0545\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0543 - mse: 1.0543 - val_loss: 1.0541 - val_mse: 1.0541\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0539 - mse: 1.0539 - val_loss: 1.0537 - val_mse: 1.0537\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0536 - mse: 1.0536 - val_loss: 1.0534 - val_mse: 1.0534\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0532 - mse: 1.0532 - val_loss: 1.0530 - val_mse: 1.0530\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.0528 - mse: 1.0528 - val_loss: 1.0526 - val_mse: 1.0526\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0525 - mse: 1.0525 - val_loss: 1.0523 - val_mse: 1.0523\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.0521 - mse: 1.0521 - val_loss: 1.0519 - val_mse: 1.0519\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0518 - mse: 1.0518 - val_loss: 1.0516 - val_mse: 1.0516\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0514 - mse: 1.0514 - val_loss: 1.0512 - val_mse: 1.0512\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0511 - mse: 1.0511 - val_loss: 1.0509 - val_mse: 1.0509\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0507 - mse: 1.0507 - val_loss: 1.0505 - val_mse: 1.0505\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0504 - mse: 1.0504 - val_loss: 1.0502 - val_mse: 1.0502\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0500 - mse: 1.0500 - val_loss: 1.0499 - val_mse: 1.0499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 49/200 [18:44<58:00, 23.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 597ms/step - loss: 1.0730 - mse: 1.0730 - val_loss: 0.9191 - val_mse: 0.9191\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.9611 - mse: 0.9611 - val_loss: 0.8990 - val_mse: 0.8990\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.9475 - mse: 0.9475 - val_loss: 0.8927 - val_mse: 0.8927\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.9428 - mse: 0.9428 - val_loss: 0.8895 - val_mse: 0.8895\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.9402 - mse: 0.9402 - val_loss: 0.8874 - val_mse: 0.8874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 50/200 [18:50<45:07, 18.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 380ms/step - loss: 1.5033 - mse: 1.5033 - val_loss: 1.4677 - val_mse: 1.4677\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.4580 - mse: 1.4580 - val_loss: 1.4221 - val_mse: 1.4221\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.4124 - mse: 1.4124 - val_loss: 1.3768 - val_mse: 1.3768\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.3673 - mse: 1.3673 - val_loss: 1.3326 - val_mse: 1.3326\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.3235 - mse: 1.3235 - val_loss: 1.2904 - val_mse: 1.2904\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.2818 - mse: 1.2818 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2430 - mse: 1.2430 - val_loss: 1.2148 - val_mse: 1.2148\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2077 - mse: 1.2077 - val_loss: 1.1825 - val_mse: 1.1825\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.1763 - mse: 1.1763 - val_loss: 1.1543 - val_mse: 1.1543\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.1488 - mse: 1.1488 - val_loss: 1.1300 - val_mse: 1.1300\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.1254 - mse: 1.1254 - val_loss: 1.1094 - val_mse: 1.1094\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.1056 - mse: 1.1056 - val_loss: 1.0923 - val_mse: 1.0923\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.0891 - mse: 1.0891 - val_loss: 1.0782 - val_mse: 1.0782\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.0755 - mse: 1.0755 - val_loss: 1.0666 - val_mse: 1.0666\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0644 - mse: 1.0644 - val_loss: 1.0571 - val_mse: 1.0571\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0553 - mse: 1.0553 - val_loss: 1.0494 - val_mse: 1.0494\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0479 - mse: 1.0479 - val_loss: 1.0430 - val_mse: 1.0430\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0418 - mse: 1.0418 - val_loss: 1.0378 - val_mse: 1.0378\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.0368 - mse: 1.0368 - val_loss: 1.0334 - val_mse: 1.0334\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0326 - mse: 1.0326 - val_loss: 1.0298 - val_mse: 1.0298\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0291 - mse: 1.0291 - val_loss: 1.0268 - val_mse: 1.0268\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0262 - mse: 1.0262 - val_loss: 1.0243 - val_mse: 1.0243\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0237 - mse: 1.0237 - val_loss: 1.0221 - val_mse: 1.0221\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0216 - mse: 1.0216 - val_loss: 1.0202 - val_mse: 1.0202\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0198 - mse: 1.0198 - val_loss: 1.0186 - val_mse: 1.0186\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0183 - mse: 1.0183 - val_loss: 1.0172 - val_mse: 1.0172\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0169 - mse: 1.0169 - val_loss: 1.0160 - val_mse: 1.0160\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 1.0149 - val_mse: 1.0149\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0146 - mse: 1.0146 - val_loss: 1.0139 - val_mse: 1.0139\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0137 - mse: 1.0137 - val_loss: 1.0131 - val_mse: 1.0131\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0128 - mse: 1.0128 - val_loss: 1.0123 - val_mse: 1.0123\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0121 - mse: 1.0121 - val_loss: 1.0116 - val_mse: 1.0116\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0114 - mse: 1.0114 - val_loss: 1.0109 - val_mse: 1.0109\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0108 - mse: 1.0108 - val_loss: 1.0104 - val_mse: 1.0104\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0102 - mse: 1.0102 - val_loss: 1.0098 - val_mse: 1.0098\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0097 - mse: 1.0097 - val_loss: 1.0093 - val_mse: 1.0093\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0092 - mse: 1.0092 - val_loss: 1.0089 - val_mse: 1.0089\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0087 - mse: 1.0087 - val_loss: 1.0085 - val_mse: 1.0085\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0083 - mse: 1.0083 - val_loss: 1.0081 - val_mse: 1.0081\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0079 - mse: 1.0079 - val_loss: 1.0077 - val_mse: 1.0077\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0076 - mse: 1.0076 - val_loss: 1.0074 - val_mse: 1.0074\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0072 - mse: 1.0072 - val_loss: 1.0071 - val_mse: 1.0071\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0069 - mse: 1.0069 - val_loss: 1.0068 - val_mse: 1.0068\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0066 - mse: 1.0066 - val_loss: 1.0065 - val_mse: 1.0065\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0064 - mse: 1.0064 - val_loss: 1.0062 - val_mse: 1.0062\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0061 - mse: 1.0061 - val_loss: 1.0060 - val_mse: 1.0060\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0059 - mse: 1.0059 - val_loss: 1.0057 - val_mse: 1.0057\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.0056 - mse: 1.0056 - val_loss: 1.0055 - val_mse: 1.0055\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0054 - mse: 1.0054 - val_loss: 1.0053 - val_mse: 1.0053\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0052 - mse: 1.0052 - val_loss: 1.0051 - val_mse: 1.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 51/200 [19:32<1:03:00, 25.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 677ms/step - loss: 1.2485 - mse: 1.2485 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2441 - val_mse: 1.2441\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 1.2437 - mse: 1.2437 - val_loss: 1.2417 - val_mse: 1.2417\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 1.2413 - mse: 1.2413 - val_loss: 1.2393 - val_mse: 1.2393\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 1.2389 - mse: 1.2389 - val_loss: 1.2369 - val_mse: 1.2369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 52/200 [19:39<48:16, 19.57s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 475ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2471 - mse: 1.2471 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2462 - val_mse: 1.2462\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2459 - val_mse: 1.2459\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 1.2456 - val_mse: 1.2456\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 1.2454 - mse: 1.2454 - val_loss: 1.2452 - val_mse: 1.2452\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 1.2451 - mse: 1.2451 - val_loss: 1.2449 - val_mse: 1.2449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 53/200 [19:50<42:07, 17.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 157ms/step - loss: 1.2379 - mse: 1.2379 - val_loss: 1.2141 - val_mse: 1.2141\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.1715 - mse: 1.1715 - val_loss: 1.0784 - val_mse: 1.0784\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.0046 - mse: 1.0046 - val_loss: 0.8987 - val_mse: 0.8987\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.9033 - mse: 0.9033 - val_loss: 0.8462 - val_mse: 0.8462\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.8551 - mse: 0.8551 - val_loss: 0.8059 - val_mse: 0.8059\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.8243 - mse: 0.8243 - val_loss: 0.7823 - val_mse: 0.7823\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.8087 - mse: 0.8087 - val_loss: 0.7723 - val_mse: 0.7723\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.8006 - mse: 0.8006 - val_loss: 0.7672 - val_mse: 0.7672\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.7946 - mse: 0.7946 - val_loss: 0.7649 - val_mse: 0.7649\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.7917 - mse: 0.7917 - val_loss: 0.7589 - val_mse: 0.7589\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.7860 - mse: 0.7860 - val_loss: 0.7552 - val_mse: 0.7552\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.7830 - mse: 0.7830 - val_loss: 0.7450 - val_mse: 0.7450\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.7796 - mse: 0.7796 - val_loss: 0.7444 - val_mse: 0.7444\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.7789 - mse: 0.7789 - val_loss: 0.7464 - val_mse: 0.7464\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.7797 - mse: 0.7797 - val_loss: 0.7468 - val_mse: 0.7468\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.7796 - mse: 0.7796 - val_loss: 0.7445 - val_mse: 0.7445\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.7776 - mse: 0.7776 - val_loss: 0.7436 - val_mse: 0.7436\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.7765 - mse: 0.7765 - val_loss: 0.7388 - val_mse: 0.7388\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.7752 - mse: 0.7752 - val_loss: 0.7339 - val_mse: 0.7339\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.7741 - mse: 0.7741 - val_loss: 0.7331 - val_mse: 0.7331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 54/200 [20:13<46:16, 19.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 278ms/step - loss: 1.1676 - mse: 1.1676 - val_loss: 1.0128 - val_mse: 1.0128\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 207ms/step - loss: 0.9754 - mse: 0.9754 - val_loss: 0.8761 - val_mse: 0.8761\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.8866 - mse: 0.8866 - val_loss: 0.8315 - val_mse: 0.8315\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 0.8536 - mse: 0.8536 - val_loss: 0.8018 - val_mse: 0.8018\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.8345 - mse: 0.8345 - val_loss: 0.7824 - val_mse: 0.7824\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.8215 - mse: 0.8215 - val_loss: 0.7784 - val_mse: 0.7784\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.8117 - mse: 0.8117 - val_loss: 0.7705 - val_mse: 0.7705\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.8030 - mse: 0.8030 - val_loss: 0.7545 - val_mse: 0.7545\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 200ms/step - loss: 0.7951 - mse: 0.7951 - val_loss: 0.7549 - val_mse: 0.7549\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 0.7895 - mse: 0.7895 - val_loss: 0.7439 - val_mse: 0.7439\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.7849 - mse: 0.7849 - val_loss: 0.7489 - val_mse: 0.7489\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.7806 - mse: 0.7806 - val_loss: 0.7361 - val_mse: 0.7361\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 207ms/step - loss: 0.7758 - mse: 0.7758 - val_loss: 0.7320 - val_mse: 0.7320\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.7723 - mse: 0.7723 - val_loss: 0.7324 - val_mse: 0.7324\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.7739 - mse: 0.7739 - val_loss: 0.7309 - val_mse: 0.7309\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 0.7792 - mse: 0.7792 - val_loss: 0.7538 - val_mse: 0.7538\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 200ms/step - loss: 0.7807 - mse: 0.7807 - val_loss: 0.7416 - val_mse: 0.7416\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.7754 - mse: 0.7754 - val_loss: 0.7355 - val_mse: 0.7355\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.7695 - mse: 0.7695 - val_loss: 0.7269 - val_mse: 0.7269\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.7661 - mse: 0.7661 - val_loss: 0.7276 - val_mse: 0.7276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 55/200 [20:35<48:05, 19.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 3s 171ms/step - loss: 1.2497 - mse: 1.2497 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 133ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2472 - val_mse: 1.2472\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2462 - val_mse: 1.2462\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 1.2453 - val_mse: 1.2453\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 129ms/step - loss: 1.2449 - mse: 1.2449 - val_loss: 1.2443 - val_mse: 1.2443\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 131ms/step - loss: 1.2439 - mse: 1.2439 - val_loss: 1.2433 - val_mse: 1.2433\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 1.2429 - mse: 1.2429 - val_loss: 1.2424 - val_mse: 1.2424\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 1.2420 - mse: 1.2420 - val_loss: 1.2414 - val_mse: 1.2414\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 132ms/step - loss: 1.2410 - mse: 1.2410 - val_loss: 1.2405 - val_mse: 1.2405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 56/200 [20:49<43:15, 18.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 676ms/step - loss: 1.2624 - mse: 1.2624 - val_loss: 1.2641 - val_mse: 1.2641\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 1.2609 - mse: 1.2609 - val_loss: 1.2623 - val_mse: 1.2623\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 379ms/step - loss: 1.2594 - mse: 1.2594 - val_loss: 1.2605 - val_mse: 1.2605\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 1.2579 - mse: 1.2579 - val_loss: 1.2588 - val_mse: 1.2588\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 1.2565 - mse: 1.2565 - val_loss: 1.2571 - val_mse: 1.2571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 57/200 [20:56<34:47, 14.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 295ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 211ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 211ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 216ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2450 - val_mse: 1.2450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 58/200 [21:07<32:32, 13.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 271ms/step - loss: 1.2665 - mse: 1.2665 - val_loss: 1.2622 - val_mse: 1.2622\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 1.2599 - mse: 1.2599 - val_loss: 1.2557 - val_mse: 1.2557\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.2535 - mse: 1.2535 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 184ms/step - loss: 1.2471 - mse: 1.2471 - val_loss: 1.2430 - val_mse: 1.2430\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.2409 - mse: 1.2409 - val_loss: 1.2368 - val_mse: 1.2368\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.2347 - mse: 1.2347 - val_loss: 1.2307 - val_mse: 1.2307\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.2287 - mse: 1.2287 - val_loss: 1.2248 - val_mse: 1.2248\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 1.2227 - mse: 1.2227 - val_loss: 1.2189 - val_mse: 1.2189\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.2169 - mse: 1.2169 - val_loss: 1.2132 - val_mse: 1.2132\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.2113 - mse: 1.2113 - val_loss: 1.2076 - val_mse: 1.2076\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 1.2057 - mse: 1.2057 - val_loss: 1.2021 - val_mse: 1.2021\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2003 - mse: 1.2003 - val_loss: 1.1968 - val_mse: 1.1968\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 1.1950 - mse: 1.1950 - val_loss: 1.1916 - val_mse: 1.1916\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.1898 - mse: 1.1898 - val_loss: 1.1865 - val_mse: 1.1865\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.1848 - mse: 1.1848 - val_loss: 1.1815 - val_mse: 1.1815\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.1798 - mse: 1.1798 - val_loss: 1.1767 - val_mse: 1.1767\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.1750 - mse: 1.1750 - val_loss: 1.1720 - val_mse: 1.1720\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.1704 - mse: 1.1704 - val_loss: 1.1674 - val_mse: 1.1674\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 1.1658 - mse: 1.1658 - val_loss: 1.1629 - val_mse: 1.1629\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.1614 - mse: 1.1614 - val_loss: 1.1586 - val_mse: 1.1586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 59/200 [21:29<38:08, 16.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 2s 658ms/step - loss: 1.3752 - mse: 1.3752 - val_loss: 1.2517 - val_mse: 1.2517\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.2320 - mse: 1.2320 - val_loss: 1.1389 - val_mse: 1.1389\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 1.1262 - mse: 1.1262 - val_loss: 1.0695 - val_mse: 1.0695\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 1.0627 - mse: 1.0627 - val_loss: 1.0335 - val_mse: 1.0335\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 1.0303 - mse: 1.0303 - val_loss: 1.0165 - val_mse: 1.0165\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.0149 - mse: 1.0149 - val_loss: 1.0085 - val_mse: 1.0085\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.0077 - mse: 1.0077 - val_loss: 1.0046 - val_mse: 1.0046\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 1.0041 - mse: 1.0041 - val_loss: 1.0025 - val_mse: 1.0025\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 1.0014 - val_mse: 1.0014\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 1.0013 - mse: 1.0013 - val_loss: 1.0008 - val_mse: 1.0008\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 1.0004 - val_mse: 1.0004\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 1.0003 - mse: 1.0003 - val_loss: 1.0001 - val_mse: 1.0001\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 1.0000 - val_mse: 1.0000\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 373ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9997 - val_mse: 0.9997\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 0.9996 - val_mse: 0.9996\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 379ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 1s 334ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 1s 336ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9994 - val_mse: 0.9994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 60/200 [22:53<1:24:53, 36.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 373ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2377 - val_mse: 1.2377\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.2348 - mse: 1.2348 - val_loss: 1.2186 - val_mse: 1.2186\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.2147 - mse: 1.2147 - val_loss: 1.1874 - val_mse: 1.1874\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.1818 - mse: 1.1818 - val_loss: 1.1375 - val_mse: 1.1375\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.1310 - mse: 1.1310 - val_loss: 1.0669 - val_mse: 1.0669\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0629 - mse: 1.0629 - val_loss: 0.9880 - val_mse: 0.9880\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9925 - mse: 0.9925 - val_loss: 0.9309 - val_mse: 0.9309\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.9054 - val_mse: 0.9054\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.9266 - mse: 0.9266 - val_loss: 0.8944 - val_mse: 0.8944\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.8825 - val_mse: 0.8825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 61/200 [23:04<1:06:58, 28.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 448ms/step - loss: 1.2383 - mse: 1.2383 - val_loss: 1.2337 - val_mse: 1.2337\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.2364 - mse: 1.2364 - val_loss: 1.2315 - val_mse: 1.2315\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.2345 - mse: 1.2345 - val_loss: 1.2292 - val_mse: 1.2292\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 1.2269 - val_mse: 1.2269\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.2307 - mse: 1.2307 - val_loss: 1.2245 - val_mse: 1.2245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 62/200 [23:11<50:56, 22.15s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 611ms/step - loss: 1.5718 - mse: 1.5718 - val_loss: 1.4638 - val_mse: 1.4638\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 1.4168 - mse: 1.4168 - val_loss: 1.2854 - val_mse: 1.2854\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 368ms/step - loss: 1.2626 - mse: 1.2626 - val_loss: 1.1338 - val_mse: 1.1338\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 1.1373 - mse: 1.1373 - val_loss: 1.0304 - val_mse: 1.0304\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 389ms/step - loss: 1.0526 - mse: 1.0526 - val_loss: 0.9689 - val_mse: 0.9689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 63/200 [23:17<39:24, 17.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 235ms/step - loss: 1.1551 - mse: 1.1551 - val_loss: 0.9791 - val_mse: 0.9791\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.9532 - mse: 0.9532 - val_loss: 0.8674 - val_mse: 0.8674\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.8825 - mse: 0.8825 - val_loss: 0.8309 - val_mse: 0.8309\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.8566 - mse: 0.8566 - val_loss: 0.8081 - val_mse: 0.8081\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.8372 - mse: 0.8372 - val_loss: 0.7926 - val_mse: 0.7926\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.8233 - mse: 0.8233 - val_loss: 0.7754 - val_mse: 0.7754\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.8155 - mse: 0.8155 - val_loss: 0.7696 - val_mse: 0.7696\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 0.8073 - mse: 0.8073 - val_loss: 0.7628 - val_mse: 0.7628\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.8005 - mse: 0.8005 - val_loss: 0.7550 - val_mse: 0.7550\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7983 - mse: 0.7983 - val_loss: 0.7646 - val_mse: 0.7646\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7940 - mse: 0.7940 - val_loss: 0.7577 - val_mse: 0.7577\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7887 - mse: 0.7887 - val_loss: 0.7541 - val_mse: 0.7541\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7852 - mse: 0.7852 - val_loss: 0.7478 - val_mse: 0.7478\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7814 - mse: 0.7814 - val_loss: 0.7436 - val_mse: 0.7436\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7790 - mse: 0.7790 - val_loss: 0.7426 - val_mse: 0.7426\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7787 - mse: 0.7787 - val_loss: 0.7413 - val_mse: 0.7413\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7786 - mse: 0.7786 - val_loss: 0.7479 - val_mse: 0.7479\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7785 - mse: 0.7785 - val_loss: 0.7380 - val_mse: 0.7380\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7753 - mse: 0.7753 - val_loss: 0.7427 - val_mse: 0.7427\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7767 - mse: 0.7767 - val_loss: 0.7394 - val_mse: 0.7394\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7740 - mse: 0.7740 - val_loss: 0.7345 - val_mse: 0.7345\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7732 - mse: 0.7732 - val_loss: 0.7289 - val_mse: 0.7289\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7743 - mse: 0.7743 - val_loss: 0.7472 - val_mse: 0.7472\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.7753 - mse: 0.7753 - val_loss: 0.7358 - val_mse: 0.7358\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7753 - mse: 0.7753 - val_loss: 0.7347 - val_mse: 0.7347\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.7704 - mse: 0.7704 - val_loss: 0.7267 - val_mse: 0.7267\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.7768 - mse: 0.7768 - val_loss: 0.7465 - val_mse: 0.7465\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7775 - mse: 0.7775 - val_loss: 0.7437 - val_mse: 0.7437\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7777 - mse: 0.7777 - val_loss: 0.7445 - val_mse: 0.7445\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7752 - mse: 0.7752 - val_loss: 0.7431 - val_mse: 0.7431\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7719 - mse: 0.7719 - val_loss: 0.7284 - val_mse: 0.7284\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 0.7705 - mse: 0.7705 - val_loss: 0.7265 - val_mse: 0.7265\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7644 - mse: 0.7644 - val_loss: 0.7370 - val_mse: 0.7370\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7693 - mse: 0.7693 - val_loss: 0.7325 - val_mse: 0.7325\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7684 - mse: 0.7684 - val_loss: 0.7454 - val_mse: 0.7454\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7764 - mse: 0.7764 - val_loss: 0.7428 - val_mse: 0.7428\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7754 - mse: 0.7754 - val_loss: 0.7434 - val_mse: 0.7434\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.7747 - mse: 0.7747 - val_loss: 0.7418 - val_mse: 0.7418\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.7731 - mse: 0.7731 - val_loss: 0.7408 - val_mse: 0.7408\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7717 - mse: 0.7717 - val_loss: 0.7368 - val_mse: 0.7368\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7702 - mse: 0.7702 - val_loss: 0.7300 - val_mse: 0.7300\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7682 - mse: 0.7682 - val_loss: 0.7203 - val_mse: 0.7203\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.7635 - mse: 0.7635 - val_loss: 0.7244 - val_mse: 0.7244\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.7640 - mse: 0.7640 - val_loss: 0.7231 - val_mse: 0.7231\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 0.7216 - val_mse: 0.7216\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 0.7167 - val_mse: 0.7167\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.7572 - mse: 0.7572 - val_loss: 0.7167 - val_mse: 0.7167\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.7563 - mse: 0.7563 - val_loss: 0.7203 - val_mse: 0.7203\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.7562 - mse: 0.7562 - val_loss: 0.7177 - val_mse: 0.7177\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.7553 - mse: 0.7553 - val_loss: 0.7171 - val_mse: 0.7171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 64/200 [24:40<1:23:58, 37.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 149ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2467 - mse: 1.2467 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2465 - mse: 1.2465 - val_loss: 1.2465 - val_mse: 1.2465\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2463 - val_mse: 1.2463\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2463 - val_mse: 1.2463\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2463 - val_mse: 1.2463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▎      | 65/200 [26:03<1:54:31, 50.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 239ms/step - loss: 1.2249 - mse: 1.2249 - val_loss: 1.2275 - val_mse: 1.2275\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2244 - mse: 1.2244 - val_loss: 1.2269 - val_mse: 1.2269\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2238 - mse: 1.2238 - val_loss: 1.2263 - val_mse: 1.2263\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2233 - mse: 1.2233 - val_loss: 1.2257 - val_mse: 1.2257\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2228 - mse: 1.2228 - val_loss: 1.2251 - val_mse: 1.2251\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2223 - mse: 1.2223 - val_loss: 1.2246 - val_mse: 1.2246\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2218 - mse: 1.2218 - val_loss: 1.2240 - val_mse: 1.2240\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2213 - mse: 1.2213 - val_loss: 1.2234 - val_mse: 1.2234\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2208 - mse: 1.2208 - val_loss: 1.2228 - val_mse: 1.2228\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2202 - mse: 1.2202 - val_loss: 1.2222 - val_mse: 1.2222\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2197 - mse: 1.2197 - val_loss: 1.2216 - val_mse: 1.2216\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2192 - mse: 1.2192 - val_loss: 1.2210 - val_mse: 1.2210\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2187 - mse: 1.2187 - val_loss: 1.2204 - val_mse: 1.2204\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2182 - mse: 1.2182 - val_loss: 1.2198 - val_mse: 1.2198\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2176 - mse: 1.2176 - val_loss: 1.2192 - val_mse: 1.2192\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2171 - mse: 1.2171 - val_loss: 1.2186 - val_mse: 1.2186\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2166 - mse: 1.2166 - val_loss: 1.2180 - val_mse: 1.2180\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2161 - mse: 1.2161 - val_loss: 1.2174 - val_mse: 1.2174\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2155 - mse: 1.2155 - val_loss: 1.2168 - val_mse: 1.2168\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2150 - mse: 1.2150 - val_loss: 1.2162 - val_mse: 1.2162\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2145 - mse: 1.2145 - val_loss: 1.2156 - val_mse: 1.2156\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2140 - mse: 1.2140 - val_loss: 1.2150 - val_mse: 1.2150\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2134 - mse: 1.2134 - val_loss: 1.2143 - val_mse: 1.2143\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2129 - mse: 1.2129 - val_loss: 1.2137 - val_mse: 1.2137\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2124 - mse: 1.2124 - val_loss: 1.2130 - val_mse: 1.2130\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2118 - mse: 1.2118 - val_loss: 1.2124 - val_mse: 1.2124\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2113 - mse: 1.2113 - val_loss: 1.2118 - val_mse: 1.2118\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2107 - mse: 1.2107 - val_loss: 1.2111 - val_mse: 1.2111\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.2102 - mse: 1.2102 - val_loss: 1.2104 - val_mse: 1.2104\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2097 - mse: 1.2097 - val_loss: 1.2098 - val_mse: 1.2098\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2091 - mse: 1.2091 - val_loss: 1.2091 - val_mse: 1.2091\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2086 - mse: 1.2086 - val_loss: 1.2085 - val_mse: 1.2085\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2080 - mse: 1.2080 - val_loss: 1.2078 - val_mse: 1.2078\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2075 - mse: 1.2075 - val_loss: 1.2071 - val_mse: 1.2071\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2069 - mse: 1.2069 - val_loss: 1.2065 - val_mse: 1.2065\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2063 - mse: 1.2063 - val_loss: 1.2058 - val_mse: 1.2058\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2058 - mse: 1.2058 - val_loss: 1.2051 - val_mse: 1.2051\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2052 - mse: 1.2052 - val_loss: 1.2045 - val_mse: 1.2045\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2046 - mse: 1.2046 - val_loss: 1.2038 - val_mse: 1.2038\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2041 - mse: 1.2041 - val_loss: 1.2031 - val_mse: 1.2031\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2035 - mse: 1.2035 - val_loss: 1.2025 - val_mse: 1.2025\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2029 - mse: 1.2029 - val_loss: 1.2018 - val_mse: 1.2018\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2023 - mse: 1.2023 - val_loss: 1.2011 - val_mse: 1.2011\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2018 - mse: 1.2018 - val_loss: 1.2004 - val_mse: 1.2004\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.2012 - mse: 1.2012 - val_loss: 1.1996 - val_mse: 1.1996\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2005 - mse: 1.2005 - val_loss: 1.1989 - val_mse: 1.1989\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.1999 - mse: 1.1999 - val_loss: 1.1981 - val_mse: 1.1981\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.1993 - mse: 1.1993 - val_loss: 1.1972 - val_mse: 1.1972\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1987 - mse: 1.1987 - val_loss: 1.1964 - val_mse: 1.1964\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.1980 - mse: 1.1980 - val_loss: 1.1956 - val_mse: 1.1956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 66/200 [26:48<1:49:58, 49.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 145ms/step - loss: 1.1078 - mse: 1.1078 - val_loss: 0.9072 - val_mse: 0.9072\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.9380 - mse: 0.9380 - val_loss: 0.8798 - val_mse: 0.8798\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.9288 - mse: 0.9288 - val_loss: 0.8729 - val_mse: 0.8729\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.9223 - mse: 0.9223 - val_loss: 0.8695 - val_mse: 0.8695\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.9181 - mse: 0.9181 - val_loss: 0.8671 - val_mse: 0.8671\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.9138 - mse: 0.9138 - val_loss: 0.8656 - val_mse: 0.8656\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.9081 - mse: 0.9081 - val_loss: 0.8595 - val_mse: 0.8595\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.8997 - mse: 0.8997 - val_loss: 0.8555 - val_mse: 0.8555\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.8823 - mse: 0.8823 - val_loss: 0.8430 - val_mse: 0.8430\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.8501 - mse: 0.8501 - val_loss: 0.8290 - val_mse: 0.8290\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.8369 - mse: 0.8369 - val_loss: 0.8120 - val_mse: 0.8120\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.8269 - mse: 0.8269 - val_loss: 0.8072 - val_mse: 0.8072\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.8187 - mse: 0.8187 - val_loss: 0.7960 - val_mse: 0.7960\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.8119 - mse: 0.8119 - val_loss: 0.7880 - val_mse: 0.7880\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.8050 - mse: 0.8050 - val_loss: 0.7807 - val_mse: 0.7807\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.7973 - mse: 0.7973 - val_loss: 0.7677 - val_mse: 0.7677\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.7907 - mse: 0.7907 - val_loss: 0.7585 - val_mse: 0.7585\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7863 - mse: 0.7863 - val_loss: 0.7579 - val_mse: 0.7579\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.7814 - mse: 0.7814 - val_loss: 0.7451 - val_mse: 0.7451\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.7792 - mse: 0.7792 - val_loss: 0.7458 - val_mse: 0.7458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 67/200 [27:31<1:44:28, 47.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 399ms/step - loss: 1.2453 - mse: 1.2453 - val_loss: 1.2265 - val_mse: 1.2265\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 1.2253 - mse: 1.2253 - val_loss: 1.2020 - val_mse: 1.2020\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2044 - mse: 1.2044 - val_loss: 1.1752 - val_mse: 1.1752\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.1813 - mse: 1.1813 - val_loss: 1.1451 - val_mse: 1.1451\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.1552 - mse: 1.1552 - val_loss: 1.1115 - val_mse: 1.1115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 68/200 [27:37<1:16:47, 34.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 238ms/step - loss: 1.2624 - mse: 1.2624 - val_loss: 1.2625 - val_mse: 1.2625\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2587 - mse: 1.2587 - val_loss: 1.2581 - val_mse: 1.2581\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2551 - mse: 1.2551 - val_loss: 1.2538 - val_mse: 1.2538\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.2516 - mse: 1.2516 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2455 - val_mse: 1.2455\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2448 - mse: 1.2448 - val_loss: 1.2414 - val_mse: 1.2414\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2415 - mse: 1.2415 - val_loss: 1.2374 - val_mse: 1.2374\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2382 - mse: 1.2382 - val_loss: 1.2334 - val_mse: 1.2334\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2349 - mse: 1.2349 - val_loss: 1.2293 - val_mse: 1.2293\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.2315 - mse: 1.2315 - val_loss: 1.2252 - val_mse: 1.2252\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.2281 - mse: 1.2281 - val_loss: 1.2210 - val_mse: 1.2210\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2246 - mse: 1.2246 - val_loss: 1.2167 - val_mse: 1.2167\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2210 - mse: 1.2210 - val_loss: 1.2123 - val_mse: 1.2123\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2173 - mse: 1.2173 - val_loss: 1.2077 - val_mse: 1.2077\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2134 - mse: 1.2134 - val_loss: 1.2029 - val_mse: 1.2029\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2094 - mse: 1.2094 - val_loss: 1.1979 - val_mse: 1.1979\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.2053 - mse: 1.2053 - val_loss: 1.1928 - val_mse: 1.1928\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2009 - mse: 1.2009 - val_loss: 1.1874 - val_mse: 1.1874\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1963 - mse: 1.1963 - val_loss: 1.1818 - val_mse: 1.1818\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.1916 - mse: 1.1916 - val_loss: 1.1759 - val_mse: 1.1759\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.1866 - mse: 1.1866 - val_loss: 1.1699 - val_mse: 1.1699\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 1.1814 - mse: 1.1814 - val_loss: 1.1636 - val_mse: 1.1636\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.1760 - mse: 1.1760 - val_loss: 1.1570 - val_mse: 1.1570\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.1704 - mse: 1.1704 - val_loss: 1.1502 - val_mse: 1.1502\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.1646 - mse: 1.1646 - val_loss: 1.1432 - val_mse: 1.1432\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1585 - mse: 1.1585 - val_loss: 1.1360 - val_mse: 1.1360\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.1523 - mse: 1.1523 - val_loss: 1.1285 - val_mse: 1.1285\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.1459 - mse: 1.1459 - val_loss: 1.1209 - val_mse: 1.1209\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.1393 - mse: 1.1393 - val_loss: 1.1131 - val_mse: 1.1131\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.1326 - mse: 1.1326 - val_loss: 1.1052 - val_mse: 1.1052\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1257 - mse: 1.1257 - val_loss: 1.0971 - val_mse: 1.0971\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.1187 - mse: 1.1187 - val_loss: 1.0890 - val_mse: 1.0890\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.1117 - mse: 1.1117 - val_loss: 1.0808 - val_mse: 1.0808\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.1045 - mse: 1.1045 - val_loss: 1.0725 - val_mse: 1.0725\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.0974 - mse: 1.0974 - val_loss: 1.0643 - val_mse: 1.0643\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.0903 - mse: 1.0903 - val_loss: 1.0561 - val_mse: 1.0561\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0831 - mse: 1.0831 - val_loss: 1.0480 - val_mse: 1.0480\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 1.0761 - mse: 1.0761 - val_loss: 1.0400 - val_mse: 1.0400\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.0692 - mse: 1.0692 - val_loss: 1.0322 - val_mse: 1.0322\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.0624 - mse: 1.0624 - val_loss: 1.0245 - val_mse: 1.0245\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.0557 - mse: 1.0557 - val_loss: 1.0171 - val_mse: 1.0171\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.0493 - mse: 1.0493 - val_loss: 1.0099 - val_mse: 1.0099\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.0431 - mse: 1.0431 - val_loss: 1.0030 - val_mse: 1.0030\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.0370 - mse: 1.0370 - val_loss: 0.9964 - val_mse: 0.9964\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.0313 - mse: 1.0313 - val_loss: 0.9900 - val_mse: 0.9900\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0258 - mse: 1.0258 - val_loss: 0.9840 - val_mse: 0.9840\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.0206 - mse: 1.0206 - val_loss: 0.9783 - val_mse: 0.9783\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9729 - val_mse: 0.9729\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.0109 - mse: 1.0109 - val_loss: 0.9677 - val_mse: 0.9677\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 0.9629 - val_mse: 0.9629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 69/200 [28:23<1:23:17, 38.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 450ms/step - loss: 1.2542 - mse: 1.2542 - val_loss: 1.2540 - val_mse: 1.2540\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.2539 - mse: 1.2539 - val_loss: 1.2537 - val_mse: 1.2537\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 1.2536 - mse: 1.2536 - val_loss: 1.2534 - val_mse: 1.2534\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.2532 - mse: 1.2532 - val_loss: 1.2530 - val_mse: 1.2530\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.2529 - mse: 1.2529 - val_loss: 1.2527 - val_mse: 1.2527\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2526 - mse: 1.2526 - val_loss: 1.2524 - val_mse: 1.2524\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2523 - mse: 1.2523 - val_loss: 1.2520 - val_mse: 1.2520\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2519 - mse: 1.2519 - val_loss: 1.2517 - val_mse: 1.2517\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.2516 - mse: 1.2516 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2510 - val_mse: 1.2510\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2499 - mse: 1.2499 - val_loss: 1.2497 - val_mse: 1.2497\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2494 - val_mse: 1.2494\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2491 - val_mse: 1.2491\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 1.2487 - val_mse: 1.2487\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2486 - mse: 1.2486 - val_loss: 1.2484 - val_mse: 1.2484\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 1.2473 - mse: 1.2473 - val_loss: 1.2471 - val_mse: 1.2471\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.2470 - mse: 1.2470 - val_loss: 1.2468 - val_mse: 1.2468\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2464 - val_mse: 1.2464\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2458 - val_mse: 1.2458\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.2457 - mse: 1.2457 - val_loss: 1.2454 - val_mse: 1.2454\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2453 - mse: 1.2453 - val_loss: 1.2451 - val_mse: 1.2451\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2448 - val_mse: 1.2448\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2447 - mse: 1.2447 - val_loss: 1.2445 - val_mse: 1.2445\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2444 - mse: 1.2444 - val_loss: 1.2441 - val_mse: 1.2441\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2440 - mse: 1.2440 - val_loss: 1.2438 - val_mse: 1.2438\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 1.2437 - mse: 1.2437 - val_loss: 1.2435 - val_mse: 1.2435\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2434 - mse: 1.2434 - val_loss: 1.2432 - val_mse: 1.2432\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 1.2431 - mse: 1.2431 - val_loss: 1.2428 - val_mse: 1.2428\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.2425 - val_mse: 1.2425\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2424 - mse: 1.2424 - val_loss: 1.2422 - val_mse: 1.2422\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2419 - val_mse: 1.2419\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.2418 - mse: 1.2418 - val_loss: 1.2415 - val_mse: 1.2415\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2414 - mse: 1.2414 - val_loss: 1.2412 - val_mse: 1.2412\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.2411 - mse: 1.2411 - val_loss: 1.2409 - val_mse: 1.2409\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2408 - mse: 1.2408 - val_loss: 1.2406 - val_mse: 1.2406\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2405 - mse: 1.2405 - val_loss: 1.2403 - val_mse: 1.2403\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2402 - mse: 1.2402 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2398 - mse: 1.2398 - val_loss: 1.2396 - val_mse: 1.2396\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 1.2393 - val_mse: 1.2393\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 1.2392 - mse: 1.2392 - val_loss: 1.2390 - val_mse: 1.2390\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 1.2389 - mse: 1.2389 - val_loss: 1.2387 - val_mse: 1.2387\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2385 - mse: 1.2385 - val_loss: 1.2383 - val_mse: 1.2383\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2382 - mse: 1.2382 - val_loss: 1.2380 - val_mse: 1.2380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 70/200 [29:46<1:51:56, 51.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 441ms/step - loss: 1.0211 - mse: 1.0211 - val_loss: 0.8858 - val_mse: 0.8858\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 0.9239 - mse: 0.9239 - val_loss: 0.8597 - val_mse: 0.8597\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.8900 - mse: 0.8900 - val_loss: 0.8542 - val_mse: 0.8542\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.8283 - val_mse: 0.8283\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 308ms/step - loss: 0.8566 - mse: 0.8566 - val_loss: 0.8188 - val_mse: 0.8188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 71/200 [29:52<1:21:49, 38.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 587ms/step - loss: 1.1417 - mse: 1.1417 - val_loss: 0.9225 - val_mse: 0.9225\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 0.9633 - mse: 0.9633 - val_loss: 0.8998 - val_mse: 0.8998\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.9488 - mse: 0.9488 - val_loss: 0.8936 - val_mse: 0.8936\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 333ms/step - loss: 0.9442 - mse: 0.9442 - val_loss: 0.8904 - val_mse: 0.8904\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 333ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.8883 - val_mse: 0.8883\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.9393 - mse: 0.9393 - val_loss: 0.8868 - val_mse: 0.8868\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 0.9379 - mse: 0.9379 - val_loss: 0.8858 - val_mse: 0.8858\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.9366 - mse: 0.9366 - val_loss: 0.8849 - val_mse: 0.8849\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.9355 - mse: 0.9355 - val_loss: 0.8840 - val_mse: 0.8840\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.8829 - val_mse: 0.8829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 72/200 [30:02<1:02:52, 29.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 2s 147ms/step - loss: 1.2511 - mse: 1.2511 - val_loss: 1.2511 - val_mse: 1.2511\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2510 - mse: 1.2510 - val_loss: 1.2510 - val_mse: 1.2510\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2500 - mse: 1.2500 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2499 - mse: 1.2499 - val_loss: 1.2499 - val_mse: 1.2499\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.2498 - mse: 1.2498 - val_loss: 1.2498 - val_mse: 1.2498\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2497 - mse: 1.2497 - val_loss: 1.2497 - val_mse: 1.2497\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2496 - mse: 1.2496 - val_loss: 1.2496 - val_mse: 1.2496\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2495 - mse: 1.2495 - val_loss: 1.2495 - val_mse: 1.2495\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2494 - mse: 1.2494 - val_loss: 1.2494 - val_mse: 1.2494\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2491 - mse: 1.2491 - val_loss: 1.2491 - val_mse: 1.2491\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2490 - mse: 1.2490 - val_loss: 1.2490 - val_mse: 1.2490\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 1.2489 - val_mse: 1.2489\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 1.2488 - val_mse: 1.2488\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 1.2488 - mse: 1.2488 - val_loss: 1.2487 - val_mse: 1.2487\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2486 - val_mse: 1.2486\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2486 - mse: 1.2486 - val_loss: 1.2485 - val_mse: 1.2485\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 1.2485 - mse: 1.2485 - val_loss: 1.2484 - val_mse: 1.2484\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2483 - val_mse: 1.2483\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 1.2482 - val_mse: 1.2482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 73/200 [30:44<1:10:28, 33.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 594ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2402 - val_mse: 1.2402\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 388ms/step - loss: 1.2406 - mse: 1.2406 - val_loss: 1.2384 - val_mse: 1.2384\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 363ms/step - loss: 1.2392 - mse: 1.2392 - val_loss: 1.2366 - val_mse: 1.2366\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 1.2377 - mse: 1.2377 - val_loss: 1.2348 - val_mse: 1.2348\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 1.2363 - mse: 1.2363 - val_loss: 1.2331 - val_mse: 1.2331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 74/200 [30:50<52:54, 25.19s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 2s 141ms/step - loss: 1.3503 - mse: 1.3503 - val_loss: 1.3249 - val_mse: 1.3249\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2931 - mse: 1.2931 - val_loss: 1.2621 - val_mse: 1.2621\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2400 - mse: 1.2400 - val_loss: 1.2045 - val_mse: 1.2045\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1924 - mse: 1.1924 - val_loss: 1.1542 - val_mse: 1.1542\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1516 - mse: 1.1516 - val_loss: 1.1117 - val_mse: 1.1117\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1175 - mse: 1.1175 - val_loss: 1.0771 - val_mse: 1.0771\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0901 - mse: 1.0901 - val_loss: 1.0492 - val_mse: 1.0492\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0680 - mse: 1.0680 - val_loss: 1.0269 - val_mse: 1.0269\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.0503 - mse: 1.0503 - val_loss: 1.0090 - val_mse: 1.0090\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0360 - mse: 1.0360 - val_loss: 0.9945 - val_mse: 0.9945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 75/200 [31:02<43:53, 21.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 570ms/step - loss: 1.3236 - mse: 1.3236 - val_loss: 1.2741 - val_mse: 1.2741\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.2877 - mse: 1.2877 - val_loss: 1.2433 - val_mse: 1.2433\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.2583 - mse: 1.2583 - val_loss: 1.2151 - val_mse: 1.2151\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.2308 - mse: 1.2308 - val_loss: 1.1865 - val_mse: 1.1865\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.2029 - mse: 1.2029 - val_loss: 1.1561 - val_mse: 1.1561\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 336ms/step - loss: 1.1744 - mse: 1.1744 - val_loss: 1.1253 - val_mse: 1.1253\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 334ms/step - loss: 1.1455 - mse: 1.1455 - val_loss: 1.0973 - val_mse: 1.0973\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 1.1174 - mse: 1.1174 - val_loss: 1.0725 - val_mse: 1.0725\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 1.0920 - mse: 1.0920 - val_loss: 1.0522 - val_mse: 1.0522\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 1.0704 - mse: 1.0704 - val_loss: 1.0334 - val_mse: 1.0334\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.0509 - mse: 1.0509 - val_loss: 1.0133 - val_mse: 1.0133\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 336ms/step - loss: 1.0316 - mse: 1.0316 - val_loss: 0.9923 - val_mse: 0.9923\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.0128 - mse: 1.0128 - val_loss: 0.9718 - val_mse: 0.9718\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.9953 - mse: 0.9953 - val_loss: 0.9536 - val_mse: 0.9536\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.9800 - mse: 0.9800 - val_loss: 0.9381 - val_mse: 0.9381\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.9667 - mse: 0.9667 - val_loss: 0.9250 - val_mse: 0.9250\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 0.9550 - mse: 0.9550 - val_loss: 0.9137 - val_mse: 0.9137\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.9442 - mse: 0.9442 - val_loss: 0.9044 - val_mse: 0.9044\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.9346 - mse: 0.9346 - val_loss: 0.8965 - val_mse: 0.8965\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 0.9264 - mse: 0.9264 - val_loss: 0.8898 - val_mse: 0.8898\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 383ms/step - loss: 0.9194 - mse: 0.9194 - val_loss: 0.8835 - val_mse: 0.8835\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.8772 - val_mse: 0.8772\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 0.9073 - mse: 0.9073 - val_loss: 0.8711 - val_mse: 0.8711\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 0.9021 - mse: 0.9021 - val_loss: 0.8657 - val_mse: 0.8657\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.8973 - mse: 0.8973 - val_loss: 0.8611 - val_mse: 0.8611\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 0.8928 - mse: 0.8928 - val_loss: 0.8571 - val_mse: 0.8571\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 0.8886 - mse: 0.8886 - val_loss: 0.8534 - val_mse: 0.8534\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.8848 - mse: 0.8848 - val_loss: 0.8497 - val_mse: 0.8497\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 0.8811 - mse: 0.8811 - val_loss: 0.8456 - val_mse: 0.8456\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 336ms/step - loss: 0.8775 - mse: 0.8775 - val_loss: 0.8413 - val_mse: 0.8413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 76/200 [31:44<56:35, 27.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 2s 247ms/step - loss: 1.2328 - mse: 1.2328 - val_loss: 1.2044 - val_mse: 1.2044\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.1999 - mse: 1.1999 - val_loss: 1.1601 - val_mse: 1.1601\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.1597 - mse: 1.1597 - val_loss: 1.1076 - val_mse: 1.1076\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.1129 - mse: 1.1129 - val_loss: 1.0497 - val_mse: 1.0497\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 1.0628 - mse: 1.0628 - val_loss: 0.9945 - val_mse: 0.9945\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.0174 - mse: 1.0174 - val_loss: 0.9509 - val_mse: 0.9509\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.9836 - mse: 0.9836 - val_loss: 0.9221 - val_mse: 0.9221\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.9623 - mse: 0.9623 - val_loss: 0.9056 - val_mse: 0.9056\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.9505 - mse: 0.9505 - val_loss: 0.8964 - val_mse: 0.8964\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.9437 - mse: 0.9437 - val_loss: 0.8909 - val_mse: 0.8909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 77/200 [31:54<45:52, 22.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 147ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2481 - val_mse: 1.2481\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2481 - mse: 1.2481 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2480 - val_mse: 1.2480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 78/200 [32:37<57:34, 28.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 542ms/step - loss: 1.0740 - mse: 1.0740 - val_loss: 1.0731 - val_mse: 1.0731\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.0730 - mse: 1.0730 - val_loss: 1.0721 - val_mse: 1.0721\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 1.0719 - mse: 1.0719 - val_loss: 1.0710 - val_mse: 1.0710\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0708 - mse: 1.0708 - val_loss: 1.0700 - val_mse: 1.0700\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0698 - mse: 1.0698 - val_loss: 1.0690 - val_mse: 1.0690\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 1.0688 - mse: 1.0688 - val_loss: 1.0679 - val_mse: 1.0679\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0678 - mse: 1.0678 - val_loss: 1.0669 - val_mse: 1.0669\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.0668 - mse: 1.0668 - val_loss: 1.0660 - val_mse: 1.0660\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 1.0658 - mse: 1.0658 - val_loss: 1.0650 - val_mse: 1.0650\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0648 - mse: 1.0648 - val_loss: 1.0640 - val_mse: 1.0640\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 333ms/step - loss: 1.0639 - mse: 1.0639 - val_loss: 1.0631 - val_mse: 1.0631\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.0629 - mse: 1.0629 - val_loss: 1.0622 - val_mse: 1.0622\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 1.0620 - mse: 1.0620 - val_loss: 1.0613 - val_mse: 1.0613\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 1.0611 - mse: 1.0611 - val_loss: 1.0604 - val_mse: 1.0604\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 1.0602 - mse: 1.0602 - val_loss: 1.0595 - val_mse: 1.0595\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0593 - mse: 1.0593 - val_loss: 1.0586 - val_mse: 1.0586\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 336ms/step - loss: 1.0585 - mse: 1.0585 - val_loss: 1.0578 - val_mse: 1.0578\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 1.0576 - mse: 1.0576 - val_loss: 1.0570 - val_mse: 1.0570\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 1.0568 - mse: 1.0568 - val_loss: 1.0561 - val_mse: 1.0561\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 1.0560 - mse: 1.0560 - val_loss: 1.0553 - val_mse: 1.0553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 79/200 [32:54<50:15, 24.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "9/9 [==============================] - 2s 147ms/step - loss: 1.0037 - mse: 1.0037 - val_loss: 0.8864 - val_mse: 0.8864\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.8929 - mse: 0.8929 - val_loss: 0.8421 - val_mse: 0.8421\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.8562 - mse: 0.8562 - val_loss: 0.8190 - val_mse: 0.8190\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.8356 - mse: 0.8356 - val_loss: 0.7983 - val_mse: 0.7983\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.8219 - mse: 0.8219 - val_loss: 0.7816 - val_mse: 0.7816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 80/200 [33:00<38:52, 19.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 365ms/step - loss: 1.4060 - mse: 1.4060 - val_loss: 1.4094 - val_mse: 1.4094\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.3808 - mse: 1.3808 - val_loss: 1.3807 - val_mse: 1.3807\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.3556 - mse: 1.3556 - val_loss: 1.3521 - val_mse: 1.3521\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.3309 - mse: 1.3309 - val_loss: 1.3239 - val_mse: 1.3239\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.3065 - mse: 1.3065 - val_loss: 1.2964 - val_mse: 1.2964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 81/200 [33:06<30:42, 15.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 435ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2482 - val_mse: 1.2482\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.2445 - mse: 1.2445 - val_loss: 1.2434 - val_mse: 1.2434\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.2429 - mse: 1.2429 - val_loss: 1.2418 - val_mse: 1.2418\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 310ms/step - loss: 1.2413 - mse: 1.2413 - val_loss: 1.2402 - val_mse: 1.2402\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.2397 - mse: 1.2397 - val_loss: 1.2386 - val_mse: 1.2386\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.2381 - mse: 1.2381 - val_loss: 1.2370 - val_mse: 1.2370\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2365 - mse: 1.2365 - val_loss: 1.2354 - val_mse: 1.2354\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2349 - mse: 1.2349 - val_loss: 1.2338 - val_mse: 1.2338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 82/200 [33:17<27:28, 13.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 385ms/step - loss: 1.2454 - mse: 1.2454 - val_loss: 1.1607 - val_mse: 1.1607\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.1532 - mse: 1.1532 - val_loss: 1.0338 - val_mse: 1.0338\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.0428 - mse: 1.0428 - val_loss: 0.9301 - val_mse: 0.9301\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.9652 - mse: 0.9652 - val_loss: 0.8946 - val_mse: 0.8946\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.9423 - mse: 0.9423 - val_loss: 0.8876 - val_mse: 0.8876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 83/200 [33:23<22:44, 11.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 382ms/step - loss: 1.2486 - mse: 1.2486 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2470 - mse: 1.2470 - val_loss: 1.2458 - val_mse: 1.2458\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2454 - mse: 1.2454 - val_loss: 1.2442 - val_mse: 1.2442\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2438 - mse: 1.2438 - val_loss: 1.2426 - val_mse: 1.2426\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2422 - mse: 1.2422 - val_loss: 1.2410 - val_mse: 1.2410\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 1.2407 - mse: 1.2407 - val_loss: 1.2394 - val_mse: 1.2394\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2391 - mse: 1.2391 - val_loss: 1.2378 - val_mse: 1.2378\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2375 - mse: 1.2375 - val_loss: 1.2363 - val_mse: 1.2363\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.2359 - mse: 1.2359 - val_loss: 1.2347 - val_mse: 1.2347\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2344 - mse: 1.2344 - val_loss: 1.2331 - val_mse: 1.2331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 84/200 [33:34<21:47, 11.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 250ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2471 - val_mse: 1.2471\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 1.2469 - mse: 1.2469 - val_loss: 1.2466 - val_mse: 1.2466\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2455 - val_mse: 1.2455\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 1.2453 - mse: 1.2453 - val_loss: 1.2450 - val_mse: 1.2450\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.2448 - mse: 1.2448 - val_loss: 1.2444 - val_mse: 1.2444\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.2443 - mse: 1.2443 - val_loss: 1.2439 - val_mse: 1.2439\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.2437 - mse: 1.2437 - val_loss: 1.2434 - val_mse: 1.2434\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 1.2432 - mse: 1.2432 - val_loss: 1.2428 - val_mse: 1.2428\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.2423 - val_mse: 1.2423\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2418 - val_mse: 1.2418\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.2416 - mse: 1.2416 - val_loss: 1.2412 - val_mse: 1.2412\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 1.2411 - mse: 1.2411 - val_loss: 1.2407 - val_mse: 1.2407\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 1.2405 - mse: 1.2405 - val_loss: 1.2402 - val_mse: 1.2402\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 1.2400 - mse: 1.2400 - val_loss: 1.2396 - val_mse: 1.2396\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 1.2391 - val_mse: 1.2391\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 1.2389 - mse: 1.2389 - val_loss: 1.2386 - val_mse: 1.2386\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.2384 - mse: 1.2384 - val_loss: 1.2381 - val_mse: 1.2381\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 1.2379 - mse: 1.2379 - val_loss: 1.2375 - val_mse: 1.2375\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 1.2374 - mse: 1.2374 - val_loss: 1.2370 - val_mse: 1.2370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▎     | 85/200 [33:55<27:34, 14.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 230ms/step - loss: 1.2489 - mse: 1.2489 - val_loss: 1.2390 - val_mse: 1.2390\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 1.2428 - mse: 1.2428 - val_loss: 1.2327 - val_mse: 1.2327\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2367 - mse: 1.2367 - val_loss: 1.2264 - val_mse: 1.2264\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2308 - mse: 1.2308 - val_loss: 1.2203 - val_mse: 1.2203\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 1.2252 - mse: 1.2252 - val_loss: 1.2146 - val_mse: 1.2146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 86/200 [34:01<22:41, 11.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 244ms/step - loss: 1.1508 - mse: 1.1508 - val_loss: 0.9614 - val_mse: 0.9614\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.9651 - mse: 0.9651 - val_loss: 0.8846 - val_mse: 0.8846\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 0.9341 - mse: 0.9341 - val_loss: 0.8804 - val_mse: 0.8804\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.9314 - mse: 0.9314 - val_loss: 0.8768 - val_mse: 0.8768\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.9279 - mse: 0.9279 - val_loss: 0.8731 - val_mse: 0.8731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 87/200 [34:07<19:08, 10.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 137ms/step - loss: 1.2455 - mse: 1.2455 - val_loss: 1.2378 - val_mse: 1.2378\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2364 - mse: 1.2364 - val_loss: 1.2274 - val_mse: 1.2274\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2278 - mse: 1.2278 - val_loss: 1.2171 - val_mse: 1.2171\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2192 - mse: 1.2192 - val_loss: 1.2070 - val_mse: 1.2070\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2108 - mse: 1.2108 - val_loss: 1.1969 - val_mse: 1.1969\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2022 - mse: 1.2022 - val_loss: 1.1866 - val_mse: 1.1866\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1935 - mse: 1.1935 - val_loss: 1.1761 - val_mse: 1.1761\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1845 - mse: 1.1845 - val_loss: 1.1652 - val_mse: 1.1652\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.1751 - mse: 1.1751 - val_loss: 1.1539 - val_mse: 1.1539\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 1.1653 - mse: 1.1653 - val_loss: 1.1421 - val_mse: 1.1421\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.1552 - mse: 1.1552 - val_loss: 1.1300 - val_mse: 1.1300\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.1447 - mse: 1.1447 - val_loss: 1.1174 - val_mse: 1.1174\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.1337 - mse: 1.1337 - val_loss: 1.1045 - val_mse: 1.1045\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.1226 - mse: 1.1226 - val_loss: 1.0913 - val_mse: 1.0913\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.1111 - mse: 1.1111 - val_loss: 1.0780 - val_mse: 1.0780\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0996 - mse: 1.0996 - val_loss: 1.0646 - val_mse: 1.0646\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0880 - mse: 1.0880 - val_loss: 1.0513 - val_mse: 1.0513\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 1.0765 - mse: 1.0765 - val_loss: 1.0383 - val_mse: 1.0383\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.0653 - mse: 1.0653 - val_loss: 1.0257 - val_mse: 1.0257\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0545 - mse: 1.0545 - val_loss: 1.0136 - val_mse: 1.0136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 88/200 [34:29<25:08, 13.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 356ms/step - loss: 1.3539 - mse: 1.3539 - val_loss: 1.3505 - val_mse: 1.3505\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.3496 - mse: 1.3496 - val_loss: 1.3461 - val_mse: 1.3461\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.3452 - mse: 1.3452 - val_loss: 1.3417 - val_mse: 1.3417\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.3408 - mse: 1.3408 - val_loss: 1.3374 - val_mse: 1.3374\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.3365 - mse: 1.3365 - val_loss: 1.3331 - val_mse: 1.3331\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.3322 - mse: 1.3322 - val_loss: 1.3288 - val_mse: 1.3288\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.3279 - mse: 1.3279 - val_loss: 1.3245 - val_mse: 1.3245\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.3236 - mse: 1.3236 - val_loss: 1.3202 - val_mse: 1.3202\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.3194 - mse: 1.3194 - val_loss: 1.3160 - val_mse: 1.3160\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.3151 - mse: 1.3151 - val_loss: 1.3118 - val_mse: 1.3118\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.3110 - mse: 1.3110 - val_loss: 1.3077 - val_mse: 1.3077\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.3068 - mse: 1.3068 - val_loss: 1.3035 - val_mse: 1.3035\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.3027 - mse: 1.3027 - val_loss: 1.2994 - val_mse: 1.2994\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2986 - mse: 1.2986 - val_loss: 1.2953 - val_mse: 1.2953\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.2945 - mse: 1.2945 - val_loss: 1.2913 - val_mse: 1.2913\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2904 - mse: 1.2904 - val_loss: 1.2873 - val_mse: 1.2873\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2864 - mse: 1.2864 - val_loss: 1.2833 - val_mse: 1.2833\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.2825 - mse: 1.2825 - val_loss: 1.2794 - val_mse: 1.2794\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.2785 - mse: 1.2785 - val_loss: 1.2755 - val_mse: 1.2755\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.2746 - mse: 1.2746 - val_loss: 1.2716 - val_mse: 1.2716\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2708 - mse: 1.2708 - val_loss: 1.2678 - val_mse: 1.2678\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.2670 - mse: 1.2670 - val_loss: 1.2640 - val_mse: 1.2640\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.2632 - mse: 1.2632 - val_loss: 1.2602 - val_mse: 1.2602\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.2594 - mse: 1.2594 - val_loss: 1.2565 - val_mse: 1.2565\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2557 - mse: 1.2557 - val_loss: 1.2528 - val_mse: 1.2528\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2520 - mse: 1.2520 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2456 - val_mse: 1.2456\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.2448 - mse: 1.2448 - val_loss: 1.2420 - val_mse: 1.2420\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2413 - mse: 1.2413 - val_loss: 1.2385 - val_mse: 1.2385\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.2377 - mse: 1.2377 - val_loss: 1.2350 - val_mse: 1.2350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 89/200 [34:54<31:37, 17.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 358ms/step - loss: 1.5029 - mse: 1.5029 - val_loss: 1.4995 - val_mse: 1.4995\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.4985 - mse: 1.4985 - val_loss: 1.4951 - val_mse: 1.4951\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.4942 - mse: 1.4942 - val_loss: 1.4908 - val_mse: 1.4908\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.4899 - mse: 1.4899 - val_loss: 1.4865 - val_mse: 1.4865\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.4856 - mse: 1.4856 - val_loss: 1.4821 - val_mse: 1.4821\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.4812 - mse: 1.4812 - val_loss: 1.4778 - val_mse: 1.4778\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.4769 - mse: 1.4769 - val_loss: 1.4734 - val_mse: 1.4734\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.4725 - mse: 1.4725 - val_loss: 1.4691 - val_mse: 1.4691\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.4682 - mse: 1.4682 - val_loss: 1.4647 - val_mse: 1.4647\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.4638 - mse: 1.4638 - val_loss: 1.4604 - val_mse: 1.4604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 90/200 [35:04<27:04, 14.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 393ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2451 - val_mse: 1.2451\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.2440 - mse: 1.2440 - val_loss: 1.2428 - val_mse: 1.2428\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.2417 - mse: 1.2417 - val_loss: 1.2406 - val_mse: 1.2406\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2393 - mse: 1.2393 - val_loss: 1.2380 - val_mse: 1.2380\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.2366 - mse: 1.2366 - val_loss: 1.2350 - val_mse: 1.2350\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2335 - mse: 1.2335 - val_loss: 1.2315 - val_mse: 1.2315\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2299 - mse: 1.2299 - val_loss: 1.2274 - val_mse: 1.2274\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.2257 - mse: 1.2257 - val_loss: 1.2226 - val_mse: 1.2226\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2209 - mse: 1.2209 - val_loss: 1.2170 - val_mse: 1.2170\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2153 - mse: 1.2153 - val_loss: 1.2106 - val_mse: 1.2106\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.2088 - mse: 1.2088 - val_loss: 1.2030 - val_mse: 1.2030\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2012 - mse: 1.2012 - val_loss: 1.1942 - val_mse: 1.1942\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.1922 - mse: 1.1922 - val_loss: 1.1837 - val_mse: 1.1837\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.1818 - mse: 1.1818 - val_loss: 1.1714 - val_mse: 1.1714\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.1696 - mse: 1.1696 - val_loss: 1.1571 - val_mse: 1.1571\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.1556 - mse: 1.1556 - val_loss: 1.1406 - val_mse: 1.1406\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.1396 - mse: 1.1396 - val_loss: 1.1218 - val_mse: 1.1218\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 1.1009 - val_mse: 1.1009\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.1015 - mse: 1.1015 - val_loss: 1.0782 - val_mse: 1.0782\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.0803 - mse: 1.0803 - val_loss: 1.0540 - val_mse: 1.0540\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.0580 - mse: 1.0580 - val_loss: 1.0294 - val_mse: 1.0294\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.0357 - mse: 1.0357 - val_loss: 1.0057 - val_mse: 1.0057\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.0144 - mse: 1.0144 - val_loss: 0.9838 - val_mse: 0.9838\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.9949 - mse: 0.9949 - val_loss: 0.9644 - val_mse: 0.9644\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.9779 - mse: 0.9779 - val_loss: 0.9480 - val_mse: 0.9480\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.9637 - mse: 0.9637 - val_loss: 0.9344 - val_mse: 0.9344\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.9522 - mse: 0.9522 - val_loss: 0.9234 - val_mse: 0.9234\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.9429 - mse: 0.9429 - val_loss: 0.9146 - val_mse: 0.9146\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.9353 - mse: 0.9353 - val_loss: 0.9075 - val_mse: 0.9075\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.9289 - mse: 0.9289 - val_loss: 0.9007 - val_mse: 0.9007\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.9229 - mse: 0.9229 - val_loss: 0.8941 - val_mse: 0.8941\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.9172 - mse: 0.9172 - val_loss: 0.8879 - val_mse: 0.8879\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.8816 - val_mse: 0.8816\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.9054 - mse: 0.9054 - val_loss: 0.8737 - val_mse: 0.8737\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.8991 - mse: 0.8991 - val_loss: 0.8666 - val_mse: 0.8666\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.8924 - mse: 0.8924 - val_loss: 0.8593 - val_mse: 0.8593\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.8855 - mse: 0.8855 - val_loss: 0.8515 - val_mse: 0.8515\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.8785 - mse: 0.8785 - val_loss: 0.8437 - val_mse: 0.8437\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 0.8714 - mse: 0.8714 - val_loss: 0.8355 - val_mse: 0.8355\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.8644 - mse: 0.8644 - val_loss: 0.8284 - val_mse: 0.8284\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.8576 - mse: 0.8576 - val_loss: 0.8212 - val_mse: 0.8212\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.8513 - mse: 0.8513 - val_loss: 0.8143 - val_mse: 0.8143\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.8454 - mse: 0.8454 - val_loss: 0.8094 - val_mse: 0.8094\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.8402 - mse: 0.8402 - val_loss: 0.8034 - val_mse: 0.8034\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.8355 - mse: 0.8355 - val_loss: 0.7995 - val_mse: 0.7995\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.8313 - mse: 0.8313 - val_loss: 0.7950 - val_mse: 0.7950\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.8276 - mse: 0.8276 - val_loss: 0.7930 - val_mse: 0.7930\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.8242 - mse: 0.8242 - val_loss: 0.7880 - val_mse: 0.7880\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.8212 - mse: 0.8212 - val_loss: 0.7862 - val_mse: 0.7862\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.8182 - mse: 0.8182 - val_loss: 0.7839 - val_mse: 0.7839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 91/200 [35:46<41:43, 22.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 555ms/step - loss: 1.0793 - mse: 1.0793 - val_loss: 1.0783 - val_mse: 1.0783\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 1.0781 - mse: 1.0781 - val_loss: 1.0772 - val_mse: 1.0772\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 1.0770 - mse: 1.0770 - val_loss: 1.0760 - val_mse: 1.0760\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.0758 - mse: 1.0758 - val_loss: 1.0749 - val_mse: 1.0749\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.0747 - mse: 1.0747 - val_loss: 1.0738 - val_mse: 1.0738\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 1.0736 - mse: 1.0736 - val_loss: 1.0727 - val_mse: 1.0727\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 1.0725 - mse: 1.0725 - val_loss: 1.0717 - val_mse: 1.0717\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.0715 - mse: 1.0715 - val_loss: 1.0706 - val_mse: 1.0706\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 1.0704 - mse: 1.0704 - val_loss: 1.0696 - val_mse: 1.0696\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0694 - mse: 1.0694 - val_loss: 1.0686 - val_mse: 1.0686\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.0684 - mse: 1.0684 - val_loss: 1.0676 - val_mse: 1.0676\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 1.0674 - mse: 1.0674 - val_loss: 1.0666 - val_mse: 1.0666\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 1.0664 - mse: 1.0664 - val_loss: 1.0656 - val_mse: 1.0656\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 324ms/step - loss: 1.0654 - mse: 1.0654 - val_loss: 1.0646 - val_mse: 1.0646\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 330ms/step - loss: 1.0644 - mse: 1.0644 - val_loss: 1.0637 - val_mse: 1.0637\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 1.0635 - mse: 1.0635 - val_loss: 1.0628 - val_mse: 1.0628\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 337ms/step - loss: 1.0626 - mse: 1.0626 - val_loss: 1.0618 - val_mse: 1.0618\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 1.0617 - mse: 1.0617 - val_loss: 1.0609 - val_mse: 1.0609\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 1.0608 - mse: 1.0608 - val_loss: 1.0601 - val_mse: 1.0601\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 1.0599 - mse: 1.0599 - val_loss: 1.0592 - val_mse: 1.0592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 92/200 [36:07<40:35, 22.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 349ms/step - loss: 1.2732 - mse: 1.2732 - val_loss: 1.2400 - val_mse: 1.2400\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.2316 - mse: 1.2316 - val_loss: 1.2014 - val_mse: 1.2014\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.1939 - mse: 1.1939 - val_loss: 1.1672 - val_mse: 1.1672\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.1606 - mse: 1.1606 - val_loss: 1.1375 - val_mse: 1.1375\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.1319 - mse: 1.1319 - val_loss: 1.1125 - val_mse: 1.1125\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.1078 - mse: 1.1078 - val_loss: 1.0918 - val_mse: 1.0918\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0880 - mse: 1.0880 - val_loss: 1.0750 - val_mse: 1.0750\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0719 - mse: 1.0719 - val_loss: 1.0615 - val_mse: 1.0615\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.0590 - mse: 1.0590 - val_loss: 1.0507 - val_mse: 1.0507\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.0488 - mse: 1.0488 - val_loss: 1.0422 - val_mse: 1.0422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 93/200 [36:19<34:13, 19.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 554ms/step - loss: 1.6394 - mse: 1.6394 - val_loss: 1.5277 - val_mse: 1.5277\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.5051 - mse: 1.5051 - val_loss: 1.3852 - val_mse: 1.3852\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.3633 - mse: 1.3633 - val_loss: 1.2532 - val_mse: 1.2532\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.2354 - mse: 1.2354 - val_loss: 1.1505 - val_mse: 1.1505\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.1383 - mse: 1.1383 - val_loss: 1.0832 - val_mse: 1.0832\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 1.0761 - mse: 1.0761 - val_loss: 1.0448 - val_mse: 1.0448\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 1.0409 - mse: 1.0409 - val_loss: 1.0244 - val_mse: 1.0244\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 326ms/step - loss: 1.0224 - mse: 1.0224 - val_loss: 1.0138 - val_mse: 1.0138\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 326ms/step - loss: 1.0127 - mse: 1.0127 - val_loss: 1.0082 - val_mse: 1.0082\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 1.0076 - mse: 1.0076 - val_loss: 1.0051 - val_mse: 1.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 94/200 [36:30<29:44, 16.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 387ms/step - loss: 1.0192 - mse: 1.0192 - val_loss: 0.8917 - val_mse: 0.8917\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9302 - mse: 0.9302 - val_loss: 0.8862 - val_mse: 0.8862\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9200 - mse: 0.9200 - val_loss: 0.8820 - val_mse: 0.8820\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.8718 - val_mse: 0.8718\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.9027 - mse: 0.9027 - val_loss: 0.8626 - val_mse: 0.8626\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.8881 - mse: 0.8881 - val_loss: 0.8508 - val_mse: 0.8508\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.8715 - mse: 0.8715 - val_loss: 0.8252 - val_mse: 0.8252\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.8556 - mse: 0.8556 - val_loss: 0.8210 - val_mse: 0.8210\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.8471 - mse: 0.8471 - val_loss: 0.8112 - val_mse: 0.8112\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.8392 - mse: 0.8392 - val_loss: 0.8065 - val_mse: 0.8065\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.8317 - mse: 0.8317 - val_loss: 0.7982 - val_mse: 0.7982\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.8248 - mse: 0.8248 - val_loss: 0.7917 - val_mse: 0.7917\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.8191 - mse: 0.8191 - val_loss: 0.7852 - val_mse: 0.7852\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.8151 - mse: 0.8151 - val_loss: 0.7866 - val_mse: 0.7866\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.8112 - mse: 0.8112 - val_loss: 0.7778 - val_mse: 0.7778\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.8034 - mse: 0.8034 - val_loss: 0.7662 - val_mse: 0.7662\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.8004 - mse: 0.8004 - val_loss: 0.7724 - val_mse: 0.7724\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.7984 - mse: 0.7984 - val_loss: 0.7585 - val_mse: 0.7585\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.7949 - mse: 0.7949 - val_loss: 0.7624 - val_mse: 0.7624\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.7927 - mse: 0.7927 - val_loss: 0.7560 - val_mse: 0.7560\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.7889 - mse: 0.7889 - val_loss: 0.7558 - val_mse: 0.7558\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.7889 - mse: 0.7889 - val_loss: 0.7589 - val_mse: 0.7589\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.7883 - mse: 0.7883 - val_loss: 0.7526 - val_mse: 0.7526\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.7881 - mse: 0.7881 - val_loss: 0.7540 - val_mse: 0.7540\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.7860 - mse: 0.7860 - val_loss: 0.7580 - val_mse: 0.7580\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.7851 - mse: 0.7851 - val_loss: 0.7455 - val_mse: 0.7455\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.7821 - mse: 0.7821 - val_loss: 0.7399 - val_mse: 0.7399\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.7776 - mse: 0.7776 - val_loss: 0.7435 - val_mse: 0.7435\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.7798 - mse: 0.7798 - val_loss: 0.7359 - val_mse: 0.7359\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.7762 - mse: 0.7762 - val_loss: 0.7412 - val_mse: 0.7412\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.7763 - mse: 0.7763 - val_loss: 0.7341 - val_mse: 0.7341\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.7751 - mse: 0.7751 - val_loss: 0.7381 - val_mse: 0.7381\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.7724 - mse: 0.7724 - val_loss: 0.7360 - val_mse: 0.7360\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.7716 - mse: 0.7716 - val_loss: 0.7296 - val_mse: 0.7296\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.7704 - mse: 0.7704 - val_loss: 0.7296 - val_mse: 0.7296\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.7695 - mse: 0.7695 - val_loss: 0.7329 - val_mse: 0.7329\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.7689 - mse: 0.7689 - val_loss: 0.7285 - val_mse: 0.7285\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.7686 - mse: 0.7686 - val_loss: 0.7301 - val_mse: 0.7301\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.7685 - mse: 0.7685 - val_loss: 0.7268 - val_mse: 0.7268\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.7678 - mse: 0.7678 - val_loss: 0.7280 - val_mse: 0.7280\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.7676 - mse: 0.7676 - val_loss: 0.7303 - val_mse: 0.7303\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.7666 - mse: 0.7666 - val_loss: 0.7257 - val_mse: 0.7257\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.7660 - mse: 0.7660 - val_loss: 0.7247 - val_mse: 0.7247\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.7669 - mse: 0.7669 - val_loss: 0.7265 - val_mse: 0.7265\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.7652 - mse: 0.7652 - val_loss: 0.7243 - val_mse: 0.7243\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.7650 - mse: 0.7650 - val_loss: 0.7244 - val_mse: 0.7244\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.7652 - mse: 0.7652 - val_loss: 0.7357 - val_mse: 0.7357\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.7684 - mse: 0.7684 - val_loss: 0.7260 - val_mse: 0.7260\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.7677 - mse: 0.7677 - val_loss: 0.7319 - val_mse: 0.7319\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.7656 - mse: 0.7656 - val_loss: 0.7235 - val_mse: 0.7235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 95/200 [37:53<1:04:12, 36.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 401ms/step - loss: 1.1740 - mse: 1.1740 - val_loss: 0.9397 - val_mse: 0.9397\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.9723 - mse: 0.9723 - val_loss: 0.9099 - val_mse: 0.9099\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 0.9559 - mse: 0.9559 - val_loss: 0.9005 - val_mse: 0.9005\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.9492 - mse: 0.9492 - val_loss: 0.8951 - val_mse: 0.8951\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 0.9448 - mse: 0.9448 - val_loss: 0.8915 - val_mse: 0.8915\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.9418 - mse: 0.9418 - val_loss: 0.8890 - val_mse: 0.8890\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.9394 - mse: 0.9394 - val_loss: 0.8871 - val_mse: 0.8871\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.9375 - mse: 0.9375 - val_loss: 0.8857 - val_mse: 0.8857\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.9358 - mse: 0.9358 - val_loss: 0.8845 - val_mse: 0.8845\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.9340 - mse: 0.9340 - val_loss: 0.8832 - val_mse: 0.8832\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.9319 - mse: 0.9319 - val_loss: 0.8813 - val_mse: 0.8813\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.9286 - mse: 0.9286 - val_loss: 0.8783 - val_mse: 0.8783\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.9231 - mse: 0.9231 - val_loss: 0.8726 - val_mse: 0.8726\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 0.9093 - mse: 0.9093 - val_loss: 0.8656 - val_mse: 0.8656\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.8866 - mse: 0.8866 - val_loss: 0.8420 - val_mse: 0.8420\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.8721 - mse: 0.8721 - val_loss: 0.8389 - val_mse: 0.8389\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 0.8594 - mse: 0.8594 - val_loss: 0.8223 - val_mse: 0.8223\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 0.8430 - mse: 0.8430 - val_loss: 0.8119 - val_mse: 0.8119\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 0.8319 - mse: 0.8319 - val_loss: 0.8000 - val_mse: 0.8000\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.8253 - mse: 0.8253 - val_loss: 0.7965 - val_mse: 0.7965\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 0.8205 - mse: 0.8205 - val_loss: 0.7949 - val_mse: 0.7949\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.8175 - mse: 0.8175 - val_loss: 0.7901 - val_mse: 0.7901\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 0.8160 - mse: 0.8160 - val_loss: 0.7900 - val_mse: 0.7900\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 0.8127 - mse: 0.8127 - val_loss: 0.7902 - val_mse: 0.7902\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.8109 - mse: 0.8109 - val_loss: 0.7829 - val_mse: 0.7829\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.8089 - mse: 0.8089 - val_loss: 0.7843 - val_mse: 0.7843\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 0.8067 - mse: 0.8067 - val_loss: 0.7773 - val_mse: 0.7773\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 0.8050 - mse: 0.8050 - val_loss: 0.7788 - val_mse: 0.7788\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 0.8033 - mse: 0.8033 - val_loss: 0.7730 - val_mse: 0.7730\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 0.8017 - mse: 0.8017 - val_loss: 0.7737 - val_mse: 0.7737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 96/200 [38:35<1:06:23, 38.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 571ms/step - loss: 1.2318 - mse: 1.2318 - val_loss: 1.2252 - val_mse: 1.2252\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.2300 - mse: 1.2300 - val_loss: 1.2230 - val_mse: 1.2230\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 342ms/step - loss: 1.2282 - mse: 1.2282 - val_loss: 1.2209 - val_mse: 1.2209\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.2264 - mse: 1.2264 - val_loss: 1.2187 - val_mse: 1.2187\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 343ms/step - loss: 1.2246 - mse: 1.2246 - val_loss: 1.2166 - val_mse: 1.2166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 97/200 [38:40<48:45, 28.40s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 416ms/step - loss: 1.2510 - mse: 1.2510 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2510 - mse: 1.2510 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2509 - val_mse: 1.2509\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 290ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2509 - mse: 1.2509 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2508 - val_mse: 1.2508\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2508 - mse: 1.2508 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.2507 - mse: 1.2507 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2506 - val_mse: 1.2506\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.2506 - mse: 1.2506 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2505 - val_mse: 1.2505\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2505 - mse: 1.2505 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2504 - val_mse: 1.2504\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2504 - mse: 1.2504 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2503 - val_mse: 1.2503\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 1.2503 - mse: 1.2503 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2502 - val_mse: 1.2502\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 294ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.2502 - mse: 1.2502 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 288ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2501 - val_mse: 1.2501\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.2500 - mse: 1.2500 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.2500 - mse: 1.2500 - val_loss: 1.2499 - val_mse: 1.2499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 98/200 [40:03<1:16:08, 44.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 435ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2463 - val_mse: 1.2463\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2463 - val_mse: 1.2463\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2463 - mse: 1.2463 - val_loss: 1.2462 - val_mse: 1.2462\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2462 - mse: 1.2462 - val_loss: 1.2462 - val_mse: 1.2462\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2462 - mse: 1.2462 - val_loss: 1.2462 - val_mse: 1.2462\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.2462 - mse: 1.2462 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2461 - val_mse: 1.2461\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2461 - mse: 1.2461 - val_loss: 1.2460 - val_mse: 1.2460\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2460 - val_mse: 1.2460\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2460 - val_mse: 1.2460\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2459 - val_mse: 1.2459\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2459 - val_mse: 1.2459\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2459 - val_mse: 1.2459\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.2459 - mse: 1.2459 - val_loss: 1.2458 - val_mse: 1.2458\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 1.2458 - val_mse: 1.2458\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 1.2458 - val_mse: 1.2458\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 1.2457 - val_mse: 1.2457\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2457 - mse: 1.2457 - val_loss: 1.2457 - val_mse: 1.2457\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2457 - mse: 1.2457 - val_loss: 1.2457 - val_mse: 1.2457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 99/200 [40:23<1:02:48, 37.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 569ms/step - loss: 1.1967 - mse: 1.1967 - val_loss: 1.0804 - val_mse: 1.0804\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.0920 - mse: 1.0920 - val_loss: 0.9990 - val_mse: 0.9990\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.0226 - mse: 1.0226 - val_loss: 0.9504 - val_mse: 0.9504\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9806 - mse: 0.9806 - val_loss: 0.9223 - val_mse: 0.9223\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9556 - mse: 0.9556 - val_loss: 0.9055 - val_mse: 0.9055\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.9397 - mse: 0.9397 - val_loss: 0.8946 - val_mse: 0.8946\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.9291 - mse: 0.9291 - val_loss: 0.8871 - val_mse: 0.8871\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.9216 - mse: 0.9216 - val_loss: 0.8813 - val_mse: 0.8813\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.9158 - mse: 0.9158 - val_loss: 0.8767 - val_mse: 0.8767\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 0.8727 - val_mse: 0.8727\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.8692 - val_mse: 0.8692\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9038 - mse: 0.9038 - val_loss: 0.8661 - val_mse: 0.8661\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.9006 - mse: 0.9006 - val_loss: 0.8632 - val_mse: 0.8632\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.8976 - mse: 0.8976 - val_loss: 0.8604 - val_mse: 0.8604\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.8947 - mse: 0.8947 - val_loss: 0.8577 - val_mse: 0.8577\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.8918 - mse: 0.8918 - val_loss: 0.8549 - val_mse: 0.8549\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 0.8889 - mse: 0.8889 - val_loss: 0.8521 - val_mse: 0.8521\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.8860 - mse: 0.8860 - val_loss: 0.8493 - val_mse: 0.8493\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.8832 - mse: 0.8832 - val_loss: 0.8465 - val_mse: 0.8465\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.8803 - mse: 0.8803 - val_loss: 0.8437 - val_mse: 0.8437\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.8776 - mse: 0.8776 - val_loss: 0.8408 - val_mse: 0.8408\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.8749 - mse: 0.8749 - val_loss: 0.8381 - val_mse: 0.8381\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 0.8725 - mse: 0.8725 - val_loss: 0.8358 - val_mse: 0.8358\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 0.8701 - mse: 0.8701 - val_loss: 0.8339 - val_mse: 0.8339\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.8678 - mse: 0.8678 - val_loss: 0.8323 - val_mse: 0.8323\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.8657 - mse: 0.8657 - val_loss: 0.8306 - val_mse: 0.8306\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.8637 - mse: 0.8637 - val_loss: 0.8289 - val_mse: 0.8289\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 387ms/step - loss: 0.8618 - mse: 0.8618 - val_loss: 0.8270 - val_mse: 0.8270\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.8597 - mse: 0.8597 - val_loss: 0.8251 - val_mse: 0.8251\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.8577 - mse: 0.8577 - val_loss: 0.8232 - val_mse: 0.8232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 100/200 [41:05<1:04:34, 38.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 242ms/step - loss: 1.2382 - mse: 1.2382 - val_loss: 1.2022 - val_mse: 1.2022\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.1959 - mse: 1.1959 - val_loss: 1.1522 - val_mse: 1.1522\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.1530 - mse: 1.1530 - val_loss: 1.0975 - val_mse: 1.0975\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.1044 - mse: 1.1044 - val_loss: 1.0391 - val_mse: 1.0391\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 1.0540 - mse: 1.0540 - val_loss: 0.9846 - val_mse: 0.9846\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.0094 - mse: 1.0094 - val_loss: 0.9426 - val_mse: 0.9426\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9772 - mse: 0.9772 - val_loss: 0.9160 - val_mse: 0.9160\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.9577 - mse: 0.9577 - val_loss: 0.9013 - val_mse: 0.9013\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.9473 - mse: 0.9473 - val_loss: 0.8934 - val_mse: 0.8934\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9415 - mse: 0.9415 - val_loss: 0.8889 - val_mse: 0.8889\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.9381 - mse: 0.9381 - val_loss: 0.8860 - val_mse: 0.8860\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 0.9358 - mse: 0.9358 - val_loss: 0.8838 - val_mse: 0.8838\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.9340 - mse: 0.9340 - val_loss: 0.8821 - val_mse: 0.8821\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.9324 - mse: 0.9324 - val_loss: 0.8806 - val_mse: 0.8806\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 0.9309 - mse: 0.9309 - val_loss: 0.8792 - val_mse: 0.8792\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.9296 - mse: 0.9296 - val_loss: 0.8779 - val_mse: 0.8779\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9283 - mse: 0.9283 - val_loss: 0.8768 - val_mse: 0.8768\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 0.9272 - mse: 0.9272 - val_loss: 0.8757 - val_mse: 0.8757\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9260 - mse: 0.9260 - val_loss: 0.8747 - val_mse: 0.8747\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.9250 - mse: 0.9250 - val_loss: 0.8738 - val_mse: 0.8738\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9240 - mse: 0.9240 - val_loss: 0.8730 - val_mse: 0.8730\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9231 - mse: 0.9231 - val_loss: 0.8722 - val_mse: 0.8722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 0.9222 - mse: 0.9222 - val_loss: 0.8715 - val_mse: 0.8715\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 0.9214 - mse: 0.9214 - val_loss: 0.8709 - val_mse: 0.8709\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9207 - mse: 0.9207 - val_loss: 0.8703 - val_mse: 0.8703\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 0.9199 - mse: 0.9199 - val_loss: 0.8698 - val_mse: 0.8698\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.9192 - mse: 0.9192 - val_loss: 0.8693 - val_mse: 0.8693\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9185 - mse: 0.9185 - val_loss: 0.8688 - val_mse: 0.8688\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.9178 - mse: 0.9178 - val_loss: 0.8683 - val_mse: 0.8683\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.9171 - mse: 0.9171 - val_loss: 0.8679 - val_mse: 0.8679\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9164 - mse: 0.9164 - val_loss: 0.8674 - val_mse: 0.8674\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.9156 - mse: 0.9156 - val_loss: 0.8670 - val_mse: 0.8670\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9149 - mse: 0.9149 - val_loss: 0.8665 - val_mse: 0.8665\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9141 - mse: 0.9141 - val_loss: 0.8661 - val_mse: 0.8661\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.9133 - mse: 0.9133 - val_loss: 0.8656 - val_mse: 0.8656\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.9125 - mse: 0.9125 - val_loss: 0.8653 - val_mse: 0.8653\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.9117 - mse: 0.9117 - val_loss: 0.8650 - val_mse: 0.8650\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 0.9109 - mse: 0.9109 - val_loss: 0.8647 - val_mse: 0.8647\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9102 - mse: 0.9102 - val_loss: 0.8644 - val_mse: 0.8644\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9095 - mse: 0.9095 - val_loss: 0.8642 - val_mse: 0.8642\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9087 - mse: 0.9087 - val_loss: 0.8638 - val_mse: 0.8638\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9080 - mse: 0.9080 - val_loss: 0.8634 - val_mse: 0.8634\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 1s 197ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.8631 - val_mse: 0.8631\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9063 - mse: 0.9063 - val_loss: 0.8627 - val_mse: 0.8627\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.9054 - mse: 0.9054 - val_loss: 0.8624 - val_mse: 0.8624\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 1s 201ms/step - loss: 0.9043 - mse: 0.9043 - val_loss: 0.8622 - val_mse: 0.8622\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9028 - mse: 0.9028 - val_loss: 0.8619 - val_mse: 0.8619\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.9010 - mse: 0.9010 - val_loss: 0.8615 - val_mse: 0.8615\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 0.8977 - mse: 0.8977 - val_loss: 0.8596 - val_mse: 0.8596\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.8906 - mse: 0.8906 - val_loss: 0.8570 - val_mse: 0.8570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 101/200 [42:28<1:25:50, 52.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 604ms/step - loss: 1.2444 - mse: 1.2444 - val_loss: 1.2443 - val_mse: 1.2443\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 389ms/step - loss: 1.2442 - mse: 1.2442 - val_loss: 1.2440 - val_mse: 1.2440\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 372ms/step - loss: 1.2440 - mse: 1.2440 - val_loss: 1.2438 - val_mse: 1.2438\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 1.2438 - mse: 1.2438 - val_loss: 1.2436 - val_mse: 1.2436\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 1.2436 - mse: 1.2436 - val_loss: 1.2434 - val_mse: 1.2434\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 1.2434 - mse: 1.2434 - val_loss: 1.2432 - val_mse: 1.2432\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 380ms/step - loss: 1.2431 - mse: 1.2431 - val_loss: 1.2430 - val_mse: 1.2430\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 380ms/step - loss: 1.2429 - mse: 1.2429 - val_loss: 1.2427 - val_mse: 1.2427\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 381ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.2425 - val_mse: 1.2425\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 373ms/step - loss: 1.2425 - mse: 1.2425 - val_loss: 1.2423 - val_mse: 1.2423\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 1.2423 - mse: 1.2423 - val_loss: 1.2421 - val_mse: 1.2421\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 372ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2419 - val_mse: 1.2419\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 1.2418 - mse: 1.2418 - val_loss: 1.2417 - val_mse: 1.2417\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 382ms/step - loss: 1.2416 - mse: 1.2416 - val_loss: 1.2414 - val_mse: 1.2414\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 381ms/step - loss: 1.2414 - mse: 1.2414 - val_loss: 1.2412 - val_mse: 1.2412\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 1.2412 - mse: 1.2412 - val_loss: 1.2410 - val_mse: 1.2410\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 368ms/step - loss: 1.2410 - mse: 1.2410 - val_loss: 1.2408 - val_mse: 1.2408\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 373ms/step - loss: 1.2408 - mse: 1.2408 - val_loss: 1.2406 - val_mse: 1.2406\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 1.2406 - mse: 1.2406 - val_loss: 1.2404 - val_mse: 1.2404\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 1.2403 - mse: 1.2403 - val_loss: 1.2402 - val_mse: 1.2402\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 393ms/step - loss: 1.2401 - mse: 1.2401 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 1.2399 - mse: 1.2399 - val_loss: 1.2397 - val_mse: 1.2397\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 394ms/step - loss: 1.2397 - mse: 1.2397 - val_loss: 1.2395 - val_mse: 1.2395\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 373ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 1.2393 - val_mse: 1.2393\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 387ms/step - loss: 1.2393 - mse: 1.2393 - val_loss: 1.2391 - val_mse: 1.2391\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 1.2390 - mse: 1.2390 - val_loss: 1.2389 - val_mse: 1.2389\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 1.2388 - mse: 1.2388 - val_loss: 1.2387 - val_mse: 1.2387\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 383ms/step - loss: 1.2386 - mse: 1.2386 - val_loss: 1.2384 - val_mse: 1.2384\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 384ms/step - loss: 1.2384 - mse: 1.2384 - val_loss: 1.2382 - val_mse: 1.2382\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 384ms/step - loss: 1.2382 - mse: 1.2382 - val_loss: 1.2380 - val_mse: 1.2380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 102/200 [42:56<1:12:59, 44.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 600ms/step - loss: 1.2417 - mse: 1.2417 - val_loss: 1.1807 - val_mse: 1.1807\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 1.1809 - mse: 1.1809 - val_loss: 1.0971 - val_mse: 1.0971\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 1.1069 - mse: 1.1069 - val_loss: 1.0019 - val_mse: 1.0019\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 1.0262 - mse: 1.0262 - val_loss: 0.9293 - val_mse: 0.9293\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 0.9675 - mse: 0.9675 - val_loss: 0.8955 - val_mse: 0.8955\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 1s 368ms/step - loss: 0.9419 - mse: 0.9419 - val_loss: 0.8848 - val_mse: 0.8848\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 0.9344 - mse: 0.9344 - val_loss: 0.8815 - val_mse: 0.8815\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 1s 378ms/step - loss: 0.9323 - mse: 0.9323 - val_loss: 0.8800 - val_mse: 0.8800\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 0.9312 - mse: 0.9312 - val_loss: 0.8786 - val_mse: 0.8786\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 0.9301 - mse: 0.9301 - val_loss: 0.8772 - val_mse: 0.8772\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9288 - mse: 0.9288 - val_loss: 0.8756 - val_mse: 0.8756\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 0.9273 - mse: 0.9273 - val_loss: 0.8740 - val_mse: 0.8740\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 0.9257 - mse: 0.9257 - val_loss: 0.8724 - val_mse: 0.8724\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 0.9240 - mse: 0.9240 - val_loss: 0.8709 - val_mse: 0.8709\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 1s 379ms/step - loss: 0.9223 - mse: 0.9223 - val_loss: 0.8698 - val_mse: 0.8698\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 1s 368ms/step - loss: 0.9209 - mse: 0.9209 - val_loss: 0.8690 - val_mse: 0.8690\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 0.9197 - mse: 0.9197 - val_loss: 0.8686 - val_mse: 0.8686\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 0.9187 - mse: 0.9187 - val_loss: 0.8682 - val_mse: 0.8682\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.9177 - mse: 0.9177 - val_loss: 0.8677 - val_mse: 0.8677\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.8669 - val_mse: 0.8669\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 1s 378ms/step - loss: 0.9157 - mse: 0.9157 - val_loss: 0.8660 - val_mse: 0.8660\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.9144 - mse: 0.9144 - val_loss: 0.8650 - val_mse: 0.8650\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 0.9130 - mse: 0.9130 - val_loss: 0.8644 - val_mse: 0.8644\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.8645 - val_mse: 0.8645\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 0.9113 - mse: 0.9113 - val_loss: 0.8646 - val_mse: 0.8646\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.9100 - mse: 0.9100 - val_loss: 0.8636 - val_mse: 0.8636\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 0.9083 - mse: 0.9083 - val_loss: 0.8621 - val_mse: 0.8621\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 0.9064 - mse: 0.9064 - val_loss: 0.8605 - val_mse: 0.8605\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 0.9044 - mse: 0.9044 - val_loss: 0.8591 - val_mse: 0.8591\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9025 - mse: 0.9025 - val_loss: 0.8579 - val_mse: 0.8579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 103/200 [43:23<1:03:50, 39.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 405ms/step - loss: 1.2495 - mse: 1.2495 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2491 - val_mse: 1.2491\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2489 - val_mse: 1.2489\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.2490 - mse: 1.2490 - val_loss: 1.2487 - val_mse: 1.2487\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 1.2488 - mse: 1.2488 - val_loss: 1.2485 - val_mse: 1.2485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 104/200 [43:29<47:12, 29.51s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 591ms/step - loss: 1.2689 - mse: 1.2689 - val_loss: 0.9167 - val_mse: 0.9167\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.9604 - mse: 0.9604 - val_loss: 0.8945 - val_mse: 0.8945\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8912 - val_mse: 0.8912\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9434 - mse: 0.9434 - val_loss: 0.8885 - val_mse: 0.8885\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.9411 - mse: 0.9411 - val_loss: 0.8857 - val_mse: 0.8857\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.9386 - mse: 0.9386 - val_loss: 0.8830 - val_mse: 0.8830\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.9359 - mse: 0.9359 - val_loss: 0.8804 - val_mse: 0.8804\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8784 - val_mse: 0.8784\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.9318 - mse: 0.9318 - val_loss: 0.8769 - val_mse: 0.8769\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9303 - mse: 0.9303 - val_loss: 0.8753 - val_mse: 0.8753\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9288 - mse: 0.9288 - val_loss: 0.8734 - val_mse: 0.8734\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9272 - mse: 0.9272 - val_loss: 0.8717 - val_mse: 0.8717\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 0.9258 - mse: 0.9258 - val_loss: 0.8703 - val_mse: 0.8703\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 0.9244 - mse: 0.9244 - val_loss: 0.8687 - val_mse: 0.8687\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.9226 - mse: 0.9226 - val_loss: 0.8662 - val_mse: 0.8662\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.8620 - val_mse: 0.8620\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 0.9145 - mse: 0.9145 - val_loss: 0.8545 - val_mse: 0.8545\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 0.9044 - mse: 0.9044 - val_loss: 0.8374 - val_mse: 0.8374\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.8812 - mse: 0.8812 - val_loss: 0.8230 - val_mse: 0.8230\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.8616 - mse: 0.8616 - val_loss: 0.8350 - val_mse: 0.8350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▎    | 105/200 [43:51<42:57, 27.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 372ms/step - loss: 1.0431 - mse: 1.0431 - val_loss: 1.0092 - val_mse: 1.0092\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0423 - mse: 1.0423 - val_loss: 1.0082 - val_mse: 1.0082\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0414 - mse: 1.0414 - val_loss: 1.0072 - val_mse: 1.0072\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0406 - mse: 1.0406 - val_loss: 1.0063 - val_mse: 1.0063\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0398 - mse: 1.0398 - val_loss: 1.0053 - val_mse: 1.0053\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0389 - mse: 1.0389 - val_loss: 1.0044 - val_mse: 1.0044\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.0381 - mse: 1.0381 - val_loss: 1.0034 - val_mse: 1.0034\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.0373 - mse: 1.0373 - val_loss: 1.0025 - val_mse: 1.0025\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0365 - mse: 1.0365 - val_loss: 1.0016 - val_mse: 1.0016\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0357 - mse: 1.0357 - val_loss: 1.0007 - val_mse: 1.0007\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 1.0350 - mse: 1.0350 - val_loss: 0.9998 - val_mse: 0.9998\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0342 - mse: 1.0342 - val_loss: 0.9990 - val_mse: 0.9990\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0334 - mse: 1.0334 - val_loss: 0.9981 - val_mse: 0.9981\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0327 - mse: 1.0327 - val_loss: 0.9972 - val_mse: 0.9972\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 1.0319 - mse: 1.0319 - val_loss: 0.9964 - val_mse: 0.9964\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.0312 - mse: 1.0312 - val_loss: 0.9956 - val_mse: 0.9956\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0305 - mse: 1.0305 - val_loss: 0.9947 - val_mse: 0.9947\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0298 - mse: 1.0298 - val_loss: 0.9939 - val_mse: 0.9939\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0291 - mse: 1.0291 - val_loss: 0.9931 - val_mse: 0.9931\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0284 - mse: 1.0284 - val_loss: 0.9923 - val_mse: 0.9923\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0277 - mse: 1.0277 - val_loss: 0.9915 - val_mse: 0.9915\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0270 - mse: 1.0270 - val_loss: 0.9908 - val_mse: 0.9908\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.0263 - mse: 1.0263 - val_loss: 0.9900 - val_mse: 0.9900\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.0257 - mse: 1.0257 - val_loss: 0.9892 - val_mse: 0.9892\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.0250 - mse: 1.0250 - val_loss: 0.9885 - val_mse: 0.9885\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0244 - mse: 1.0244 - val_loss: 0.9877 - val_mse: 0.9877\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0237 - mse: 1.0237 - val_loss: 0.9870 - val_mse: 0.9870\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.0231 - mse: 1.0231 - val_loss: 0.9863 - val_mse: 0.9863\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.0225 - mse: 1.0225 - val_loss: 0.9856 - val_mse: 0.9856\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.0218 - mse: 1.0218 - val_loss: 0.9849 - val_mse: 0.9849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 106/200 [44:17<41:52, 26.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 233ms/step - loss: 1.2776 - mse: 1.2776 - val_loss: 1.2802 - val_mse: 1.2802\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 1.2726 - mse: 1.2726 - val_loss: 1.2745 - val_mse: 1.2745\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 1.2679 - mse: 1.2679 - val_loss: 1.2689 - val_mse: 1.2689\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.2632 - mse: 1.2632 - val_loss: 1.2636 - val_mse: 1.2636\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.2588 - mse: 1.2588 - val_loss: 1.2584 - val_mse: 1.2584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 107/200 [44:23<31:52, 20.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 582ms/step - loss: 1.0265 - mse: 1.0265 - val_loss: 0.9899 - val_mse: 0.9899\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 1.0259 - mse: 1.0259 - val_loss: 0.9893 - val_mse: 0.9893\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 379ms/step - loss: 1.0254 - mse: 1.0254 - val_loss: 0.9887 - val_mse: 0.9887\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 1.0248 - mse: 1.0248 - val_loss: 0.9881 - val_mse: 0.9881\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 1.0242 - mse: 1.0242 - val_loss: 0.9875 - val_mse: 0.9875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 108/200 [44:29<24:41, 16.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 409ms/step - loss: 1.4331 - mse: 1.4331 - val_loss: 1.4328 - val_mse: 1.4328\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.4326 - mse: 1.4326 - val_loss: 1.4323 - val_mse: 1.4323\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.4322 - mse: 1.4322 - val_loss: 1.4319 - val_mse: 1.4319\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.4317 - mse: 1.4317 - val_loss: 1.4314 - val_mse: 1.4314\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.4313 - mse: 1.4313 - val_loss: 1.4310 - val_mse: 1.4310\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.4308 - mse: 1.4308 - val_loss: 1.4305 - val_mse: 1.4305\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.4304 - mse: 1.4304 - val_loss: 1.4301 - val_mse: 1.4301\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.4299 - mse: 1.4299 - val_loss: 1.4296 - val_mse: 1.4296\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.4295 - mse: 1.4295 - val_loss: 1.4292 - val_mse: 1.4292\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 1.4290 - mse: 1.4290 - val_loss: 1.4287 - val_mse: 1.4287\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.4286 - mse: 1.4286 - val_loss: 1.4282 - val_mse: 1.4282\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 1.4281 - mse: 1.4281 - val_loss: 1.4278 - val_mse: 1.4278\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.4276 - mse: 1.4276 - val_loss: 1.4273 - val_mse: 1.4273\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.4272 - mse: 1.4272 - val_loss: 1.4269 - val_mse: 1.4269\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.4267 - mse: 1.4267 - val_loss: 1.4264 - val_mse: 1.4264\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 1.4263 - mse: 1.4263 - val_loss: 1.4260 - val_mse: 1.4260\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 1.4258 - mse: 1.4258 - val_loss: 1.4255 - val_mse: 1.4255\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 293ms/step - loss: 1.4254 - mse: 1.4254 - val_loss: 1.4251 - val_mse: 1.4251\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 1.4249 - mse: 1.4249 - val_loss: 1.4246 - val_mse: 1.4246\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 291ms/step - loss: 1.4245 - mse: 1.4245 - val_loss: 1.4242 - val_mse: 1.4242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 109/200 [44:47<25:24, 16.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 569ms/step - loss: 1.2239 - mse: 1.2239 - val_loss: 1.2270 - val_mse: 1.2270\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 339ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 1.2242 - val_mse: 1.2242\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 1.2185 - mse: 1.2185 - val_loss: 1.2213 - val_mse: 1.2213\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.2158 - mse: 1.2158 - val_loss: 1.2184 - val_mse: 1.2184\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 333ms/step - loss: 1.2131 - mse: 1.2131 - val_loss: 1.2155 - val_mse: 1.2155\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.2104 - mse: 1.2104 - val_loss: 1.2126 - val_mse: 1.2126\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.2077 - mse: 1.2077 - val_loss: 1.2098 - val_mse: 1.2098\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 1.2050 - mse: 1.2050 - val_loss: 1.2069 - val_mse: 1.2069\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 1.2023 - mse: 1.2023 - val_loss: 1.2041 - val_mse: 1.2041\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 330ms/step - loss: 1.1996 - mse: 1.1996 - val_loss: 1.2012 - val_mse: 1.2012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 110/200 [44:58<22:41, 15.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 580ms/step - loss: 1.2540 - mse: 1.2540 - val_loss: 1.2539 - val_mse: 1.2539\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 1.2538 - mse: 1.2538 - val_loss: 1.2536 - val_mse: 1.2536\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 362ms/step - loss: 1.2536 - mse: 1.2536 - val_loss: 1.2534 - val_mse: 1.2534\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.2534 - mse: 1.2534 - val_loss: 1.2532 - val_mse: 1.2532\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 1.2532 - mse: 1.2532 - val_loss: 1.2530 - val_mse: 1.2530\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.2530 - mse: 1.2530 - val_loss: 1.2528 - val_mse: 1.2528\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 1.2527 - mse: 1.2527 - val_loss: 1.2526 - val_mse: 1.2526\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 1.2525 - mse: 1.2525 - val_loss: 1.2523 - val_mse: 1.2523\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 361ms/step - loss: 1.2523 - mse: 1.2523 - val_loss: 1.2521 - val_mse: 1.2521\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.2521 - mse: 1.2521 - val_loss: 1.2519 - val_mse: 1.2519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 111/200 [45:08<20:05, 13.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 541ms/step - loss: 1.3807 - mse: 1.3807 - val_loss: 1.3888 - val_mse: 1.3888\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.3676 - mse: 1.3676 - val_loss: 1.3737 - val_mse: 1.3737\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 1.3546 - mse: 1.3546 - val_loss: 1.3587 - val_mse: 1.3587\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.3417 - mse: 1.3417 - val_loss: 1.3439 - val_mse: 1.3439\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.3290 - mse: 1.3290 - val_loss: 1.3292 - val_mse: 1.3292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 112/200 [45:14<16:38, 11.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 413ms/step - loss: 1.2355 - mse: 1.2355 - val_loss: 1.2338 - val_mse: 1.2338\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.2352 - mse: 1.2352 - val_loss: 1.2335 - val_mse: 1.2335\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 1.2350 - mse: 1.2350 - val_loss: 1.2332 - val_mse: 1.2332\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.2348 - mse: 1.2348 - val_loss: 1.2329 - val_mse: 1.2329\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 1.2345 - mse: 1.2345 - val_loss: 1.2326 - val_mse: 1.2326\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2343 - mse: 1.2343 - val_loss: 1.2323 - val_mse: 1.2323\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.2341 - mse: 1.2341 - val_loss: 1.2321 - val_mse: 1.2321\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.2338 - mse: 1.2338 - val_loss: 1.2318 - val_mse: 1.2318\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 299ms/step - loss: 1.2336 - mse: 1.2336 - val_loss: 1.2315 - val_mse: 1.2315\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2333 - mse: 1.2333 - val_loss: 1.2312 - val_mse: 1.2312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 113/200 [45:24<15:49, 10.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 2s 127ms/step - loss: 1.0472 - mse: 1.0472 - val_loss: 1.0048 - val_mse: 1.0048\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0017 - mse: 1.0017 - val_loss: 1.0000 - val_mse: 1.0000\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9995 - val_mse: 0.9995\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9993 - val_mse: 0.9993\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9992 - mse: 0.9992 - val_loss: 0.9992 - val_mse: 0.9992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 114/200 [45:36<15:49, 11.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 342ms/step - loss: 1.2399 - mse: 1.2399 - val_loss: 1.2374 - val_mse: 1.2374\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.2396 - mse: 1.2396 - val_loss: 1.2371 - val_mse: 1.2371\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.2394 - mse: 1.2394 - val_loss: 1.2368 - val_mse: 1.2368\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.2392 - mse: 1.2392 - val_loss: 1.2365 - val_mse: 1.2365\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.2389 - mse: 1.2389 - val_loss: 1.2362 - val_mse: 1.2362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▊    | 115/200 [45:42<13:35,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 235ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2493 - val_mse: 1.2493\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 183ms/step - loss: 1.2492 - mse: 1.2492 - val_loss: 1.2492 - val_mse: 1.2492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 116/200 [46:01<17:37, 12.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 379ms/step - loss: 1.0924 - mse: 1.0924 - val_loss: 1.0796 - val_mse: 1.0796\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.0740 - mse: 1.0740 - val_loss: 1.0634 - val_mse: 1.0634\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.0589 - mse: 1.0589 - val_loss: 1.0504 - val_mse: 1.0504\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.0468 - mse: 1.0468 - val_loss: 1.0400 - val_mse: 1.0400\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.0372 - mse: 1.0372 - val_loss: 1.0319 - val_mse: 1.0319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 117/200 [46:07<14:20, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 128ms/step - loss: 1.2518 - mse: 1.2518 - val_loss: 1.2517 - val_mse: 1.2517\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2510 - mse: 1.2510 - val_loss: 1.2507 - val_mse: 1.2507\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2501 - mse: 1.2501 - val_loss: 1.2497 - val_mse: 1.2497\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2487 - val_mse: 1.2487\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2484 - mse: 1.2484 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2467 - val_mse: 1.2467\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2468 - mse: 1.2468 - val_loss: 1.2457 - val_mse: 1.2457\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2447 - val_mse: 1.2447\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2451 - mse: 1.2451 - val_loss: 1.2437 - val_mse: 1.2437\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2443 - mse: 1.2443 - val_loss: 1.2427 - val_mse: 1.2427\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2435 - mse: 1.2435 - val_loss: 1.2417 - val_mse: 1.2417\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.2407 - val_mse: 1.2407\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2419 - mse: 1.2419 - val_loss: 1.2397 - val_mse: 1.2397\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2411 - mse: 1.2411 - val_loss: 1.2387 - val_mse: 1.2387\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2402 - mse: 1.2402 - val_loss: 1.2378 - val_mse: 1.2378\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2394 - mse: 1.2394 - val_loss: 1.2368 - val_mse: 1.2368\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2386 - mse: 1.2386 - val_loss: 1.2358 - val_mse: 1.2358\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2378 - mse: 1.2378 - val_loss: 1.2348 - val_mse: 1.2348\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2370 - mse: 1.2370 - val_loss: 1.2338 - val_mse: 1.2338\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2362 - mse: 1.2362 - val_loss: 1.2328 - val_mse: 1.2328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 118/200 [46:28<18:46, 13.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2478 - val_mse: 1.2478\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2478 - mse: 1.2478 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2477 - val_mse: 1.2477\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2477 - mse: 1.2477 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2476 - val_mse: 1.2476\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2476 - mse: 1.2476 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2475 - val_mse: 1.2475\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2475 - mse: 1.2475 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2473 - val_mse: 1.2473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 119/200 [47:51<46:37, 34.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 346ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.2381 - mse: 1.2381 - val_loss: 1.2280 - val_mse: 1.2280\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.2248 - mse: 1.2248 - val_loss: 1.2072 - val_mse: 1.2072\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.2032 - mse: 1.2032 - val_loss: 1.1745 - val_mse: 1.1745\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.1697 - mse: 1.1697 - val_loss: 1.1256 - val_mse: 1.1256\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.1214 - mse: 1.1214 - val_loss: 1.0587 - val_mse: 1.0587\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.0575 - mse: 1.0575 - val_loss: 0.9826 - val_mse: 0.9826\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9871 - mse: 0.9871 - val_loss: 0.9132 - val_mse: 0.9132\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9306 - mse: 0.9306 - val_loss: 0.8772 - val_mse: 0.8772\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8973 - mse: 0.8973 - val_loss: 0.8493 - val_mse: 0.8493\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8765 - mse: 0.8765 - val_loss: 0.8326 - val_mse: 0.8326\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8583 - mse: 0.8583 - val_loss: 0.8159 - val_mse: 0.8159\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.8424 - mse: 0.8424 - val_loss: 0.7966 - val_mse: 0.7966\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8326 - mse: 0.8326 - val_loss: 0.8008 - val_mse: 0.8008\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8255 - mse: 0.8255 - val_loss: 0.7827 - val_mse: 0.7827\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.8151 - mse: 0.8151 - val_loss: 0.7743 - val_mse: 0.7743\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.8092 - mse: 0.8092 - val_loss: 0.7823 - val_mse: 0.7823\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.8056 - mse: 0.8056 - val_loss: 0.7670 - val_mse: 0.7670\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.7991 - mse: 0.7991 - val_loss: 0.7629 - val_mse: 0.7629\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.7958 - mse: 0.7958 - val_loss: 0.7634 - val_mse: 0.7634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 120/200 [48:13<40:51, 30.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 0.8588 - val_mse: 0.8588\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.8747 - mse: 0.8747 - val_loss: 0.8240 - val_mse: 0.8240\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.8417 - mse: 0.8417 - val_loss: 0.8071 - val_mse: 0.8071\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.8221 - mse: 0.8221 - val_loss: 0.7804 - val_mse: 0.7804\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.8054 - mse: 0.8054 - val_loss: 0.7635 - val_mse: 0.7635\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.7938 - mse: 0.7938 - val_loss: 0.7527 - val_mse: 0.7527\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.7855 - mse: 0.7855 - val_loss: 0.7423 - val_mse: 0.7423\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7777 - mse: 0.7777 - val_loss: 0.7358 - val_mse: 0.7358\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7754 - mse: 0.7754 - val_loss: 0.7341 - val_mse: 0.7341\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7733 - mse: 0.7733 - val_loss: 0.7431 - val_mse: 0.7431\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7721 - mse: 0.7721 - val_loss: 0.7404 - val_mse: 0.7404\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7708 - mse: 0.7708 - val_loss: 0.7318 - val_mse: 0.7318\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7669 - mse: 0.7669 - val_loss: 0.7263 - val_mse: 0.7263\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.7652 - mse: 0.7652 - val_loss: 0.7249 - val_mse: 0.7249\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7667 - mse: 0.7667 - val_loss: 0.7259 - val_mse: 0.7259\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.7652 - mse: 0.7652 - val_loss: 0.7276 - val_mse: 0.7276\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7642 - mse: 0.7642 - val_loss: 0.7269 - val_mse: 0.7269\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7632 - mse: 0.7632 - val_loss: 0.7310 - val_mse: 0.7310\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7625 - mse: 0.7625 - val_loss: 0.7277 - val_mse: 0.7277\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.7617 - mse: 0.7617 - val_loss: 0.7216 - val_mse: 0.7216\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7613 - mse: 0.7613 - val_loss: 0.7229 - val_mse: 0.7229\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.7603 - mse: 0.7603 - val_loss: 0.7216 - val_mse: 0.7216\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.7594 - mse: 0.7594 - val_loss: 0.7206 - val_mse: 0.7206\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7594 - mse: 0.7594 - val_loss: 0.7204 - val_mse: 0.7204\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.7589 - mse: 0.7589 - val_loss: 0.7234 - val_mse: 0.7234\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7588 - mse: 0.7588 - val_loss: 0.7218 - val_mse: 0.7218\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 0.7181 - val_mse: 0.7181\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7579 - mse: 0.7579 - val_loss: 0.7205 - val_mse: 0.7205\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.7573 - mse: 0.7573 - val_loss: 0.7201 - val_mse: 0.7201\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7571 - mse: 0.7571 - val_loss: 0.7166 - val_mse: 0.7166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 121/200 [48:43<40:14, 30.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "9/9 [==============================] - 2s 129ms/step - loss: 1.0840 - mse: 1.0840 - val_loss: 0.9397 - val_mse: 0.9397\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9681 - mse: 0.9681 - val_loss: 0.9091 - val_mse: 0.9091\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9526 - mse: 0.9526 - val_loss: 0.8996 - val_mse: 0.8996\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9461 - mse: 0.9461 - val_loss: 0.8939 - val_mse: 0.8939\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9418 - mse: 0.9418 - val_loss: 0.8902 - val_mse: 0.8902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 122/200 [48:49<30:14, 23.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 543ms/step - loss: 1.2136 - mse: 1.2136 - val_loss: 1.1999 - val_mse: 1.1999\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 1.2125 - mse: 1.2125 - val_loss: 1.1986 - val_mse: 1.1986\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 340ms/step - loss: 1.2115 - mse: 1.2115 - val_loss: 1.1974 - val_mse: 1.1974\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 1.2104 - mse: 1.2104 - val_loss: 1.1962 - val_mse: 1.1962\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.2093 - mse: 1.2093 - val_loss: 1.1949 - val_mse: 1.1949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 123/200 [48:55<22:53, 17.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 2s 127ms/step - loss: 1.0675 - mse: 1.0675 - val_loss: 1.0438 - val_mse: 1.0438\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0326 - mse: 1.0326 - val_loss: 1.0215 - val_mse: 1.0215\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0166 - mse: 1.0166 - val_loss: 1.0117 - val_mse: 1.0117\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0094 - mse: 1.0094 - val_loss: 1.0071 - val_mse: 1.0071\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 1.0048 - val_mse: 1.0048\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0042 - mse: 1.0042 - val_loss: 1.0035 - val_mse: 1.0035\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0031 - mse: 1.0031 - val_loss: 1.0027 - val_mse: 1.0027\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 1.0021 - val_mse: 1.0021\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0019 - mse: 1.0019 - val_loss: 1.0017 - val_mse: 1.0017\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0015 - mse: 1.0015 - val_loss: 1.0014 - val_mse: 1.0014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 124/200 [49:06<20:07, 15.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 2s 138ms/step - loss: 1.2482 - mse: 1.2482 - val_loss: 1.2444 - val_mse: 1.2444\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2412 - mse: 1.2412 - val_loss: 1.2359 - val_mse: 1.2359\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2341 - mse: 1.2341 - val_loss: 1.2274 - val_mse: 1.2274\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2270 - mse: 1.2270 - val_loss: 1.2187 - val_mse: 1.2187\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2197 - mse: 1.2197 - val_loss: 1.2097 - val_mse: 1.2097\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2121 - mse: 1.2121 - val_loss: 1.2004 - val_mse: 1.2004\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.2041 - mse: 1.2041 - val_loss: 1.1906 - val_mse: 1.1906\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.1957 - mse: 1.1957 - val_loss: 1.1802 - val_mse: 1.1802\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1867 - mse: 1.1867 - val_loss: 1.1691 - val_mse: 1.1691\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1771 - mse: 1.1771 - val_loss: 1.1574 - val_mse: 1.1574\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.1670 - mse: 1.1670 - val_loss: 1.1451 - val_mse: 1.1451\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.1563 - mse: 1.1563 - val_loss: 1.1322 - val_mse: 1.1322\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.1451 - mse: 1.1451 - val_loss: 1.1188 - val_mse: 1.1188\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.1335 - mse: 1.1335 - val_loss: 1.1049 - val_mse: 1.1049\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1215 - mse: 1.1215 - val_loss: 1.0906 - val_mse: 1.0906\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.1091 - mse: 1.1091 - val_loss: 1.0762 - val_mse: 1.0762\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0967 - mse: 1.0967 - val_loss: 1.0618 - val_mse: 1.0618\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.0842 - mse: 1.0842 - val_loss: 1.0475 - val_mse: 1.0475\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0720 - mse: 1.0720 - val_loss: 1.0337 - val_mse: 1.0337\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 1.0602 - mse: 1.0602 - val_loss: 1.0203 - val_mse: 1.0203\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0487 - mse: 1.0487 - val_loss: 1.0076 - val_mse: 1.0076\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0380 - mse: 1.0380 - val_loss: 0.9957 - val_mse: 0.9957\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0279 - mse: 1.0279 - val_loss: 0.9847 - val_mse: 0.9847\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.0186 - mse: 1.0186 - val_loss: 0.9746 - val_mse: 0.9746\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.0101 - mse: 1.0101 - val_loss: 0.9654 - val_mse: 0.9654\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 0.9571 - val_mse: 0.9571\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9954 - mse: 0.9954 - val_loss: 0.9497 - val_mse: 0.9497\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9892 - mse: 0.9892 - val_loss: 0.9430 - val_mse: 0.9430\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9836 - mse: 0.9836 - val_loss: 0.9371 - val_mse: 0.9371\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 0.9319 - val_mse: 0.9319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 125/200 [49:48<29:40, 23.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 135ms/step - loss: 1.2543 - mse: 1.2543 - val_loss: 1.2500 - val_mse: 1.2500\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.2460 - mse: 1.2460 - val_loss: 1.2400 - val_mse: 1.2400\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2379 - mse: 1.2379 - val_loss: 1.2303 - val_mse: 1.2303\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.2300 - mse: 1.2300 - val_loss: 1.2207 - val_mse: 1.2207\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2222 - mse: 1.2222 - val_loss: 1.2110 - val_mse: 1.2110\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2141 - mse: 1.2141 - val_loss: 1.2012 - val_mse: 1.2012\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.2059 - mse: 1.2059 - val_loss: 1.1908 - val_mse: 1.1908\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1972 - mse: 1.1972 - val_loss: 1.1801 - val_mse: 1.1801\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1881 - mse: 1.1881 - val_loss: 1.1688 - val_mse: 1.1688\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1784 - mse: 1.1784 - val_loss: 1.1568 - val_mse: 1.1568\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1681 - mse: 1.1681 - val_loss: 1.1442 - val_mse: 1.1442\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1572 - mse: 1.1572 - val_loss: 1.1310 - val_mse: 1.1310\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.1458 - mse: 1.1458 - val_loss: 1.1172 - val_mse: 1.1172\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 1.1338 - mse: 1.1338 - val_loss: 1.1030 - val_mse: 1.1030\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.1215 - mse: 1.1215 - val_loss: 1.0885 - val_mse: 1.0885\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.1090 - mse: 1.1090 - val_loss: 1.0739 - val_mse: 1.0739\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.0963 - mse: 1.0963 - val_loss: 1.0594 - val_mse: 1.0594\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 1.0839 - mse: 1.0839 - val_loss: 1.0452 - val_mse: 1.0452\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 1.0717 - mse: 1.0717 - val_loss: 1.0315 - val_mse: 1.0315\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 1.0600 - mse: 1.0600 - val_loss: 1.0185 - val_mse: 1.0185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 126/200 [50:10<28:28, 23.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 369ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2547 - val_mse: 1.2547\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2547 - mse: 1.2547 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2546 - mse: 1.2546 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2545 - val_mse: 1.2545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 127/200 [51:33<49:58, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 2s 220ms/step - loss: 1.3614 - mse: 1.3614 - val_loss: 1.3566 - val_mse: 1.3566\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.3541 - mse: 1.3541 - val_loss: 1.3493 - val_mse: 1.3493\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.3468 - mse: 1.3468 - val_loss: 1.3420 - val_mse: 1.3420\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.3395 - mse: 1.3395 - val_loss: 1.3348 - val_mse: 1.3348\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.3323 - mse: 1.3323 - val_loss: 1.3277 - val_mse: 1.3277\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.3252 - mse: 1.3252 - val_loss: 1.3206 - val_mse: 1.3206\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.3182 - mse: 1.3182 - val_loss: 1.3136 - val_mse: 1.3136\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.3112 - mse: 1.3112 - val_loss: 1.3067 - val_mse: 1.3067\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.3043 - mse: 1.3043 - val_loss: 1.2998 - val_mse: 1.2998\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2975 - mse: 1.2975 - val_loss: 1.2931 - val_mse: 1.2931\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2908 - mse: 1.2908 - val_loss: 1.2864 - val_mse: 1.2864\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2841 - mse: 1.2841 - val_loss: 1.2798 - val_mse: 1.2798\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2776 - mse: 1.2776 - val_loss: 1.2734 - val_mse: 1.2734\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.2712 - mse: 1.2712 - val_loss: 1.2670 - val_mse: 1.2670\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2648 - mse: 1.2648 - val_loss: 1.2607 - val_mse: 1.2607\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2586 - mse: 1.2586 - val_loss: 1.2546 - val_mse: 1.2546\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2525 - mse: 1.2525 - val_loss: 1.2485 - val_mse: 1.2485\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.2464 - mse: 1.2464 - val_loss: 1.2426 - val_mse: 1.2426\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2405 - mse: 1.2405 - val_loss: 1.2367 - val_mse: 1.2367\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.2347 - mse: 1.2347 - val_loss: 1.2310 - val_mse: 1.2310\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2291 - mse: 1.2291 - val_loss: 1.2254 - val_mse: 1.2254\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2235 - mse: 1.2235 - val_loss: 1.2199 - val_mse: 1.2199\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.2180 - mse: 1.2180 - val_loss: 1.2145 - val_mse: 1.2145\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.2127 - mse: 1.2127 - val_loss: 1.2093 - val_mse: 1.2093\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.2075 - mse: 1.2075 - val_loss: 1.2041 - val_mse: 1.2041\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2024 - mse: 1.2024 - val_loss: 1.1991 - val_mse: 1.1991\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.1974 - mse: 1.1974 - val_loss: 1.1942 - val_mse: 1.1942\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.1925 - mse: 1.1925 - val_loss: 1.1894 - val_mse: 1.1894\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.1877 - mse: 1.1877 - val_loss: 1.1847 - val_mse: 1.1847\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.1831 - mse: 1.1831 - val_loss: 1.1801 - val_mse: 1.1801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 128/200 [51:59<43:51, 36.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 130ms/step - loss: 1.2451 - mse: 1.2451 - val_loss: 1.2407 - val_mse: 1.2407\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2367 - mse: 1.2367 - val_loss: 1.2297 - val_mse: 1.2297\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2238 - mse: 1.2238 - val_loss: 1.2126 - val_mse: 1.2126\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2037 - mse: 1.2037 - val_loss: 1.1850 - val_mse: 1.1850\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1720 - mse: 1.1720 - val_loss: 1.1414 - val_mse: 1.1414\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1249 - mse: 1.1249 - val_loss: 1.0808 - val_mse: 1.0808\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0638 - mse: 1.0638 - val_loss: 1.0090 - val_mse: 1.0090\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9429 - val_mse: 0.9429\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9473 - mse: 0.9473 - val_loss: 0.8979 - val_mse: 0.8979\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9137 - mse: 0.9137 - val_loss: 0.8701 - val_mse: 0.8701\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8919 - mse: 0.8919 - val_loss: 0.8506 - val_mse: 0.8506\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8750 - mse: 0.8750 - val_loss: 0.8340 - val_mse: 0.8340\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8612 - mse: 0.8612 - val_loss: 0.8195 - val_mse: 0.8195\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8501 - mse: 0.8501 - val_loss: 0.8109 - val_mse: 0.8109\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8410 - mse: 0.8410 - val_loss: 0.8033 - val_mse: 0.8033\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8337 - mse: 0.8337 - val_loss: 0.7949 - val_mse: 0.7949\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8274 - mse: 0.8274 - val_loss: 0.7886 - val_mse: 0.7886\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8220 - mse: 0.8220 - val_loss: 0.7872 - val_mse: 0.7872\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8175 - mse: 0.8175 - val_loss: 0.7797 - val_mse: 0.7797\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8136 - mse: 0.8136 - val_loss: 0.7768 - val_mse: 0.7768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 129/200 [52:20<37:55, 32.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 351ms/step - loss: 1.1559 - mse: 1.1559 - val_loss: 0.9392 - val_mse: 0.9392\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.9783 - mse: 0.9783 - val_loss: 0.9125 - val_mse: 0.9125\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9590 - mse: 0.9590 - val_loss: 0.8999 - val_mse: 0.8999\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.9487 - mse: 0.9487 - val_loss: 0.8933 - val_mse: 0.8933\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9430 - mse: 0.9430 - val_loss: 0.8902 - val_mse: 0.8902\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.9398 - mse: 0.9398 - val_loss: 0.8886 - val_mse: 0.8886\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.9366 - mse: 0.9366 - val_loss: 0.8866 - val_mse: 0.8866\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9290 - mse: 0.9290 - val_loss: 0.8881 - val_mse: 0.8881\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.9186 - mse: 0.9186 - val_loss: 0.8703 - val_mse: 0.8703\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.9050 - mse: 0.9050 - val_loss: 0.8621 - val_mse: 0.8621\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.8970 - mse: 0.8970 - val_loss: 0.8624 - val_mse: 0.8624\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.8902 - mse: 0.8902 - val_loss: 0.8544 - val_mse: 0.8544\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8809 - mse: 0.8809 - val_loss: 0.8435 - val_mse: 0.8435\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.8677 - mse: 0.8677 - val_loss: 0.8263 - val_mse: 0.8263\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.8510 - mse: 0.8510 - val_loss: 0.8122 - val_mse: 0.8122\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8373 - mse: 0.8373 - val_loss: 0.8014 - val_mse: 0.8014\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8290 - mse: 0.8290 - val_loss: 0.7990 - val_mse: 0.7990\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.8230 - mse: 0.8230 - val_loss: 0.7941 - val_mse: 0.7941\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.8190 - mse: 0.8190 - val_loss: 0.7943 - val_mse: 0.7943\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.8162 - mse: 0.8162 - val_loss: 0.7927 - val_mse: 0.7927\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8139 - mse: 0.8139 - val_loss: 0.7884 - val_mse: 0.7884\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.8119 - mse: 0.8119 - val_loss: 0.7937 - val_mse: 0.7937\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8120 - mse: 0.8120 - val_loss: 0.7853 - val_mse: 0.7853\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8092 - mse: 0.8092 - val_loss: 0.7836 - val_mse: 0.7836\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.8076 - mse: 0.8076 - val_loss: 0.7858 - val_mse: 0.7858\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8072 - mse: 0.8072 - val_loss: 0.7793 - val_mse: 0.7793\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8070 - mse: 0.8070 - val_loss: 0.7837 - val_mse: 0.7837\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.8046 - mse: 0.8046 - val_loss: 0.7759 - val_mse: 0.7759\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8044 - mse: 0.8044 - val_loss: 0.7820 - val_mse: 0.7820\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8032 - mse: 0.8032 - val_loss: 0.7730 - val_mse: 0.7730\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8024 - mse: 0.8024 - val_loss: 0.7750 - val_mse: 0.7750\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8004 - mse: 0.8004 - val_loss: 0.7720 - val_mse: 0.7720\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.7999 - mse: 0.7999 - val_loss: 0.7726 - val_mse: 0.7726\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.7988 - mse: 0.7988 - val_loss: 0.7705 - val_mse: 0.7705\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.7980 - mse: 0.7980 - val_loss: 0.7681 - val_mse: 0.7681\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.7977 - mse: 0.7977 - val_loss: 0.7702 - val_mse: 0.7702\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.7968 - mse: 0.7968 - val_loss: 0.7667 - val_mse: 0.7667\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.7959 - mse: 0.7959 - val_loss: 0.7641 - val_mse: 0.7641\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.7955 - mse: 0.7955 - val_loss: 0.7703 - val_mse: 0.7703\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.7948 - mse: 0.7948 - val_loss: 0.7627 - val_mse: 0.7627\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.7947 - mse: 0.7947 - val_loss: 0.7613 - val_mse: 0.7613\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.7932 - mse: 0.7932 - val_loss: 0.7706 - val_mse: 0.7706\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.7935 - mse: 0.7935 - val_loss: 0.7618 - val_mse: 0.7618\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.7928 - mse: 0.7928 - val_loss: 0.7606 - val_mse: 0.7606\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.7919 - mse: 0.7919 - val_loss: 0.7677 - val_mse: 0.7677\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.7916 - mse: 0.7916 - val_loss: 0.7578 - val_mse: 0.7578\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.7907 - mse: 0.7907 - val_loss: 0.7566 - val_mse: 0.7566\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.7906 - mse: 0.7906 - val_loss: 0.7672 - val_mse: 0.7672\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.7901 - mse: 0.7901 - val_loss: 0.7540 - val_mse: 0.7540\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.7895 - mse: 0.7895 - val_loss: 0.7601 - val_mse: 0.7601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 130/200 [53:01<40:27, 34.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 383ms/step - loss: 1.2406 - mse: 1.2406 - val_loss: 1.2381 - val_mse: 1.2381\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2369 - mse: 1.2369 - val_loss: 1.2344 - val_mse: 1.2344\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2333 - mse: 1.2333 - val_loss: 1.2308 - val_mse: 1.2308\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2296 - mse: 1.2296 - val_loss: 1.2272 - val_mse: 1.2272\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2261 - mse: 1.2261 - val_loss: 1.2237 - val_mse: 1.2237\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2225 - mse: 1.2225 - val_loss: 1.2202 - val_mse: 1.2202\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2190 - mse: 1.2190 - val_loss: 1.2167 - val_mse: 1.2167\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2156 - mse: 1.2156 - val_loss: 1.2133 - val_mse: 1.2133\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2122 - mse: 1.2122 - val_loss: 1.2099 - val_mse: 1.2099\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2088 - mse: 1.2088 - val_loss: 1.2065 - val_mse: 1.2065\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2055 - mse: 1.2055 - val_loss: 1.2032 - val_mse: 1.2032\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.2022 - mse: 1.2022 - val_loss: 1.2000 - val_mse: 1.2000\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.1989 - mse: 1.1989 - val_loss: 1.1968 - val_mse: 1.1968\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.1957 - mse: 1.1957 - val_loss: 1.1936 - val_mse: 1.1936\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.1926 - mse: 1.1926 - val_loss: 1.1905 - val_mse: 1.1905\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.1895 - mse: 1.1895 - val_loss: 1.1874 - val_mse: 1.1874\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.1864 - mse: 1.1864 - val_loss: 1.1844 - val_mse: 1.1844\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.1834 - mse: 1.1834 - val_loss: 1.1814 - val_mse: 1.1814\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.1804 - mse: 1.1804 - val_loss: 1.1784 - val_mse: 1.1784\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.1775 - mse: 1.1775 - val_loss: 1.1755 - val_mse: 1.1755\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.1746 - mse: 1.1746 - val_loss: 1.1727 - val_mse: 1.1727\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.1717 - mse: 1.1717 - val_loss: 1.1699 - val_mse: 1.1699\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.1690 - mse: 1.1690 - val_loss: 1.1671 - val_mse: 1.1671\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.1662 - mse: 1.1662 - val_loss: 1.1644 - val_mse: 1.1644\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.1635 - mse: 1.1635 - val_loss: 1.1617 - val_mse: 1.1617\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.1608 - mse: 1.1608 - val_loss: 1.1591 - val_mse: 1.1591\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.1582 - mse: 1.1582 - val_loss: 1.1565 - val_mse: 1.1565\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.1557 - mse: 1.1557 - val_loss: 1.1540 - val_mse: 1.1540\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 1.1531 - mse: 1.1531 - val_loss: 1.1515 - val_mse: 1.1515\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 1.1506 - mse: 1.1506 - val_loss: 1.1490 - val_mse: 1.1490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 131/200 [53:43<42:25, 36.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 419ms/step - loss: 1.2413 - mse: 1.2413 - val_loss: 1.2378 - val_mse: 1.2378\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2391 - mse: 1.2391 - val_loss: 1.2352 - val_mse: 1.2352\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 1.2369 - mse: 1.2369 - val_loss: 1.2325 - val_mse: 1.2325\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 1.2347 - mse: 1.2347 - val_loss: 1.2299 - val_mse: 1.2299\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 1.2325 - mse: 1.2325 - val_loss: 1.2273 - val_mse: 1.2273\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2303 - mse: 1.2303 - val_loss: 1.2246 - val_mse: 1.2246\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 1.2281 - mse: 1.2281 - val_loss: 1.2220 - val_mse: 1.2220\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.2259 - mse: 1.2259 - val_loss: 1.2193 - val_mse: 1.2193\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.2236 - mse: 1.2236 - val_loss: 1.2166 - val_mse: 1.2166\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 1.2214 - mse: 1.2214 - val_loss: 1.2139 - val_mse: 1.2139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 132/200 [53:54<33:06, 29.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 390ms/step - loss: 1.2144 - mse: 1.2144 - val_loss: 1.1805 - val_mse: 1.1805\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 1.1400 - val_mse: 1.1400\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.1465 - mse: 1.1465 - val_loss: 1.0981 - val_mse: 1.0981\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.1104 - mse: 1.1104 - val_loss: 1.0560 - val_mse: 1.0560\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.0743 - mse: 1.0743 - val_loss: 1.0161 - val_mse: 1.0161\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 1.0407 - mse: 1.0407 - val_loss: 0.9811 - val_mse: 0.9811\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.0117 - mse: 1.0117 - val_loss: 0.9527 - val_mse: 0.9527\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9889 - mse: 0.9889 - val_loss: 0.9314 - val_mse: 0.9314\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9720 - mse: 0.9720 - val_loss: 0.9164 - val_mse: 0.9164\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9062 - val_mse: 0.9062\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.9524 - mse: 0.9524 - val_loss: 0.8994 - val_mse: 0.8994\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.9471 - mse: 0.9471 - val_loss: 0.8947 - val_mse: 0.8947\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.9434 - mse: 0.9434 - val_loss: 0.8913 - val_mse: 0.8913\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9407 - mse: 0.9407 - val_loss: 0.8888 - val_mse: 0.8888\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9387 - mse: 0.9387 - val_loss: 0.8869 - val_mse: 0.8869\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9371 - mse: 0.9371 - val_loss: 0.8853 - val_mse: 0.8853\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9357 - mse: 0.9357 - val_loss: 0.8839 - val_mse: 0.8839\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 287ms/step - loss: 0.9345 - mse: 0.9345 - val_loss: 0.8827 - val_mse: 0.8827\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8817 - val_mse: 0.8817\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9324 - mse: 0.9324 - val_loss: 0.8807 - val_mse: 0.8807\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9314 - mse: 0.9314 - val_loss: 0.8797 - val_mse: 0.8797\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.9305 - mse: 0.9305 - val_loss: 0.8789 - val_mse: 0.8789\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 0.9297 - mse: 0.9297 - val_loss: 0.8781 - val_mse: 0.8781\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.9289 - mse: 0.9289 - val_loss: 0.8773 - val_mse: 0.8773\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9281 - mse: 0.9281 - val_loss: 0.8766 - val_mse: 0.8766\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9274 - mse: 0.9274 - val_loss: 0.8760 - val_mse: 0.8760\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9267 - mse: 0.9267 - val_loss: 0.8753 - val_mse: 0.8753\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9260 - mse: 0.9260 - val_loss: 0.8747 - val_mse: 0.8747\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.9253 - mse: 0.9253 - val_loss: 0.8742 - val_mse: 0.8742\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9247 - mse: 0.9247 - val_loss: 0.8737 - val_mse: 0.8737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 133/200 [54:36<36:56, 33.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 2s 347ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2456 - val_mse: 1.2456\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.2450 - mse: 1.2450 - val_loss: 1.2428 - val_mse: 1.2428\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2394 - val_mse: 1.2394\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.2388 - mse: 1.2388 - val_loss: 1.2358 - val_mse: 1.2358\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.2352 - mse: 1.2352 - val_loss: 1.2316 - val_mse: 1.2316\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.2312 - mse: 1.2312 - val_loss: 1.2269 - val_mse: 1.2269\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.2265 - mse: 1.2265 - val_loss: 1.2214 - val_mse: 1.2214\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 1.2151 - val_mse: 1.2151\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.2150 - mse: 1.2150 - val_loss: 1.2079 - val_mse: 1.2079\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.2080 - mse: 1.2080 - val_loss: 1.1995 - val_mse: 1.1995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 134/200 [54:48<29:12, 26.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 2s 583ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 1.2399 - val_mse: 1.2399\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2407 - mse: 1.2407 - val_loss: 1.2383 - val_mse: 1.2383\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.2394 - mse: 1.2394 - val_loss: 1.2367 - val_mse: 1.2367\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 1.2380 - mse: 1.2380 - val_loss: 1.2351 - val_mse: 1.2351\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 1.2367 - mse: 1.2367 - val_loss: 1.2335 - val_mse: 1.2335\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 371ms/step - loss: 1.2353 - mse: 1.2353 - val_loss: 1.2319 - val_mse: 1.2319\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 1.2340 - mse: 1.2340 - val_loss: 1.2302 - val_mse: 1.2302\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 1.2326 - mse: 1.2326 - val_loss: 1.2286 - val_mse: 1.2286\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 1.2312 - mse: 1.2312 - val_loss: 1.2269 - val_mse: 1.2269\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.2298 - mse: 1.2298 - val_loss: 1.2253 - val_mse: 1.2253\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 1.2285 - mse: 1.2285 - val_loss: 1.2236 - val_mse: 1.2236\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 1.2270 - mse: 1.2270 - val_loss: 1.2219 - val_mse: 1.2219\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2256 - mse: 1.2256 - val_loss: 1.2202 - val_mse: 1.2202\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.2242 - mse: 1.2242 - val_loss: 1.2184 - val_mse: 1.2184\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2227 - mse: 1.2227 - val_loss: 1.2167 - val_mse: 1.2167\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 1.2149 - val_mse: 1.2149\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 377ms/step - loss: 1.2197 - mse: 1.2197 - val_loss: 1.2131 - val_mse: 1.2131\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 1.2182 - mse: 1.2182 - val_loss: 1.2112 - val_mse: 1.2112\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2167 - mse: 1.2167 - val_loss: 1.2094 - val_mse: 1.2094\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.2151 - mse: 1.2151 - val_loss: 1.2075 - val_mse: 1.2075\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.2135 - mse: 1.2135 - val_loss: 1.2056 - val_mse: 1.2056\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.2118 - mse: 1.2118 - val_loss: 1.2036 - val_mse: 1.2036\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 1.2102 - mse: 1.2102 - val_loss: 1.2016 - val_mse: 1.2016\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 1.2085 - mse: 1.2085 - val_loss: 1.1996 - val_mse: 1.1996\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 1.2068 - mse: 1.2068 - val_loss: 1.1975 - val_mse: 1.1975\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2051 - mse: 1.2051 - val_loss: 1.1954 - val_mse: 1.1954\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 1.2033 - mse: 1.2033 - val_loss: 1.1933 - val_mse: 1.1933\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 1.2015 - mse: 1.2015 - val_loss: 1.1911 - val_mse: 1.1911\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 1.1997 - mse: 1.1997 - val_loss: 1.1889 - val_mse: 1.1889\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 1.1978 - mse: 1.1978 - val_loss: 1.1867 - val_mse: 1.1867\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.1959 - mse: 1.1959 - val_loss: 1.1844 - val_mse: 1.1844\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.1940 - mse: 1.1940 - val_loss: 1.1821 - val_mse: 1.1821\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 1.1920 - mse: 1.1920 - val_loss: 1.1797 - val_mse: 1.1797\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 1s 363ms/step - loss: 1.1900 - mse: 1.1900 - val_loss: 1.1773 - val_mse: 1.1773\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.1880 - mse: 1.1880 - val_loss: 1.1749 - val_mse: 1.1749\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 1.1859 - mse: 1.1859 - val_loss: 1.1724 - val_mse: 1.1724\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 1s 351ms/step - loss: 1.1838 - mse: 1.1838 - val_loss: 1.1699 - val_mse: 1.1699\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 1.1817 - mse: 1.1817 - val_loss: 1.1674 - val_mse: 1.1674\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 1.1795 - mse: 1.1795 - val_loss: 1.1648 - val_mse: 1.1648\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.1773 - mse: 1.1773 - val_loss: 1.1622 - val_mse: 1.1622\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 1.1751 - mse: 1.1751 - val_loss: 1.1595 - val_mse: 1.1595\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 1.1728 - mse: 1.1728 - val_loss: 1.1568 - val_mse: 1.1568\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 1.1705 - mse: 1.1705 - val_loss: 1.1541 - val_mse: 1.1541\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 1.1682 - mse: 1.1682 - val_loss: 1.1513 - val_mse: 1.1513\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 1.1659 - mse: 1.1659 - val_loss: 1.1485 - val_mse: 1.1485\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 1.1635 - mse: 1.1635 - val_loss: 1.1457 - val_mse: 1.1457\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 1.1611 - mse: 1.1611 - val_loss: 1.1428 - val_mse: 1.1428\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 1.1586 - mse: 1.1586 - val_loss: 1.1399 - val_mse: 1.1399\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 1.1561 - mse: 1.1561 - val_loss: 1.1370 - val_mse: 1.1370\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 1.1536 - mse: 1.1536 - val_loss: 1.1341 - val_mse: 1.1341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 135/200 [56:11<47:06, 43.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 384ms/step - loss: 1.1905 - mse: 1.1905 - val_loss: 1.0982 - val_mse: 1.0982\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.0892 - mse: 1.0892 - val_loss: 1.0160 - val_mse: 1.0160\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 1.0315 - mse: 1.0315 - val_loss: 0.9714 - val_mse: 0.9714\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.0006 - mse: 1.0006 - val_loss: 0.9466 - val_mse: 0.9466\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.9831 - mse: 0.9831 - val_loss: 0.9317 - val_mse: 0.9317\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.9724 - mse: 0.9724 - val_loss: 0.9220 - val_mse: 0.9220\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9651 - mse: 0.9651 - val_loss: 0.9152 - val_mse: 0.9152\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9598 - mse: 0.9598 - val_loss: 0.9101 - val_mse: 0.9101\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9557 - mse: 0.9557 - val_loss: 0.9061 - val_mse: 0.9061\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.9524 - mse: 0.9524 - val_loss: 0.9029 - val_mse: 0.9029\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.9496 - mse: 0.9496 - val_loss: 0.9003 - val_mse: 0.9003\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.9472 - mse: 0.9472 - val_loss: 0.8981 - val_mse: 0.8981\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.8962 - val_mse: 0.8962\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9431 - mse: 0.9431 - val_loss: 0.8945 - val_mse: 0.8945\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.8930 - val_mse: 0.8930\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9395 - mse: 0.9395 - val_loss: 0.8916 - val_mse: 0.8916\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.9378 - mse: 0.9378 - val_loss: 0.8902 - val_mse: 0.8902\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.9360 - mse: 0.9360 - val_loss: 0.8889 - val_mse: 0.8889\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.9340 - mse: 0.9340 - val_loss: 0.8874 - val_mse: 0.8874\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.9317 - mse: 0.9317 - val_loss: 0.8858 - val_mse: 0.8858\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.9291 - mse: 0.9291 - val_loss: 0.8840 - val_mse: 0.8840\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.9260 - mse: 0.9260 - val_loss: 0.8818 - val_mse: 0.8818\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 281ms/step - loss: 0.9224 - mse: 0.9224 - val_loss: 0.8793 - val_mse: 0.8793\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.9183 - mse: 0.9183 - val_loss: 0.8765 - val_mse: 0.8765\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9139 - mse: 0.9139 - val_loss: 0.8735 - val_mse: 0.8735\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.9095 - mse: 0.9095 - val_loss: 0.8705 - val_mse: 0.8705\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 284ms/step - loss: 0.9056 - mse: 0.9056 - val_loss: 0.8679 - val_mse: 0.8679\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.9020 - mse: 0.9020 - val_loss: 0.8656 - val_mse: 0.8656\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.8989 - mse: 0.8989 - val_loss: 0.8637 - val_mse: 0.8637\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.8960 - mse: 0.8960 - val_loss: 0.8619 - val_mse: 0.8619\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 283ms/step - loss: 0.8931 - mse: 0.8931 - val_loss: 0.8600 - val_mse: 0.8600\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.8901 - mse: 0.8901 - val_loss: 0.8580 - val_mse: 0.8580\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.8869 - mse: 0.8869 - val_loss: 0.8553 - val_mse: 0.8553\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.8834 - mse: 0.8834 - val_loss: 0.8523 - val_mse: 0.8523\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.8795 - mse: 0.8795 - val_loss: 0.8484 - val_mse: 0.8484\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.8751 - mse: 0.8751 - val_loss: 0.8440 - val_mse: 0.8440\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.8703 - mse: 0.8703 - val_loss: 0.8389 - val_mse: 0.8389\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.8649 - mse: 0.8649 - val_loss: 0.8334 - val_mse: 0.8334\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.8590 - mse: 0.8590 - val_loss: 0.8269 - val_mse: 0.8269\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.8529 - mse: 0.8529 - val_loss: 0.8209 - val_mse: 0.8209\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.8469 - mse: 0.8469 - val_loss: 0.8148 - val_mse: 0.8148\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.8413 - mse: 0.8413 - val_loss: 0.8098 - val_mse: 0.8098\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.8363 - mse: 0.8363 - val_loss: 0.8053 - val_mse: 0.8053\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.8318 - mse: 0.8318 - val_loss: 0.8017 - val_mse: 0.8017\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.8279 - mse: 0.8279 - val_loss: 0.7988 - val_mse: 0.7988\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.8247 - mse: 0.8247 - val_loss: 0.7964 - val_mse: 0.7964\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 0.8219 - mse: 0.8219 - val_loss: 0.7941 - val_mse: 0.7941\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.8197 - mse: 0.8197 - val_loss: 0.7924 - val_mse: 0.7924\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 0.8178 - mse: 0.8178 - val_loss: 0.7909 - val_mse: 0.7909\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 278ms/step - loss: 0.8162 - mse: 0.8162 - val_loss: 0.7894 - val_mse: 0.7894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 136/200 [56:52<45:34, 42.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 2s 131ms/step - loss: 1.0906 - mse: 1.0906 - val_loss: 1.0874 - val_mse: 1.0874\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0850 - mse: 1.0850 - val_loss: 1.0821 - val_mse: 1.0821\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0798 - mse: 1.0798 - val_loss: 1.0770 - val_mse: 1.0770\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0750 - mse: 1.0750 - val_loss: 1.0724 - val_mse: 1.0724\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0704 - mse: 1.0704 - val_loss: 1.0680 - val_mse: 1.0680\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0662 - mse: 1.0662 - val_loss: 1.0639 - val_mse: 1.0639\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0623 - mse: 1.0623 - val_loss: 1.0602 - val_mse: 1.0602\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0586 - mse: 1.0586 - val_loss: 1.0567 - val_mse: 1.0567\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0552 - mse: 1.0552 - val_loss: 1.0535 - val_mse: 1.0535\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0521 - mse: 1.0521 - val_loss: 1.0505 - val_mse: 1.0505\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0492 - mse: 1.0492 - val_loss: 1.0477 - val_mse: 1.0477\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0465 - mse: 1.0465 - val_loss: 1.0451 - val_mse: 1.0451\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0440 - mse: 1.0440 - val_loss: 1.0427 - val_mse: 1.0427\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0416 - mse: 1.0416 - val_loss: 1.0404 - val_mse: 1.0404\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0395 - mse: 1.0395 - val_loss: 1.0383 - val_mse: 1.0383\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0374 - mse: 1.0374 - val_loss: 1.0364 - val_mse: 1.0364\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0355 - mse: 1.0355 - val_loss: 1.0346 - val_mse: 1.0346\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0338 - mse: 1.0338 - val_loss: 1.0329 - val_mse: 1.0329\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0321 - mse: 1.0321 - val_loss: 1.0313 - val_mse: 1.0313\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0306 - mse: 1.0306 - val_loss: 1.0298 - val_mse: 1.0298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 137/200 [57:11<37:36, 35.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "2/2 [==============================] - 2s 550ms/step - loss: 1.2079 - mse: 1.2079 - val_loss: 0.9617 - val_mse: 0.9617\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 1s 326ms/step - loss: 0.9926 - mse: 0.9926 - val_loss: 0.9157 - val_mse: 0.9157\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9035 - val_mse: 0.9035\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 0.9522 - mse: 0.9522 - val_loss: 0.8982 - val_mse: 0.8982\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 0.9485 - mse: 0.9485 - val_loss: 0.8949 - val_mse: 0.8949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 138/200 [57:18<27:49, 26.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 554ms/step - loss: 1.2535 - mse: 1.2535 - val_loss: 1.1756 - val_mse: 1.1756\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 326ms/step - loss: 1.1767 - mse: 1.1767 - val_loss: 1.0822 - val_mse: 1.0822\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.0949 - mse: 1.0949 - val_loss: 0.9867 - val_mse: 0.9867\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9253 - val_mse: 0.9253\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.9673 - mse: 0.9673 - val_loss: 0.9014 - val_mse: 0.9014\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 326ms/step - loss: 0.9496 - mse: 0.9496 - val_loss: 0.8936 - val_mse: 0.8936\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.9440 - mse: 0.9440 - val_loss: 0.8900 - val_mse: 0.8900\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 0.8872 - val_mse: 0.8872\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 0.9390 - mse: 0.9390 - val_loss: 0.8846 - val_mse: 0.8846\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.9366 - mse: 0.9366 - val_loss: 0.8821 - val_mse: 0.8821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 139/200 [57:29<22:37, 22.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 351ms/step - loss: 1.1285 - mse: 1.1285 - val_loss: 0.9244 - val_mse: 0.9244\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9650 - mse: 0.9650 - val_loss: 0.9056 - val_mse: 0.9056\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.9529 - mse: 0.9529 - val_loss: 0.8978 - val_mse: 0.8978\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.9470 - mse: 0.9470 - val_loss: 0.8929 - val_mse: 0.8929\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.9431 - mse: 0.9431 - val_loss: 0.8899 - val_mse: 0.8899\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.9406 - mse: 0.9406 - val_loss: 0.8881 - val_mse: 0.8881\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.9389 - mse: 0.9389 - val_loss: 0.8869 - val_mse: 0.8869\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9378 - mse: 0.9378 - val_loss: 0.8860 - val_mse: 0.8860\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9367 - mse: 0.9367 - val_loss: 0.8850 - val_mse: 0.8850\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.9355 - mse: 0.9355 - val_loss: 0.8835 - val_mse: 0.8835\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.9339 - mse: 0.9339 - val_loss: 0.8816 - val_mse: 0.8816\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.9316 - mse: 0.9316 - val_loss: 0.8787 - val_mse: 0.8787\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.9283 - mse: 0.9283 - val_loss: 0.8740 - val_mse: 0.8740\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9221 - mse: 0.9221 - val_loss: 0.8646 - val_mse: 0.8646\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.9086 - mse: 0.9086 - val_loss: 0.8528 - val_mse: 0.8528\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.8838 - mse: 0.8838 - val_loss: 0.8280 - val_mse: 0.8280\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.8559 - mse: 0.8559 - val_loss: 0.8150 - val_mse: 0.8150\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8420 - mse: 0.8420 - val_loss: 0.8164 - val_mse: 0.8164\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8321 - mse: 0.8321 - val_loss: 0.8018 - val_mse: 0.8018\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8248 - mse: 0.8248 - val_loss: 0.8053 - val_mse: 0.8053\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.8207 - mse: 0.8207 - val_loss: 0.7944 - val_mse: 0.7944\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8181 - mse: 0.8181 - val_loss: 0.7987 - val_mse: 0.7987\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.8162 - mse: 0.8162 - val_loss: 0.7910 - val_mse: 0.7910\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8140 - mse: 0.8140 - val_loss: 0.7921 - val_mse: 0.7921\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8124 - mse: 0.8124 - val_loss: 0.7883 - val_mse: 0.7883\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.8107 - mse: 0.8107 - val_loss: 0.7871 - val_mse: 0.7871\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.8090 - mse: 0.8090 - val_loss: 0.7870 - val_mse: 0.7870\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.8078 - mse: 0.8078 - val_loss: 0.7832 - val_mse: 0.7832\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.8066 - mse: 0.8066 - val_loss: 0.7830 - val_mse: 0.7830\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.8055 - mse: 0.8055 - val_loss: 0.7805 - val_mse: 0.7805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 140/200 [57:54<23:08, 23.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 551ms/step - loss: 1.2493 - mse: 1.2493 - val_loss: 1.2489 - val_mse: 1.2489\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.2480 - mse: 1.2480 - val_loss: 1.2474 - val_mse: 1.2474\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.2466 - mse: 1.2466 - val_loss: 1.2459 - val_mse: 1.2459\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 327ms/step - loss: 1.2451 - mse: 1.2451 - val_loss: 1.2441 - val_mse: 1.2441\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.2434 - mse: 1.2434 - val_loss: 1.2422 - val_mse: 1.2422\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 1.2416 - mse: 1.2416 - val_loss: 1.2400 - val_mse: 1.2400\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 1.2395 - mse: 1.2395 - val_loss: 1.2375 - val_mse: 1.2375\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 321ms/step - loss: 1.2370 - mse: 1.2370 - val_loss: 1.2346 - val_mse: 1.2346\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 1.2343 - mse: 1.2343 - val_loss: 1.2311 - val_mse: 1.2311\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 330ms/step - loss: 1.2310 - mse: 1.2310 - val_loss: 1.2273 - val_mse: 1.2273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 141/200 [58:03<18:36, 18.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 2s 226ms/step - loss: 1.1864 - mse: 1.1864 - val_loss: 1.0288 - val_mse: 1.0288\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.0318 - mse: 1.0318 - val_loss: 0.9537 - val_mse: 0.9537\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 0.9862 - mse: 0.9862 - val_loss: 0.9282 - val_mse: 0.9282\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.9693 - mse: 0.9693 - val_loss: 0.9161 - val_mse: 0.9161\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 0.9606 - mse: 0.9606 - val_loss: 0.9088 - val_mse: 0.9088\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.9550 - mse: 0.9550 - val_loss: 0.9037 - val_mse: 0.9037\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 0.8998 - val_mse: 0.8998\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.9474 - mse: 0.9474 - val_loss: 0.8966 - val_mse: 0.8966\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 0.9446 - mse: 0.9446 - val_loss: 0.8940 - val_mse: 0.8940\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 0.9420 - mse: 0.9420 - val_loss: 0.8916 - val_mse: 0.8916\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.9395 - mse: 0.9395 - val_loss: 0.8894 - val_mse: 0.8894\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 0.9368 - mse: 0.9368 - val_loss: 0.8870 - val_mse: 0.8870\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8841 - val_mse: 0.8841\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 173ms/step - loss: 0.9284 - mse: 0.9284 - val_loss: 0.8806 - val_mse: 0.8806\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.9212 - mse: 0.9212 - val_loss: 0.8785 - val_mse: 0.8785\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 0.9146 - mse: 0.9146 - val_loss: 0.8751 - val_mse: 0.8751\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.9073 - mse: 0.9073 - val_loss: 0.8674 - val_mse: 0.8674\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 0.9010 - mse: 0.9010 - val_loss: 0.8628 - val_mse: 0.8628\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 0.8957 - mse: 0.8957 - val_loss: 0.8605 - val_mse: 0.8605\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 0.8903 - mse: 0.8903 - val_loss: 0.8579 - val_mse: 0.8579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 142/200 [58:25<19:03, 19.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 375ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2514 - val_mse: 1.2514\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2514 - mse: 1.2514 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2513 - mse: 1.2513 - val_loss: 1.2513 - val_mse: 1.2513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 143/200 [59:48<36:47, 38.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1022, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1020, 64)          24640     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1018, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 1020, 32)          3104      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 1022, 64)          6208      \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 1024, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1024, 1)           385       \n",
            "=================================================================\n",
            "Total params: 65,729\n",
            "Trainable params: 65,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 218ms/step - loss: 1.0857 - mse: 1.0857 - val_loss: 1.0676 - val_mse: 1.0676\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.0598 - mse: 1.0598 - val_loss: 1.0469 - val_mse: 1.0469\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.0415 - mse: 1.0415 - val_loss: 1.0327 - val_mse: 1.0327\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.0291 - mse: 1.0291 - val_loss: 1.0232 - val_mse: 1.0232\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.0208 - mse: 1.0208 - val_loss: 1.0169 - val_mse: 1.0169\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 1.0127 - val_mse: 1.0127\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 1.0116 - mse: 1.0116 - val_loss: 1.0099 - val_mse: 1.0099\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.0091 - mse: 1.0091 - val_loss: 1.0079 - val_mse: 1.0079\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0073 - mse: 1.0073 - val_loss: 1.0064 - val_mse: 1.0064\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 1.0054 - val_mse: 1.0054\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.0050 - mse: 1.0050 - val_loss: 1.0046 - val_mse: 1.0046\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 1.0043 - mse: 1.0043 - val_loss: 1.0039 - val_mse: 1.0039\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0037 - mse: 1.0037 - val_loss: 1.0034 - val_mse: 1.0034\n",
            "Epoch 14/50\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 1.0034 - mse: 1.0034"
          ]
        }
      ]
    }
  ]
}